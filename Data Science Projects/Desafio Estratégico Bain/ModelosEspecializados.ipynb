{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pmdarima\n",
    "#!pip install TBATS\n",
    "#!pip install auto_ts\n",
    "#pip install fedot==0.3.0\n",
    "# !pip install auto_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd; pd.set_option('display.max_columns', None) \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pickle\n",
    "from IPython.display import clear_output as co\n",
    "from random import random\n",
    "import warnings; # ...\n",
    "\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.utils\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from pmdarima.arima import auto_arima\n",
    "from tbats import TBATS\n",
    "# import auto_ts\n",
    "# import prophet\n",
    "#from fedot.api.main import Fedot\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder\n",
    "#regressors = dict(sklearn.utils.all_estimators('regressor'))\n",
    "metrics = sklearn.metrics._regression\n",
    "mae = metrics.mean_absolute_error\n",
    "mse = metrics.mean_squared_error\n",
    "mape = metrics.mean_absolute_percentage_error\n",
    "r2 = metrics.r2_score\n",
    "me = metrics.max_error\n",
    "medae = metrics.median_absolute_error\n",
    "evs = metrics.explained_variance_score\n",
    "mpd = metrics.mean_poisson_deviance\n",
    "mgd = metrics.mean_gamma_deviance\n",
    "def wape(ye, yhat):\n",
    "    return np.abs(ye-yhat).sum()/ye.sum()\n",
    "def e(ye, yhat):\n",
    "    return np.abs(yhat-ye).sum()\n",
    "def estd(ye, yhat):\n",
    "    return np.abs(yhat-ye).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declarando Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series(path='series/'):\n",
    "    filenames = os.listdir(path)\n",
    "    series, cnt, n_files = {}, 0, len(filenames)\n",
    "    freq = range(1, n_files, 10)\n",
    "    for filename in filenames:\n",
    "        cnt+=1\n",
    "        if cnt in freq: print(f'Files loaded: {cnt}/{n_files}'); co(wait=True)\n",
    "        series[filename[:-4]] = pd.read_csv(path+filename, index_col=0)\n",
    "    print(f'Done! Loaded {n_files} files.')\n",
    "    return series\n",
    "\n",
    "## Return random serie's city and product-type\n",
    "def sample_serie():\n",
    "    keys = np.random.choice(list(series.keys())).split('-')\n",
    "    return keys[0], keys[1:]\n",
    "    \n",
    "def clean_series(series, train_min=1, drop_start_zeros=True):\n",
    "    clean_series = {}\n",
    "    test_empty = []\n",
    "    excluded_test_index = []\n",
    "    n_total = len(series)\n",
    "    n_values_total = 0\n",
    "    n_values_test = 0\n",
    "    n_values_train = 0\n",
    "    n_series = 0\n",
    "    n_series_empty = 0\n",
    "    n_series_test_empty = 0\n",
    "    n_series_train_min_empty = 0\n",
    "    n_values = 0\n",
    "    n_test_empty_total = 0\n",
    "    n_train_empty_total = 0\n",
    "    n_non_empty_values = 0\n",
    "    n_train_zeros = 0\n",
    "\n",
    "    cnt, freq = 0, range(1, n_total, 10)\n",
    "    for key in list(series.keys()):\n",
    "        cnt+=1\n",
    "        if cnt in freq: print(f'Cleaned series: {cnt}/{n_total}'); co(wait=True)\n",
    "\n",
    "        msk = series[key]['year'].isin(['01/01/2016', '01/01/2017'])\n",
    "        test = series[key][msk]\n",
    "        train = series[key][msk==False]\n",
    "\n",
    "        n = len(series[key])\n",
    "        n_empty = series[key][target].isna().sum()\n",
    "        n_test_empty = test[target].isna().sum()\n",
    "        n_train_empty = train[target].isna().sum()\n",
    "\n",
    "        cond1 = n_test_empty == len(test)\n",
    "        cond2 = n_train_empty > (len(train) - train_min) # if number of training samples is greater than specified minimum.\n",
    "\n",
    "        n_values_total += n\n",
    "        n_values_test += len(test)\n",
    "        n_values_train += len(train)\n",
    "\n",
    "        n_series_empty += n==n_empty\n",
    "        n_test_empty_total+=n_test_empty\n",
    "        n_train_empty_total+=n_train_empty\n",
    "        n_series_test_empty += cond1\n",
    "        n_series_train_min_empty += cond2\n",
    "\n",
    "        if cond1 or cond2:\n",
    "            n_series+=1\n",
    "            n_values+=len(series[key])\n",
    "            n_non_empty_values+=(len(series[key]) - n_empty)\n",
    "            excluded_test_index.extend(test[test[target].isna()==False].index.tolist())\n",
    "\n",
    "        else:\n",
    "            n_values+=n_empty\n",
    "            clean_series[key] = series[key].dropna(subset=['area'])\n",
    "            if drop_start_zeros:\n",
    "                test_msk = clean_series[key]['year'].isin(['01/01/2016', '01/01/2017'])\n",
    "                train_msk = test_msk==False\n",
    "                isNotZero = (clean_series[key][train_msk]['area']!=0).tolist()\n",
    "                if sum(isNotZero)!=0:\n",
    "                    testset = clean_series[key][test_msk]\n",
    "                    trainset_cut = clean_series[key][train_msk].iloc[isNotZero.index(True):]\n",
    "                    clean_series[key] = pd.concat([trainset_cut, testset])\n",
    "                    n_train_zeros+=(sum(train_msk)-len(trainset_cut))\n",
    "\n",
    "\n",
    "    print('Values Count:')\n",
    "    print( pd.Series(\n",
    "        [n_total, n_values_total, n_values_test, n_values_train],\n",
    "        index=['n_total', 'n_values_total', 'n_values_test', 'n_values_train'])\n",
    "    )\n",
    "    print(); print('Excluded count:')\n",
    "    print(\n",
    "        pd.Series([\n",
    "            n_series, n_series_empty, n_series_test_empty, n_series_train_min_empty,\n",
    "            n_values, n_values-n_non_empty_values, n_test_empty_total, n_train_empty_total,\n",
    "            n_non_empty_values, len(excluded_test_index), n_train_zeros\n",
    "        ],\n",
    "        index=[\n",
    "            'series', 'series_empty', 'series_test_empty', f'series_train_min_<_{train_min}',\n",
    "            'values', 'values_empty', 'test_empty', 'train_empty',\n",
    "            'non_empty_values', 'non_empty_test_values', 'n_train_zeros'\n",
    "        ])\n",
    "    )\n",
    "    return clean_series, excluded_test_index\n",
    "\n",
    "def test_data():\n",
    "    Y_e = []\n",
    "    for key in series.keys():\n",
    "        x_t, x_e, y_t, y_e = custom_tts(key)\n",
    "        Y_e.append(y_e)\n",
    "    return pd.concat(Y_e)\n",
    "\n",
    "def get_prod_indexes():\n",
    "    prod_indexes = {}\n",
    "    for prod in prods:\n",
    "        if prod not in ['Sorghum', 'Açaí']:\n",
    "            if '-' in prod: \n",
    "                product, prod_type = prod.split('-')\n",
    "            else:\n",
    "                product = prod\n",
    "            df = data_e[data_e['product']==product].copy()        \n",
    "            if '-' in prod: \n",
    "                df = df[df['product_type']==prod_type]\n",
    "\n",
    "            prod_indexes[prod] = df.index.copy()\n",
    "    return prod_indexes\n",
    "\n",
    "def get_prodtype_indexes():\n",
    "    prodtype_indexes = {}\n",
    "    for prodtype in ['temporary', 'permanent', 'pasture']:\n",
    "        df = data_e[data_e['product_type']==prodtype].copy()        \n",
    "        prodtype_indexes[prodtype] = df.index.copy()\n",
    "    return prodtype_indexes\n",
    "\n",
    "#### Mapping between the series test indexes and the series key\n",
    "def get_key_index_test_map():    \n",
    "    key_test_index_map = {}\n",
    "    for key in series.keys():    \n",
    "        key_index = series[key].index\n",
    "        for entry_index in key_index:\n",
    "            if entry_index in Y_e.index:\n",
    "                key_test_index_map[entry_index] = key\n",
    "    return key_test_index_map\n",
    "\n",
    "def get_key_prodtype_map():\n",
    "    key_prodtype_map = {}\n",
    "    for key in series.keys():\n",
    "        key_prodtype_map[key] = series[key].iloc[0]['product_type']\n",
    "    return key_prodtype_map\n",
    "\n",
    "#### Extract predictive and target variables\n",
    "def get_xy(data, target='area', fill_na=0):\n",
    "    ## 1. Extraindo variáveis preditivas\n",
    "    X = data.drop(target, 1)\n",
    "    ## 2. Extraindo Variável Álvo\n",
    "    Y = data[target].copy()\n",
    "    #### Substituição de Valores Vazios para Variável Alvo\n",
    "#     Y[Y.isna()] = fill_na\n",
    "    return X,Y\n",
    "\n",
    "#### Label Encode pandas dataframe\n",
    "def label_encode(X, base=None):\n",
    "    if type(base)==type(None): base = X\n",
    "    X_lab = X.copy()\n",
    "    for column in X:\n",
    "        X_lab[column] = le().fit(base[column]).transform(X[column])\n",
    "    return X_lab\n",
    "\n",
    "## Separação das amostras para treinamento e teste\n",
    "def split_ts(x, y, col='year', horizon=2):\n",
    "#     periods = x[col].sort_values().iloc[:len(x)-horizon]\n",
    "    msk = x[col].isin([42, 43])\n",
    "    return [x[msk==False], x[msk], y[msk==False], y[msk]]\n",
    "\n",
    "### Train test split of time series by key\n",
    "def custom_tts(key, encode=True):\n",
    "    x, y = get_xy(series[key], target='area', fill_na=0)\n",
    "    if encode: x = label_encode(x[['year']], base=data)\n",
    "    return split_ts(x, y, col='year', horizon=2)\n",
    "\n",
    "## Evaluating Model Predictions\n",
    "def score_predictions(y_e, y_hat):\n",
    "    return [mae(y_e, y_hat), mse(y_e, y_hat), mape(y_e, y_hat), wape(y_e, y_hat), r2(y_e, y_hat)]\n",
    "\n",
    "## Evaluating model predictions given scorer list\n",
    "def score_predictions_custom(y_e, y_hat, scorers=None):\n",
    "    if type(scorers)==type(None):\n",
    "        scorers = [mae, mse, mape, wape, r2]; names=scrs\n",
    "    return [scorer(y_e, y_hat) for scorer in scorers]\n",
    "\n",
    "def isComplete(ts):\n",
    "    return (ts.index.max().year - ts.index.min().year + 1) == len(ts)\n",
    "\n",
    "def train_test_min_max_year(train, test):\n",
    "    return train.index.min().year, train.index.max().year, test.index.min().year, test.index.max().year\n",
    "\n",
    "def train_test_min_max(train, test):\n",
    "    return train.index.min(), train.index.max(), test.index.min(), test.index.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating model predictions given scorer list\n",
    "def score_predictions_fancy(y_e, y_hat, model_name='', scorers=None, names=None):\n",
    "    if type(scorers)==type(None):\n",
    "        scorers = [mae, mse, mape, wape, r2]; names=scrs\n",
    "    scores = [scorer(y_e, y_hat) for scorer in scorers]\n",
    "    return pd.Series(scores, name=model_name, index=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating model predictions given scorer list\n",
    "def score_predictions_custom(y_e, y_hat, scorers=None):\n",
    "    if type(scorers)==type(None):\n",
    "        scorers = [mae, mse, mape, wape, r2]; names=['mae', 'mse', 'mape', 'wape', 'r2']\n",
    "    return [scorer(y_e, y_hat) for scorer in scorers]\n",
    "\n",
    "def score_by_product(Y_e, Y_hat, indexes, model_name, key='product_type', scorers=None, scorers_names=['mae', 'mse', 'mape', 'wape', 'r2']):\n",
    "    prod_scrs = []\n",
    "    for product in indexes.keys():\n",
    "        prod_index = indexes[product]\n",
    "        prod_scrs.append([ product ] + score_predictions_custom(Y_e.loc[prod_index], Y_hat.loc[prod_index], scorers=scorers))\n",
    "    prod_scrs = pd.DataFrame(prod_scrs, columns=[key]+scorers_names)\n",
    "    return prod_scrs\n",
    "\n",
    "def score_model_predictions(Y_hat, Y_e, indexes, model_name, by='product_type', scorers=None, scorers_names=['mae', 'mse', 'mape', 'wape', 'r2']):\n",
    "    model_scrs = pd.Series(score_predictions_custom(Y_e, Y_hat, scorers=scorers), index=scorers_names).to_frame().rename(columns={0: model_name}).T;\n",
    "    prod_scrs = score_by_product(Y_e, Y_hat, indexes, model_name, key=by, scorers=scorers, scorers_names=scorers_names)\n",
    "    return model_scrs, prod_scrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 0.1 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'area'\n",
    "target_years = ['01/01/2016', '01/01/2017']\n",
    "prodtypes = ['permanent', 'temporary', 'pasture']\n",
    "prods = [\n",
    "    'Rice', 'Beans', 'Cassava',\n",
    "    'Corn', 'Soy', 'Sorghum',\n",
    "    'Cocoa', 'Palm oil', 'Açaí',\n",
    "    'Livestock', 'Others-temporary', 'Others-permanent'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Loaded 1107 files.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/historical-database-clean.csv')\n",
    "X_full = pd.read_csv('data/raw_series.csv', index_col=0)\n",
    "X = pd.read_csv('data/series.csv', index_col=0)\n",
    "raw_series = tools.preprocess.load_series(path='data/series/')\n",
    "series = tools.preprocess.load_series(path='data/series clean/')\n",
    "keys = list(series.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.loc[range(42)].copy()\n",
    "X_test = X.loc[[42, 43]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Extracting test data (2016 and 2017)\n",
    "Y_e = tools.preprocess().test_data(series, data, keys=keys)\n",
    "data_e = data.loc[Y_e.index].copy()\n",
    "#### Extracting test index for each category in product_type-product combinations\n",
    "prod_indexes = tools.category_index.get_ctgr_combs_indexes(data_e, prods)\n",
    "#### Extracting test index for each category in product_type\n",
    "prodtype_indexes = tools.category_index.get_ctgrs_indexes(data_e)\n",
    "#### Mapping between the series test indexes and the series key\n",
    "key_test_index_map = tools.category_index.get_key_index_test_map(series, Y_e)\n",
    "\n",
    "int_year = {'01/01/2016': 42, '01/01/2017': 43}\n",
    "key_year_test_index_map = {42: {}, 43: {}}\n",
    "for index, key in key_test_index_map.items():\n",
    "    row = data.loc[index]\n",
    "    key_year_test_index_map[int_year[row['year']]][key] = index\n",
    "\n",
    "index2016, index2017 = [], []\n",
    "for key in keys:\n",
    "    for year, index_list in zip([42, 43], [index2016, index2017]):\n",
    "        try:\n",
    "            index_list.append(key_year_test_index_map[year][key])\n",
    "        except: \n",
    "            index_list.append(np.nan)\n",
    "year_key_index = pd.Series(index2016 + index2017)\n",
    "\n",
    "x_test = pd.Series(X_test.values.reshape(-1), index=year_key_index).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    55.0\n",
       "Name: area, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Setting label encoded index\n",
    "LE = le().fit(data['year'])\n",
    "\n",
    "lab_series = {}\n",
    "for key in keys:\n",
    "    lab_series[key] = series[key].set_index(LE.transform(series[key]['year']))[target].copy()\n",
    "\n",
    "#### Train test split for label indexed series\n",
    "tt_lab_series = {}\n",
    "for key in keys:\n",
    "    msk = lab_series[key].index.isin([42, 43])\n",
    "    tt_lab_series[key] = {'train': lab_series[key][msk==False].copy(), 'test': lab_series[key][msk].copy()}\n",
    "\n",
    "tt_lab_series[keys[0]]['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparing specialized models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric criterias settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_map = {'e': 0, 'estd': 0, 'max_error': 0, 'mae': 0, 'mse': 0, 'medae': 0, 'mape': 0, 'wape': 0, 'r2': -1, 'evs': -1}\n",
    "scorers_names = ['e','estd','max_error','mae','mse','medae','mape','wape','r2','evs']\n",
    "scorers = [e, estd, me, mae, mse, medae, mape, wape, r2, evs]\n",
    "scrs = ['mae', 'mse', 'mape', 'wape', 'r2']\n",
    "sel_scrs = scorers_names #scrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling serie to test individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrived train and test datasets\n",
    "train = tt_lab_series[full_keys[0]]['train']\n",
    "test = tt_lab_series[full_keys[0]]['test']\n",
    "# train and test prediction intervals\n",
    "x_train_min, x_train_max, x_test_min, x_test_max = train_test_min_max(train, test)\n",
    "# x_train_min_year, x_train_max_year, x_test_min_year, x_test_max_year = train_test_min_max_year(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 41, 42, 43)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_min, x_train_max, x_test_min, x_test_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## AR example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutoReg_predict(train, lags=1, x_min=42, x_max=43):\n",
    "    if len(train)<=3: return np.array([np.nan for i in range(2)])\n",
    "    model = AutoReg(train, lags=lags)\n",
    "    model_fit = model.fit()\n",
    "    # make prediction\n",
    "    return model_fit.predict(x_min, x_max)\n",
    "\n",
    "def AutoReg_predict_series(tt_series, keys, lags=1):\n",
    "    yhat = {}\n",
    "    for key in keys:\n",
    "        co(wait=True); print(f'{keys.index(key)}/{len(keys)}')\n",
    "        testset = tt_series[key]['test']\n",
    "        trainset = tt_series[key]['train']\n",
    "        yhat[key] = AutoReg_predict(trainset.values, lags=lags, x_min=len(trainset), x_max=len(trainset)+1)\n",
    "        for i, ind in zip([0, 1], [42, 43]):\n",
    "            if ind not in testset.index:\n",
    "                yhat[key][i] = np.nan\n",
    "                \n",
    "    return pd.DataFrame(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat_AutoReg = AutoReg_predict_series(tt_lab_series, keys, lags=1)\n",
    "# yhat = pd.Series(Yhat_AutoReg.values.reshape(-1), index=year_key_index).loc[x_test.index].fillna(0)\n",
    "# scrs, prod_scrs = score_model_predictions(x_test, yhat, prodtype_indexes, model_name='AR', by='product_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_scrs, ar_prod_scrs = reshape_score_predictions(\n",
    "    Yhat_AutoReg, x_test, year_key_index, prodtype_indexes,\n",
    "    fill_na=0, model_name='AR', col_name='product_type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>wape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1409.396107</td>\n",
       "      <td>2.949627e+07</td>\n",
       "      <td>8.753407e+17</td>\n",
       "      <td>0.06951</td>\n",
       "      <td>0.996326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mae           mse          mape     wape        r2\n",
       "AR  1409.396107  2.949627e+07  8.753407e+17  0.06951  0.996326"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>wape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temporary</td>\n",
       "      <td>936.629170</td>\n",
       "      <td>2.622775e+07</td>\n",
       "      <td>2.495408e+17</td>\n",
       "      <td>0.468343</td>\n",
       "      <td>0.727617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>permanent</td>\n",
       "      <td>784.828075</td>\n",
       "      <td>1.096750e+07</td>\n",
       "      <td>2.576952e+18</td>\n",
       "      <td>0.712266</td>\n",
       "      <td>0.051423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pasture</td>\n",
       "      <td>4860.063332</td>\n",
       "      <td>8.394538e+07</td>\n",
       "      <td>7.417297e-02</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.998061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_type          mae           mse          mape      wape        r2\n",
       "0    temporary   936.629170  2.622775e+07  2.495408e+17  0.468343  0.727617\n",
       "1    permanent   784.828075  1.096750e+07  2.576952e+18  0.712266  0.051423\n",
       "2      pasture  4860.063332  8.394538e+07  7.417297e-02  0.033993  0.998061"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_prod_scrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ARIMA example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_predict(train, order=(1,1,1), x_min=42, x_max=43):\n",
    "    if len(train)<=2: return np.array([np.nan for i in range(2)])\n",
    "    # fit model\n",
    "    model = ARIMA(train, order=order)\n",
    "    model_fit = model.fit()\n",
    "    # make prediction\n",
    "    return model_fit.predict(x_min, x_max)\n",
    "\n",
    "def arima_predict_series(tt_series, keys, order=(1,1,1)):\n",
    "    yhat_arima = {}\n",
    "    for key in keys:\n",
    "        co(wait=True); print(f'{keys.index(key)}/{len(keys)}')\n",
    "        testset = tt_series[key]['test']\n",
    "        trainset = tt_series[key]['train']\n",
    "        yhat_arima[key] = arima_predict(trainset.values, order=order, x_min=len(trainset), x_max=len(trainset)+1)\n",
    "        for i, ind in zip([0, 1], [42, 43]):\n",
    "            if ind not in testset.index:\n",
    "                yhat_arima[key][i] = np.nan\n",
    "    \n",
    "    return pd.DataFrame(yhat_arima, index=[42, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1107\n"
     ]
    }
   ],
   "source": [
    "Yhat_arima = arima_predict_series(tt_lab_series, keys, order=(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_scrs, arima_prod_scrs = reshape_score_predictions(\n",
    "    Yhat_arima, x_test, year_key_index, prodtype_indexes,\n",
    "    fill_na=0, model_name='AR', col_name='product_type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>wape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1181.622571</td>\n",
       "      <td>1.554773e+07</td>\n",
       "      <td>7.301628e+17</td>\n",
       "      <td>0.059485</td>\n",
       "      <td>0.99798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mae           mse          mape      wape       r2\n",
       "AR  1181.622571  1.554773e+07  7.301628e+17  0.059485  0.99798"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>wape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temporary</td>\n",
       "      <td>666.260016</td>\n",
       "      <td>7.585131e+06</td>\n",
       "      <td>4.335110e+15</td>\n",
       "      <td>0.391854</td>\n",
       "      <td>0.849011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>permanent</td>\n",
       "      <td>741.861525</td>\n",
       "      <td>1.082450e+07</td>\n",
       "      <td>2.571330e+18</td>\n",
       "      <td>0.713232</td>\n",
       "      <td>-0.078549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pasture</td>\n",
       "      <td>4424.198986</td>\n",
       "      <td>6.118807e+07</td>\n",
       "      <td>6.838385e-02</td>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.998520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_type          mae           mse          mape      wape        r2\n",
       "0    temporary   666.260016  7.585131e+06  4.335110e+15  0.391854  0.849011\n",
       "1    permanent   741.861525  1.082450e+07  2.571330e+18  0.713232 -0.078549\n",
       "2      pasture  4424.198986  6.118807e+07  6.838385e-02  0.031309  0.998520"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_prod_scrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMAX example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrived train and test datasets\n",
    "def predict_score_SARIMAX(series, key, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0), exog_train=None, exog_test=None):\n",
    "    train = series[key]['train']\n",
    "    test = series[key]['test']\n",
    "    if len(train)<=2: return np.array([np.nan for i in range(2)])\n",
    "    # fit model\n",
    "    model = SARIMAX(train.values, exog=exog_train, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    # make prediction\n",
    "    yhat = model_fit.predict(len(train), len(train)+1, exog=exog_test)\n",
    "    for i, ind in zip([0, 1], [42, 43]):\n",
    "        if ind not in test.index:\n",
    "            yhat[i] = np.nan\n",
    "    return yhat\n",
    "\n",
    "def predict_score_series_SARIMAX(series, keys):\n",
    "    yhat = []\n",
    "    for key in keys:\n",
    "        co(wait=True); print(f'{keys.index(key)}/{len(keys)}')\n",
    "        yhat_sarimax = predict_score_SARIMAX(tt_lab_series, key, order=(1, 1, 1), seasonal_order=(0,0,0,0))\n",
    "        yhat.append(yhat_sarimax)\n",
    "    yhat = pd.DataFrame(yhat).T; yhat.columns=keys\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1107\n"
     ]
    }
   ],
   "source": [
    "Yhat_sarimax = predict_score_series_SARIMAX(tt_lab_series, keys[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax_scrs, sarimax_prod_scrs = reshape_score_predictions(\n",
    "    Yhat_sarimax, x_test, year_key_index, prodtype_indexes,\n",
    "    fill_na=0, model_name='AR', col_name='product_type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>wape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1181.622571</td>\n",
       "      <td>1.554773e+07</td>\n",
       "      <td>7.301628e+17</td>\n",
       "      <td>0.059485</td>\n",
       "      <td>0.99798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mae           mse          mape      wape       r2\n",
       "AR  1181.622571  1.554773e+07  7.301628e+17  0.059485  0.99798"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarimax_scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>wape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temporary</td>\n",
       "      <td>666.260016</td>\n",
       "      <td>7.585131e+06</td>\n",
       "      <td>4.335110e+15</td>\n",
       "      <td>0.391854</td>\n",
       "      <td>0.849011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>permanent</td>\n",
       "      <td>741.861525</td>\n",
       "      <td>1.082450e+07</td>\n",
       "      <td>2.571330e+18</td>\n",
       "      <td>0.713232</td>\n",
       "      <td>-0.078549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pasture</td>\n",
       "      <td>4424.198986</td>\n",
       "      <td>6.118807e+07</td>\n",
       "      <td>6.838385e-02</td>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.998520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_type          mae           mse          mape      wape        r2\n",
       "0    temporary   666.260016  7.585131e+06  4.335110e+15  0.391854  0.849011\n",
       "1    permanent   741.861525  1.082450e+07  2.571330e+18  0.713232 -0.078549\n",
       "2      pasture  4424.198986  6.118807e+07  6.838385e-02  0.031309  0.998520"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarimax_prod_scrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAR example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_VAR(X_train, steps=2, exog_train=None, exog_test=None):\n",
    "    # fit model\n",
    "    model = VAR(X_train, exog=exog_train)\n",
    "    model_fit = model.fit()\n",
    "    # make prediction\n",
    "    yhat = model_fit.forecast(model_fit.y, steps=steps, exog_future=exog_test)\n",
    "    return pd.DataFrame(yhat, columns=X_train.columns, index=range(len(X_train), len(X_train)+steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1974-01-01', '1975-01-01', '1976-01-01', '1977-01-01',\n",
       "               '1978-01-01', '1979-01-01', '1980-01-01', '1981-01-01',\n",
       "               '1982-01-01', '1983-01-01', '1984-01-01', '1985-01-01',\n",
       "               '1986-01-01', '1987-01-01', '1988-01-01', '1989-01-01',\n",
       "               '1990-01-01', '1991-01-01', '1992-01-01', '1993-01-01',\n",
       "               '1994-01-01', '1995-01-01', '1996-01-01', '1997-01-01',\n",
       "               '1998-01-01', '1999-01-01', '2000-01-01', '2001-01-01',\n",
       "               '2002-01-01', '2003-01-01', '2004-01-01', '2005-01-01',\n",
       "               '2006-01-01', '2007-01-01', '2008-01-01', '2009-01-01',\n",
       "               '2010-01-01', '2011-01-01', '2012-01-01', '2013-01-01',\n",
       "               '2014-01-01', '2015-01-01', '2016-01-01', '2017-01-01'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = X.copy(); x_train.index = pd.DatetimeIndex(np.array([str(year) for year in range(1974, 2018)], dtype='datetime64[Y]'))\n",
    "x_train = X_train.iloc[14:].fillna(0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VARResults' object has no attribute 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-278-30840483342c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# make prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog_future\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\wrapper.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_attrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VARResults' object has no attribute 'y'"
     ]
    }
   ],
   "source": [
    "model = VAR(x_train)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.forecast(model_fit.y, steps=2, exog_future=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat_var = predict_VAR(X_train.loc[14:].fillna(0), steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_scrs, var_prod_scrs = reshape_score_predictions(\n",
    "    Yhat_var, x_test, year_key_index, prodtype_indexes,\n",
    "    fill_na=0, model_name='AR', col_name='product_type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>wape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>1409.396107</td>\n",
       "      <td>2.949627e+07</td>\n",
       "      <td>8.753407e+17</td>\n",
       "      <td>0.06951</td>\n",
       "      <td>0.996326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mae           mse          mape     wape        r2\n",
       "AR  1409.396107  2.949627e+07  8.753407e+17  0.06951  0.996326"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>mape</th>\n",
       "      <th>wape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temporary</td>\n",
       "      <td>936.629170</td>\n",
       "      <td>2.622775e+07</td>\n",
       "      <td>2.495408e+17</td>\n",
       "      <td>0.468343</td>\n",
       "      <td>0.727617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>permanent</td>\n",
       "      <td>784.828075</td>\n",
       "      <td>1.096750e+07</td>\n",
       "      <td>2.576952e+18</td>\n",
       "      <td>0.712266</td>\n",
       "      <td>0.051423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pasture</td>\n",
       "      <td>4860.063332</td>\n",
       "      <td>8.394538e+07</td>\n",
       "      <td>7.417297e-02</td>\n",
       "      <td>0.033993</td>\n",
       "      <td>0.998061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_type          mae           mse          mape      wape        r2\n",
       "0    temporary   936.629170  2.622775e+07  2.495408e+17  0.468343  0.727617\n",
       "1    permanent   784.828075  1.096750e+07  2.576952e+18  0.712266  0.051423\n",
       "2      pasture  4860.063332  8.394538e+07  7.417297e-02  0.033993  0.998061"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_prod_scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mVAR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Fit VAR(p) process and do lag order selection\n",
       "\n",
       ".. math:: y_t = A_1 y_{t-1} + \\ldots + A_p y_{t-p} + u_t\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "endog : array_like\n",
       "    2-d endogenous response variable. The independent variable.\n",
       "exog : array_like\n",
       "    2-d exogenous variable.\n",
       "dates : array_like\n",
       "    must match number of rows of endog\n",
       "\n",
       "References\n",
       "----------\n",
       "Lütkepohl (2005) New Introduction to Multiple Time Series Analysis\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\luisr\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VAR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VARMA example (not working for all series  at once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "def predict_VARMAX(X_train, steps=2, order=(1, 1)):\n",
    "    model = VARMAX(X_train, order=order)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    # make prediction\n",
    "    return model_fit.forecast(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\varmax.py:161: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
      "  warn('Estimation of VARMA(p,q) models is not generically robust,'\n",
      "C:\\Users\\luisr\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:567: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warn(\"Maximum Likelihood optimization failed to converge. \"\n",
      "C:\\Users\\luisr\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\varmax.py:161: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
      "  warn('Estimation of VARMA(p,q) models is not generically robust,'\n"
     ]
    }
   ],
   "source": [
    "Yhat_varma = predict_VARMAX(X_train.iloc[:, :2], steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = Yhat_varma.values.reshape(-1)\n",
    "x_test = X_test.iloc[:, :2].values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.14127815762053,\n",
       " 311.53917647104606,\n",
       " 0.26099213000069693,\n",
       " 0.30739831947650365,\n",
       " 0.6276516901817631]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_predictions(x_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VARMAX example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = VARMAX(X_train.iloc[:, 1:5], exog=X_train.iloc[:, 6:10], order=(1, 1))\n",
    "model_fit = model.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\varmax.py:161: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
      "  warn('Estimation of VARMA(p,q) models is not generically robust,'\n",
      "C:\\Users\\luisr\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\varmax.py:161: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
      "  warn('Estimation of VARMA(p,q) models is not generically robust,'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0307883b5d063703-Others-temporary</th>\n",
       "      <th>03e477d4ede00e89-Others-permanent</th>\n",
       "      <th>03e477d4ede00e89-Others-temporary</th>\n",
       "      <th>051e9cc7d7636816-Others-permanent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6.485532</td>\n",
       "      <td>506.906915</td>\n",
       "      <td>37.889265</td>\n",
       "      <td>15.258532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3.001125</td>\n",
       "      <td>504.499522</td>\n",
       "      <td>-11.166915</td>\n",
       "      <td>14.415549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0307883b5d063703-Others-temporary  03e477d4ede00e89-Others-permanent  \\\n",
       "42                           6.485532                         506.906915   \n",
       "43                           3.001125                         504.499522   \n",
       "\n",
       "    03e477d4ede00e89-Others-temporary  051e9cc7d7636816-Others-permanent  \n",
       "42                          37.889265                          15.258532  \n",
       "43                         -11.166915                          14.415549  "
      ]
     },
     "execution_count": 1036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction\n",
    "Yhat_varmax = model_fit.forecast(exog=X_test.iloc[:, 6:10], steps=2)\n",
    "Yhat_varmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45.956374751841096,\n",
       " 7202.773487870832,\n",
       " 0.9593998911077435,\n",
       " 0.3412740858180361,\n",
       " 0.8436123022543823]"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_predictions_custom(Yhat_varmax.values.reshape(-1), X_test.iloc[:, 1:5].values.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoArima Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_series_auto_arima(series, keys, n_periods=2):\n",
    "    Yhat, scores = [], []\n",
    "    for key in keys:\n",
    "        co(wait=True); print(f'{keys.index(key)}/{len(keys)}')\n",
    "        train = series[key]['train']\n",
    "        test = series[key]['test']\n",
    "        if len(train)<=2:\n",
    "            Yhat.append(pd.Series([np.nan for i in range(2)], index=[42,43], name=key))\n",
    "            continue\n",
    "        model = auto_arima(y=train.values, seasonal=False, stepwise=True)\n",
    "        yhat = model.predict(n_periods=n_periods)\n",
    "        for i, ind in zip([0, 1], [42, 43]):\n",
    "            if ind not in test.index:\n",
    "                yhat[i] = np.nan\n",
    "        Yhat.append(pd.Series(yhat, index=[42,43], name=key))\n",
    "#         scores.append(score_predictions_fancy(test, yhat, model_name=key))\n",
    "    return pd.concat(Yhat, 1)#, pd.concat(scores, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106/1107\n"
     ]
    }
   ],
   "source": [
    "Yhat_autoarima =  predict_series_auto_arima(tt_lab_series, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_predictions_fancy(Yhat_autoarima.values.reshape(-1), X_test.values.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBATS Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tbats(train, steps):\n",
    "    model_tbats = TBATS(seasonal_periods=(12, 28),\\\n",
    "                  use_arma_errors=False,\\\n",
    "                  use_box_cox=False,\\\n",
    "                  n_jobs=1,\\\n",
    "                  use_trend=None,\\\n",
    "                  use_damped_trend=None)\\\n",
    "                  .fit(train)\n",
    "\n",
    "    return model_tbats.forecast(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_series_tbats(series, keys, steps=2):\n",
    "    Yhat, scores = [], []\n",
    "    for key in keys:\n",
    "        co(wait=True); print(f'{keys.index(key)}/{len(keys)}')\n",
    "        train = series[key]['train']\n",
    "        test = series[key]['test']\n",
    "        yhat = predict_tbats(train, steps=len(test))\n",
    "        Yhat.append(pd.Series(yhat, index=range(len(train), len(train)+steps), name=key))\n",
    "        scores.append(score_predictions_fancy(test, yhat, model_name=key))\n",
    "    return pd.concat(Yhat, 1), pd.concat(scores, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/286\n"
     ]
    }
   ],
   "source": [
    "Yhat_tbats, scores = predict_series_tbats(tt_lab_series, full_keys[:], steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mae     4.257729e+02\n",
       "mse     1.108583e+06\n",
       "mape    1.397161e+17\n",
       "wape    8.801666e-01\n",
       "r2      4.817428e-01\n",
       "Name: , dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_predictions_fancy(X_test.iloc[:, :].values.reshape(-1), Yhat_tbats.values.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Yhat_AutoReg', 'Yhat_arima', 'Yhat_sarimax', 'Yhat_var', 'Yhat_autoarima']\n",
    "model_predictions = [Yhat_AutoReg, Yhat_arima, Yhat_sarimax, Yhat_var, Yhat_autoarima]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_i = pd.concat([pd.Series(model.values.reshape(-1), name=model_names[i]) for i, model in enumerate(model_predictions)], 1)\n",
    "y_hat_i.index = keys*2\n",
    "y_hat_i['year'] = ['01/01/2016']*len(keys) + ['01/01/2017']*len(keys)\n",
    "y_hat_i = y_hat_i.reset_index(drop=False).rename(columns={'index': 'key'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_hat_i.to_csv('evaluation/specialized_models_predictions.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_test.values.reshape(-1)\n",
    "models_scrs = pd.concat([score_predictions_fancy(x_test, y_hat_i[model], model_name=model) for model in y_hat_i], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yhat_AutoReg</th>\n",
       "      <th>Yhat_arima</th>\n",
       "      <th>Yhat_sarimax</th>\n",
       "      <th>Yhat_var</th>\n",
       "      <th>Yhat_autoarima</th>\n",
       "      <th>Yhat_tbats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>1.150449e+02</td>\n",
       "      <td>1.042907e+02</td>\n",
       "      <td>1.042907e+02</td>\n",
       "      <td>1.293528e+13</td>\n",
       "      <td>1.098114e+02</td>\n",
       "      <td>4.257729e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>1.168531e+05</td>\n",
       "      <td>1.108632e+05</td>\n",
       "      <td>1.108632e+05</td>\n",
       "      <td>1.031415e+27</td>\n",
       "      <td>1.157460e+05</td>\n",
       "      <td>1.108583e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>1.643048e+16</td>\n",
       "      <td>9.369222e+15</td>\n",
       "      <td>9.369222e+15</td>\n",
       "      <td>5.444631e+27</td>\n",
       "      <td>9.376776e+15</td>\n",
       "      <td>1.397161e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wape</th>\n",
       "      <td>2.378232e-01</td>\n",
       "      <td>2.155918e-01</td>\n",
       "      <td>2.155918e-01</td>\n",
       "      <td>2.674009e+10</td>\n",
       "      <td>2.270043e-01</td>\n",
       "      <td>8.801666e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>9.453717e-01</td>\n",
       "      <td>9.481720e-01</td>\n",
       "      <td>9.481720e-01</td>\n",
       "      <td>-4.821817e+20</td>\n",
       "      <td>9.458893e-01</td>\n",
       "      <td>4.817428e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Yhat_AutoReg    Yhat_arima  Yhat_sarimax      Yhat_var  Yhat_autoarima  \\\n",
       "mae   1.150449e+02  1.042907e+02  1.042907e+02  1.293528e+13    1.098114e+02   \n",
       "mse   1.168531e+05  1.108632e+05  1.108632e+05  1.031415e+27    1.157460e+05   \n",
       "mape  1.643048e+16  9.369222e+15  9.369222e+15  5.444631e+27    9.376776e+15   \n",
       "wape  2.378232e-01  2.155918e-01  2.155918e-01  2.674009e+10    2.270043e-01   \n",
       "r2    9.453717e-01  9.481720e-01  9.481720e-01 -4.821817e+20    9.458893e-01   \n",
       "\n",
       "        Yhat_tbats  \n",
       "mae   4.257729e+02  \n",
       "mse   1.108583e+06  \n",
       "mape  1.397161e+17  \n",
       "wape  8.801666e-01  \n",
       "r2    4.817428e-01  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_scrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds(Yhat, keys):\n",
    "    fig = plt.figure(figsize=(12, 10), tight_layout=True)\n",
    "    n_rows = len(keys)//3\n",
    "    axes = fig.subplots(n_rows,3)\n",
    "    cnt = -1\n",
    "    for axs in axes:\n",
    "        for i in range(len(axs)):\n",
    "            if cnt<len(keys)-1:\n",
    "                ax = axs[i]\n",
    "                cnt+=1; key=keys[cnt]\n",
    "                train = tt_lab_series[key]['train']\n",
    "                test = tt_lab_series[key]['test']\n",
    "                yhat = Yhat[key]\n",
    "                train.plot(ax=ax)\n",
    "                test.plot(ax=ax)\n",
    "                yhat.plot(ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
