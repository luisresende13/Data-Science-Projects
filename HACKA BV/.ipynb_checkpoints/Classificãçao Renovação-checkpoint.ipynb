{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Carregando dados\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns; sns.set()\n",
    "\n",
    "from google.cloud.bigquery import Client, QueryJobConfig\n",
    "client = Client()\n",
    "query = \"\"\"SELECT * FROM `hacka-dados.hacka_dados.tabela_dados_hacka`\"\"\"\n",
    "job = client.query(query)\n",
    "df = job.to_dataframe()\n",
    "\n",
    "## Limpeza\n",
    "\n",
    "#### Notação de células vazias\n",
    "\n",
    "def uniform_missing_values(df, notacoes=['nan', '']):\n",
    "    obj_cols = df.columns[df.dtypes=='object']\n",
    "    for col in obj_cols:\n",
    "        for value in notacoes:\n",
    "            df[col] = df[col].replace(value, np.nan)\n",
    "    return df\n",
    "\n",
    "df = uniform_missing_values(df, notacoes=['nan', ''])\n",
    "\n",
    "# Descomente para conferir valores diferentes para notações ou conferir substituição (se já foi feita).\n",
    "# for col in obj_cols: print(f'{col}: {df[col].unique()}'); print()\n",
    "\n",
    "#### Células vazias e nulas por coluna\n",
    "\n",
    "empty = df.isna().sum().nlargest(df.shape[1]) / df.shape[0]\n",
    "null = (df==0).sum().nlargest(df.shape[1]) / df.shape[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "empty.plot()\n",
    "null.plot() # descomente para incluir valores nulos\n",
    "(empty+null.loc[empty.index]).plot() # descomente para incluir valores nulos\n",
    "ax.set(\n",
    "    xticks=[],\n",
    "    xlabel='Colunas',\n",
    "    ylabel='Células (%)',\n",
    "    title='Células vazias e nulas por coluna (%)',\n",
    ")\n",
    "ax.legend(['Vazios (%)', 'Nulos (%)', 'Vazios+Nulos]); plt.show()\n",
    "\n",
    "null.head(3)\n",
    "\n",
    "#### Células vazias e nulas por linha\n",
    "\n",
    "empty = df.isna().sum(1).nlargest(df.shape[0]) / df.shape[1]\n",
    "null = (df==0).sum(1).nlargest(df.shape[0]) / df.shape[1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "ax.plot(np.percentile(empty, range(100)))\n",
    "ax.plot(np.percentile(null, range(100)))\n",
    "ax.set(\n",
    "    xticks=[],\n",
    "    xlabel='Células (%)',\n",
    "    ylabel='Linhas (%)',\n",
    "    title='Percentil vazios/nulos por linha (%/%)',\n",
    ")\n",
    "ax.legend(['Vazios (%)', 'Nulos (%) dentre não vazios']); plt.show()\n",
    "\n",
    "---\n",
    "## Modelagem preliminar de classificação da renovação\n",
    "\n",
    "# pessoal não se assuntem, copiei de outro projeto meu pra datasets desbalanceados\n",
    "\n",
    "### Transformação de dados\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "# extract columns for each data type\n",
    "int_cols, obj_cols, float_cols = (\n",
    "    data.select_dtypes([datatype]).columns.tolist() for datatype in ('int64', 'object', 'float')\n",
    ")\n",
    "\n",
    "# fill missing values for float columns\n",
    "for col in float_cols:\n",
    "    # data[col].fillna(data[col].mean(), inplace=True)\n",
    "    data[col].fillna(0, inplace=True)\n",
    "\n",
    "# import preprocessing functions\n",
    "from sklearn.preprocessing import LabelEncoder as le, MinMaxScaler as mms\n",
    "\n",
    "#### Label Encode Categorical (+ Integer) Columns\n",
    "for col in obj_cols + int_cols:\n",
    "    data[col] = le().fit_transform(data[col]) # fill missing values automatically\n",
    "\n",
    "#### Scale Float Columns\n",
    "data[float_cols] = mms().fit_transform(data[float_cols]) # eliminates negative values\n",
    "\n",
    "### Defina a variável dependente\n",
    "\n",
    "target = 'fl_renovou'\n",
    "\n",
    "# define X and Y\n",
    "Y = data[target].copy()\n",
    "X = data.drop(target, 1).copy()\n",
    "    \n",
    "# target variable classes' count\n",
    "display(Y.value_counts().rename('Target variable class count').to_frame())\n",
    "\n",
    "### Under sampling\n",
    "\n",
    "from módulos.splitter import UnderSampleSplit\n",
    "from módulos.cv_samplers import print_cls_cnt\n",
    "\n",
    "uss = UnderSampleSplit(\n",
    "    train_size=0.8, train_prct=1,\n",
    "    test_size=0.2, test_prct=None,\n",
    "    replace=False, shuffle=True,\n",
    "    random_state=None\n",
    ")\n",
    "train_index, test_index = uss.train_test_undersample(Y, random_state=0)\n",
    "xt, xe, yt, ye = X.loc[train_index], X.loc[test_index], Y.loc[train_index], Y.loc[test_index], \n",
    "print_cls_cnt(Y, train_index, test_index)\n",
    "\n",
    "cv = uss.split(Y, n_splits=10, param_list=None) # under sampling \n",
    "# for i in range(5): cv[i] = (cv[i][0], test_index) # to force same test set\n",
    "\n",
    "left_index = set(Y.index).difference(train_index)\n",
    "\n",
    "### Modelos e metricas de avaliação\n",
    "\n",
    "# define model collection\n",
    "from sklearn.utils import all_estimators\n",
    "classifiers = dict(all_estimators('classifier'))\n",
    "\n",
    "#### define score functions\n",
    "import sklearn.metrics as metrics\n",
    "recall_0, recall_1 = (metrics.make_scorer(metrics.recall_score, pos_label=label) for label in (0,1))\n",
    "precision_0, precision_1 = (metrics.make_scorer(metrics.precision_score, pos_label=label) for label in (0,1))\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy', 'f1_macro': 'f1_macro',\n",
    "    'recall_macro': 'recall_macro', 'precision_macro': 'precision_macro',\n",
    "    'recall_0': recall_0, 'recall_1': recall_1,\n",
    "    'precision_0': precision_0, 'precision_1': precision_1,\n",
    "}\n",
    "\n",
    "### Comparando shuffle splits aleatorios\n",
    "\n",
    "modelname = 'GradientBoostingClassifier' # 'DecisionTreeClassifier', 'LinearSVC', 'LogisticRegression',\n",
    "Model = classifiers[modelname]\n",
    "model = Model(n_estimators=100, random_state=0)\n",
    "\n",
    "#### score cross validation splits\n",
    "from sklearn.model_selection import cross_validate\n",
    "model_scrs = cross_validate(\n",
    "    model, X, Y, cv=cv,\n",
    "    scoring=scoring,\n",
    "    groups=None,\n",
    "    n_jobs=-1,\n",
    "    pre_dispatch='all',\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "scrs_df = pd.DataFrame({scr: model_scrs['test_'+scr] for scr in scoring})\n",
    "scrs_df.index.name='cv split'\n",
    "\n",
    "#### Scores médios\n",
    "\n",
    "scrs_df.agg([np.mean, np.var])#.to_frame('mean').T\n",
    "\n",
    "#### Scores por split\n",
    "\n",
    "scrs_df\n",
    "\n",
    "### Curvas de aprendizado Shuffle splits\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "order=2\n",
    "train_sizes = np.linspace(0.1, 1, 11)**order\n",
    "# Calculate recall learning curves per class\n",
    "lc_0, lc_1 = ( learning_curve(\n",
    "    model,\n",
    "    X, Y,\n",
    "    train_sizes=train_sizes,\n",
    "    cv=cv,\n",
    "    scoring=[recall_0, recall_1][i],\n",
    "    groups=None,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    "    verbose=5,\n",
    "    n_jobs=-1,\n",
    "    pre_dispatch='all',\n",
    "    error_score='raise'\n",
    ") for i in (0, 1) )\n",
    "\n",
    "### Plot recall learning curves\n",
    "for lc_df, cls_label in zip([lc_0, lc_1], ['class 0', 'class 1']):\n",
    "    train_lc, test_lc = (pd.DataFrame(lc_df[i], index=lc_df[0]) for i in [1,2])\n",
    "    fig, ax = plt.subplots(1,2, figsize=(9,3), tight_layout=True)\n",
    "    ax[0].plot(train_lc)\n",
    "    ax[1].plot(test_lc)\n",
    "    for i, label in zip([0,1], ['train set', 'test set']):\n",
    "        ax[i].set(\n",
    "            title=f'Cross Validation Splits´ Learning Curves - {label}',\n",
    "            ylabel=f'Recall - {cls_label}',\n",
    "            xlabel='Train size (nº of samples)'\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "---\n",
    "#### Instalações\n",
    "\n",
    "!pip install imblearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
