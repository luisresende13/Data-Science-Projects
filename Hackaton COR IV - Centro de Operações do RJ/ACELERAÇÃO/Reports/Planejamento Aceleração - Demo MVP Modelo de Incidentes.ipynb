{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLANEJAMENTO DO ESTUDO DE VIABILIDADE + CONSTRUÇÃO DE DEMO DE MODELO DE INCIDENTES\n",
    "\n",
    "### MODELO PREDITIVO DO RISCO DE OCORRÊNCIA DE INCIDENTES NA ÁREA URBANA DO RIO DE JANEIRO, CAUSADOS POR EVENTOS HIDROMETEOROLÓGICOS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Cronograma\n",
    "\n",
    "* 14/08 à 21/09 - Etapa 1 (uma semana) - Semana atual\n",
    "* 22/08 à 29/09 - Etapa 1 (uma semana) - Início da fase de aceleração\n",
    "* 30/08 à 06/09 - Etapa 2 (uma semana)\n",
    "* 07/09 à 14/09 - Etapa 3 (uma semana)\n",
    "* 15/09 à 22/09 - Etapa 4 (uma semana)\n",
    "* 23/09 à 30/09 - Etapa 5 (uma semana)\n",
    "* 31/09 à 06/10 - Etapa 6 (uma semana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Etapas\n",
    "\n",
    "0. Análise de dados exploratória do Sistema Comando: Determinar potencial de extração de catologo de incidentes para modelagem.\n",
    "\n",
    "1. Dados (lista e acesso) e estudo de integração ao datalake e demais fontes (via mentoria).\n",
    "    \n",
    "3. Análise de dados exploratória do datalake do COR-Rio: Avaliar a qualidade dos dados, o potencial preditivo (correlações), e possíveis arquiteturas de modelo.\n",
    "\n",
    "4. Estudo e desenvolvimento da arquitetura do modelo.\n",
    "\n",
    "5. Estudo de engenharia de features\n",
    "\n",
    "6. Avaliação do modelo e Demo MVP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Principais produtos de cada etapa\n",
    "\n",
    "0. Análise exploratória de dados do Sistema Comando, para determinar potencial de construção de catologo de incidentes para modelagem.\n",
    "    1. catalogo histórico de ocorrências para modelagem.\n",
    "    2. Relatório de qualidade do catalogo.\n",
    "\n",
    "\n",
    "1. Estudo do datalake do COR-Rio e demais fontes (adquirir dados).\n",
    "    1. Lista de dados do COR-RIo datalake no Google Cloud (tempo real e fixos).\n",
    "    2. Lista de dados do COR-Rio de fora do data lake, que temos acesso em tempo real (mesmo que com frequência reduzida ou fixos):\n",
    "        1. Geometria de chuvas.\n",
    "        2. Registros de processos da limpeza de ruas, bueiros e dos sistemam de drenagem.\n",
    "    2. Lista de dados fontes externas ao COR-Rio (waze).\n",
    "    3. Acesso aos dados do COR-Rio e de fontes externas testado.    \n",
    "    4. Estratégia de integração do modelo e app ao datalake e demais fontes definida.\n",
    "\n",
    "\n",
    "3. Carregamento, limpeza e análise exploratória com o objetivo de avaliar a qualidade dos dados, o potencial preditivo (correlações), e possíveis arquiteturas de modelo.\n",
    "    1. Todos os dados acessíveis disponíveis em um mesmo ambiente, avaliados, limpos e prontos para teste.\n",
    "    2. Relatório de análise exploratória dos dados:\n",
    "        1. Avaliar o potencial preditivo dos dados (correlação).\n",
    "        2. Recomendação de arquitetura do modelo.\n",
    "    \n",
    "    \n",
    "4. Estudo e desenvolvimento da arquitetura do modelo.\n",
    "    1. Arquitetura de modelo para teste definida.\n",
    "    \n",
    "    \n",
    "5. Estudo de engenharia de features.\n",
    "    1. Criação de novas features com valor preditivo, a partir das features originais.\n",
    "    \n",
    "\n",
    "6. Avaliação do modelo e Demo MVP\n",
    "    1. Modelo avaliado e hospedado via api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detalhamento das etapas\n",
    "\n",
    "0. #### Análise exploratória de dados do Sistema Comando.\n",
    "    1. Determinar potencial para construção de catologo de incidentes para modelagem.\n",
    "    2. Definir método de agrupamento dos dados em pontos ou áreas críticas. Opções:\n",
    "        1. Clusterização\n",
    "        2. Seções de área de grade 2D (incluindo áreas por contagem mínima).\n",
    "        3. Usar lista externa de pontos históricos conhecidos: Agrupar pontos dentro de raio definido ou polígono personalizado, ao redor de cada ponto histórico.\n",
    "        4. Por trecho de via, a partir dá numeração de vias e definição de distância mínima estática ou dinâmica (RECOMENDADA).\n",
    "\n",
    "\n",
    "1. #### Estudo e avaliação do ecosistema de dados do COR-Rio (datalake google cloud e demais fontes), junto à instituição e ao setor de tecnologia (Requisição dos dados).\n",
    "    \n",
    "    1. Precisamos de dados históricos de chuva e outros para treinamento, porém não podemos usar dados que não teremos acesso em tempo real, ou seja, que não são atualizados ou disponibilizados quando mudam de estado.\n",
    "    \n",
    "    2. Perguntas/Entrevista:\n",
    "        1. Como funciona o datalake do COR-Rio?\n",
    "        2. Quantas tabelas possui atualmente? Quais são em tempo real?\n",
    "        3. Quais os demais dados que o COR-Rio tem acesso que não estão no datalake? Dados de api, de geometria de chuva, de outros sistemas, outras instituições, dispersos em outros ambientes, etc. Quais demais dados são em tempo real?\n",
    "        5. Quais dados conseguimos acessar efetivamente na fase de aceleração?\n",
    "        6. Obs: Gerar lista compreensiva de dados datalake e outros, registrando quais são em tempo real e quais conseguimos acesso.\n",
    "        7. Quais dados podem ser disponibilizados futuramente ao COR-Rio?\n",
    "        8. Como funciona a integração de dados em tempo real do datalake do cor Rio?\n",
    "        9. Por quais métodos os dados podem ser acessados em tempo real? Api, BigQuery? Já existem projetos que trabalham com essa integração?\n",
    "\n",
    "    3. Definir Método de integração do modelo e da aplicação assistente, ao datalake e demais fontes:\n",
    "        1. **Método 1** (Recomendado):\n",
    "            1. Hospedar modelo via API\n",
    "            2. Aplicação assistente do agente COR-Rio em frequência definida, realiza:\n",
    "                1. Chamado direto à API do modelo, para obter as previsões para o momento em questão.\n",
    "                2. Exibe/atualiza previsões do modelo no lado do cliente.\n",
    "            3. API do modelo quando requisitada realiza, no lado do servidor:\n",
    "                1. Chamado ao datalake e demais fontes, retornando os dados preditivos em tempo real.\n",
    "                2. Processa os dados preditivos para o formato correto de input do modelo.\n",
    "                3. Calcula e retorna as previsões de risco.\n",
    "\n",
    "        2. **Método 2**:\n",
    "            1. Hospedar modelo via API\n",
    "            2. Aplicação assistente do agente COR-Rio em frequência definida, realiza:\n",
    "                1. Chamado ao datalake e demais fontes, retornando os dados preditivos em tempo real.\n",
    "                2. Processa os dados preditivos para o formato correto de input da API do modelo, no lado do cliente.\n",
    "                3. Faz chamado à API do modelo fornecendo os dados processados e recebe as previsões de risco.\n",
    "                4. Exibe/atualiza as previsões no lado do cliente.\n",
    "        \n",
    "        \n",
    "2. #### Carregamento, limpeza e análise exploratória com o objetivo de avaliar a qualidade dos dados, o potencial preditivo (correlações), e possíveis arquiteturas de modelo.\n",
    "\n",
    "4. #### Estudo e desenvolvimento da arquitetura do modelo.\n",
    "    1. Validar recomendações provenientes da análise exploratória do Sistema Comando de incidentres registrados .\n",
    "    2. Conversar com especialistas nesses eventos, ou profissionais que já abordaram essa modelagem, para o levantamento de opções de arquiteturas, estratégias de uso de dados, entre outros assuntos.\n",
    "\n",
    "\n",
    "5. #### Estudo de engenharia de features\n",
    "\n",
    "6. #### Demo e avaliação do modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
