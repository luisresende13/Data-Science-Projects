{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waterbag Model API Deployment Test Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2022-10-17T10:51:44.442451-03:00'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install --upgrade google-cloud-bigquery\n",
    "import os, json, pandas as pd, numpy as np, requests, pickle, pymongo\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.preprocessing import MinMaxScaler as mms\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime\n",
    "import pytz; tz_br = pytz.timezone('Brazil/East')\n",
    "datetime.now(tz_br).isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flat stations' observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_map = lambda row: row[1].add_suffix(' - ' + row[0])\n",
    "\n",
    "def flat_observations(data):\n",
    "    return pd.concat(list(map(row_map, data.iterrows())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibrate predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(prob, threshold=0.5):\n",
    "    if prob < threshold:\n",
    "        return 0.5 * prob / threshold\n",
    "    else:\n",
    "        return 0.5 + 0.5 * (prob - threshold) / (1 - threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model deployment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_path = 'feature_info.csv'\n",
    "deploy_info = pd.read_csv(info_path, index_col=0)\n",
    "\n",
    "from alerta_deploy import alerta_feature_name_map, alerta_station_name_id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Inmet bigquery request - python client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pressao - A602                       1019.4\n",
       "pressao_minima - A602                1019.3\n",
       "pressao_maxima - A602                1019.5\n",
       "temperatura_orvalho - A602             18.8\n",
       "temperatura_orvalho_minimo - A602      18.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_id = 'pluvia-360323'\n",
    "google_credentials = '../../../../Apps/Python/bolsao-api/credentials/pluvia-360323-eae2907a9c98.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(google_credentials)\n",
    "\n",
    "query = '''\n",
    "SELECT * FROM `datario.meio_ambiente_clima.meteorologia_inmet`\n",
    "WHERE data_particao >= \"{}\"\n",
    "ORDER BY data_particao DESC, horario DESC\n",
    "'''\n",
    "\n",
    "def inmet_bigquery_request():\n",
    "    yesterday = (datetime.now(tz_br) - pd.offsets.Day()).date().isoformat()\n",
    "    client = bigquery.Client(credentials=credentials)\n",
    "    query_job = client.query(query.format(yesterday))\n",
    "    inmet = pd.DataFrame(list(map(dict, query_job.result())))\n",
    "\n",
    "    ### Inmet data preprocessing\n",
    "    key_cols = ['primary_key', 'data_particao', 'horario']\n",
    "    # Last available record per station\n",
    "    last_records = inmet.groupby(['id_estacao']).first().drop(key_cols, axis=1)\n",
    "\n",
    "    # Flat stations' readings\n",
    "    return flat_observations(last_records)\n",
    "\n",
    "# Inmet bigquery request - python client library\n",
    "inmet_flat = inmet_bigquery_request(); inmet_flat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pressao - A602                       1019.4\n",
       "pressao_minima - A602                1019.3\n",
       "pressao_maxima - A602                1019.5\n",
       "temperatura_orvalho - A602             18.8\n",
       "temperatura_orvalho_minimo - A602      18.5\n",
       "temperatura_orvalho_maximo - A602      19.0\n",
       "umidade - A602                         73.0\n",
       "umidade_minima - A602                  68.0\n",
       "umidade_maxima - A602                  73.0\n",
       "temperatura - A602                     24.0\n",
       "temperatura_minima - A602              24.0\n",
       "temperatura_maxima - A602              25.1\n",
       "rajada_vento_max - A602                 9.9\n",
       "direcao_vento - A602                  102.0\n",
       "velocidade_vento - A602                 5.0\n",
       "radiacao_global - A602                853.6\n",
       "acumulado_chuva_1_h - A602              0.0\n",
       "pressao - A621                       1017.4\n",
       "pressao_minima - A621                1016.9\n",
       "pressao_maxima - A621                1017.4\n",
       "temperatura_orvalho - A621             18.8\n",
       "temperatura_orvalho_minimo - A621      18.5\n",
       "temperatura_orvalho_maximo - A621      19.5\n",
       "umidade - A621                         65.0\n",
       "umidade_minima - A621                  61.0\n",
       "umidade_maxima - A621                  65.0\n",
       "temperatura - A621                     25.9\n",
       "temperatura_minima - A621              25.8\n",
       "temperatura_maxima - A621              27.3\n",
       "rajada_vento_max - A621                 7.6\n",
       "direcao_vento - A621                  242.0\n",
       "velocidade_vento - A621                 3.0\n",
       "radiacao_global - A621                945.8\n",
       "acumulado_chuva_1_h - A621              0.0\n",
       "pressao - A636                       1018.8\n",
       "pressao_minima - A636                1018.5\n",
       "pressao_maxima - A636                1018.8\n",
       "temperatura_orvalho - A636             18.3\n",
       "temperatura_orvalho_minimo - A636      18.3\n",
       "temperatura_orvalho_maximo - A636      19.0\n",
       "umidade - A636                         69.0\n",
       "umidade_minima - A636                  67.0\n",
       "umidade_maxima - A636                  71.0\n",
       "temperatura - A636                     24.3\n",
       "temperatura_minima - A636              24.3\n",
       "temperatura_maxima - A636              25.2\n",
       "rajada_vento_max - A636                 7.4\n",
       "direcao_vento - A636                  235.0\n",
       "velocidade_vento - A636                 3.0\n",
       "radiacao_global - A636               1096.6\n",
       "acumulado_chuva_1_h - A636              0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inmet_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Alerta-Rio API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m05 - 1                        0.0\n",
       "acumulado_chuva_15_min - 1     0.0\n",
       "mes - 1                       12.4\n",
       "acumulado_chuva_96_h - 1       3.2\n",
       "acumulado_chuva_24_h - 1       3.2\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def alertario_api_request():\n",
    "    AlertaAPI = r'http://websempre.rio.rj.gov.br/json/chuvas'\n",
    "    alerta = pd.DataFrame(requests.get(AlertaAPI).json()['objects'])\n",
    "\n",
    "    # Alerta-Rio data preprocessing\n",
    "    alerta = pd.DataFrame(\n",
    "        alerta['data'].tolist(),\n",
    "        index=alerta['name'].map(alerta_station_name_id_map).astype('str')\n",
    "    ).rename(columns=alerta_feature_name_map)\n",
    "\n",
    "    # Flat stations observations\n",
    "    return flat_observations(alerta)\n",
    "\n",
    "# ---\n",
    "# Alerta-Rio API request\n",
    "alerta_flat = alertario_api_request(); alerta_flat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(keys, path, file_fmt):\n",
    "    models = {}\n",
    "    for model_id in keys:\n",
    "        path_model = path + str(model_id) + '/'\n",
    "        if os.path.exists(path_model):\n",
    "            models[model_id] = pickle.load(open(path_model + file_fmt.format(model_id), 'rb'))\n",
    "    return models\n",
    "\n",
    "def load_encoders(path):\n",
    "    models = {}\n",
    "    for file in os.listdir(path):\n",
    "        model_id, ext = file.split('.')\n",
    "        if ext == 'pickle':\n",
    "            models[model_id] = pickle.load(open(path + file, 'rb'))\n",
    "    return models\n",
    "\n",
    "time_keys = [\n",
    "    'month', 'day', 'hour', 'minute', 'time',\n",
    "    'dayofyear', 'weekofyear', 'weekday', 'quarter'\n",
    "]\n",
    "\n",
    "def load_time_features(now, encoders):\n",
    "    \n",
    "    ts = pd.DatetimeIndex([now]).floor('15Min')\n",
    "    values = [\n",
    "        ts.month, ts.day, ts.hour, ts.minute, ts.time,\n",
    "        ts.dayofyear, ts.weekofyear, ts.weekday, ts.quarter\n",
    "    ]\n",
    "    time_features = pd.DataFrame(np.array(values).T, index=ts, columns=time_keys)\n",
    "\n",
    "    # data type conversion for label encoding\n",
    "    float_cols = [key for key in time_keys if key != 'time']\n",
    "    time_features[float_cols] = time_features[float_cols].astype('float')\n",
    "    time_features['time'] = time_features['time'].astype(str)\n",
    "\n",
    "    # Label encoding\n",
    "    for col in time_features.columns:\n",
    "        time_features[col] = encoders[col].transform(time_features[col])\n",
    "    return time_features.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models and encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clusters = '../Dados/Clusters/clusters_micro.csv'\n",
    "clusters = pd.read_csv(path_clusters, index_col=0)['main_route']\n",
    "\n",
    "### Load classification model for each cluster\n",
    "\n",
    "models = load_models(clusters.index, 'Modelos/', file_fmt='{}.pickle')\n",
    "encoders = load_encoders('Encoders/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "today = now.date().isoformat()\n",
    "time = now.time().isoformat()[:8]\n",
    "\n",
    "time_flat = load_time_features(now, encoders); time_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-10-16T18:24:36.937044'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and transform observations from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing features (28): ['velocidade_vento - A652', 'pressao - A652', 'rajada_vento_max - A654', 'temperatura_orvalho_maximo - A652', 'acumulado_chuva_1_h - A654', 'pressao - A654', 'temperatura_maxima - A652', 'pressao_maxima - A652', 'pressao_maxima - A654', 'radiacao_global - A654', 'acumulado_chuva_1_h - A652', 'temperatura_orvalho_maximo - A654', 'pressao_minima - A652', 'pressao_minima - A654', 'year', 'temperatura_orvalho_minimo - A652', 'rajada_vento_max - A652', 'date', 'temperatura - A652', 'radiacao_global - A652', 'temperatura_minima - A654', 'temperatura_orvalho - A654', 'temperatura_maxima - A654', 'temperatura_orvalho - A652', 'temperatura_minima - A652', 'velocidade_vento - A654', 'temperatura - A654', 'temperatura_orvalho_minimo - A654'] \n",
      "\n",
      "Ignored features (144): ['h02 - 30', 'm05 - 13', 'umidade_minima - A602', 'm05 - 19', 'h02 - 12', 'h03 - 1', 'h03 - 9', 'm05 - 4', 'm05 - 12', 'h02 - 29', 'h03 - 7', 'h03 - 25', 'mes - 9', 'h03 - 33', 'm05 - 20', 'h02 - 22', 'h03 - 16', 'h02 - 23', 'm05 - 10', 'm05 - 11', 'h03 - 24', 'mes - 20', 'mes - 14', 'mes - 24', 'm05 - 7', 'mes - 13', 'mes - 22', 'm05 - 24', 'h03 - 27', 'mes - 11', 'h03 - 32', 'h03 - 30', 'h03 - 22', 'm05 - 8', 'h02 - 18', 'm05 - 6', 'm05 - 16', 'mes - 16', 'h03 - 12', 'm05 - 32', 'h02 - 24', 'umidade - A621', 'm05 - 1', 'h03 - 2', 'h02 - 13', 'h02 - 16', 'mes - 6', 'mes - 31', 'm05 - 17', 'h02 - 4', 'h02 - 32', 'umidade_maxima - A636', 'h02 - 5', 'mes - 32', 'h03 - 5', 'mes - 1', 'umidade_maxima - A602', 'mes - 25', 'mes - 2', 'h03 - 28', 'm05 - 14', 'mes - 33', 'm05 - 15', 'm05 - 30', 'h02 - 6', 'mes - 15', 'm05 - 22', 'h02 - 8', 'mes - 28', 'h02 - 26', 'mes - 5', 'h03 - 8', 'h03 - 20', 'mes - 3', 'm05 - 18', 'h03 - 19', 'h02 - 28', 'm05 - 31', 'h02 - 1', 'm05 - 26', 'mes - 10', 'umidade_maxima - A621', 'h02 - 31', 'mes - 21', 'h03 - 10', 'mes - 19', 'mes - 7', 'h02 - 10', 'm05 - 27', 'umidade_minima - A621', 'h03 - 11', 'm05 - 5', 'h02 - 21', 'mes - 8', 'h02 - 9', 'h03 - 26', 'mes - 23', 'h03 - 15', 'mes - 17', 'mes - 12', 'h03 - 31', 'm05 - 28', 'h03 - 23', 'h03 - 4', 'h03 - 13', 'h03 - 18', 'h02 - 17', 'm05 - 25', 'umidade - A602', 'h02 - 20', 'umidade_minima - A636', 'h02 - 14', 'h02 - 15', 'mes - 26', 'h03 - 21', 'mes - 18', 'm05 - 33', 'h02 - 11', 'h03 - 14', 'h02 - 27', 'm05 - 21', 'direcao_vento - A636', 'h02 - 7', 'h03 - 29', 'direcao_vento - A602', 'mes - 4', 'm05 - 9', 'mes - 27', 'm05 - 2', 'h03 - 17', 'h02 - 19', 'mes - 30', 'h02 - 25', 'h02 - 3', 'umidade - A636', 'm05 - 3', 'm05 - 29', 'h02 - 33', 'h03 - 6', 'h03 - 3', 'direcao_vento - A621', 'h02 - 2', 'm05 - 23', 'mes - 29'] \n",
      "\n",
      "Features shape: (1, 241)\n"
     ]
    }
   ],
   "source": [
    "features = pd.concat([time_flat, inmet_flat, alerta_flat])\n",
    "\n",
    "# Handle missing features\n",
    "missing_cols = list(set(deploy_info.index).difference(features.index))\n",
    "ignored_cols = list(set(features.index).difference(deploy_info.index))\n",
    "\n",
    "if len(missing_cols) or len(ignored_cols):\n",
    "    print(f'Missing features ({len(missing_cols)}):', missing_cols, '\\n')\n",
    "    print(f'Ignored features ({len(ignored_cols)}):', ignored_cols, '\\n')\n",
    "    for col in missing_cols:\n",
    "        features[col] = deploy_info.loc[col, 'mean']\n",
    "\n",
    "#### Reorder readings to match model input format\n",
    "features = features.loc[deploy_info.index].to_frame().T\n",
    "print('Features shape:', features.shape)\n",
    "\n",
    "#### Fill missing values with the mean\n",
    "na_msk = features.loc[0].isna()\n",
    "features.loc[0, na_msk] = deploy_info['mean'][na_msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Multiple model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_model_prediction(models, features, time_info, names):\n",
    "    \n",
    "    predictions = []\n",
    "    for model_id, model in models.items():\n",
    "        ### Model output transformation\n",
    "        yprob = model.predict_proba(features)[0][1]\n",
    "#         yprob_cal = calibrate(yprob, model['metadata']['threshold'])\n",
    "        yconf = abs(0.5 - yprob) / 0.5\n",
    "        label = int(yprob >= 0.5)\n",
    "        ### Prediction record\n",
    "        predictions.append({\n",
    "            'timestamp': time_info['now'],\n",
    "            'date': time_info['today'],\n",
    "            'time': time_info['time'],\n",
    "            'cluster_id': model_id,\n",
    "            'cluster': names[model_id],\n",
    "            'range': '1h',\n",
    "            'probability': round(yprob, 6),\n",
    "            'confidence': round(yconf, 6),\n",
    "            'label': label,\n",
    "        })\n",
    "    return predictions        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': datetime.datetime(2022, 10, 15, 7, 56, 2, 725342),\n",
       "  'date': '2022-10-15',\n",
       "  'time': '07:56:02',\n",
       "  'cluster_id': 0,\n",
       "  'cluster': 'Avenida Armando Lombardi',\n",
       "  'range': '1h',\n",
       "  'probability': 0.01209,\n",
       "  'confidence': 0.97582,\n",
       "  'label': 0},\n",
       " {'timestamp': datetime.datetime(2022, 10, 15, 7, 56, 2, 725342),\n",
       "  'date': '2022-10-15',\n",
       "  'time': '07:56:02',\n",
       "  'cluster_id': 1,\n",
       "  'cluster': 'Rua do Catete',\n",
       "  'range': '1h',\n",
       "  'probability': 0.001561,\n",
       "  'confidence': 0.996877,\n",
       "  'label': 0},\n",
       " {'timestamp': datetime.datetime(2022, 10, 15, 7, 56, 2, 725342),\n",
       "  'date': '2022-10-15',\n",
       "  'time': '07:56:02',\n",
       "  'cluster_id': 2,\n",
       "  'cluster': 'Rua Tonelero',\n",
       "  'range': '1h',\n",
       "  'probability': 0.000638,\n",
       "  'confidence': 0.998724,\n",
       "  'label': 0},\n",
       " {'timestamp': datetime.datetime(2022, 10, 15, 7, 56, 2, 725342),\n",
       "  'date': '2022-10-15',\n",
       "  'time': '07:56:02',\n",
       "  'cluster_id': 3,\n",
       "  'cluster': 'Avenida Epitácio Pessoa',\n",
       "  'range': '1h',\n",
       "  'probability': 0.008609,\n",
       "  'confidence': 0.982782,\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "today = now.date().isoformat()\n",
    "time = now.time().isoformat()[:8]\n",
    "time_info = {'now': now, 'today': today, 'time': time}\n",
    "\n",
    "predictions = multi_model_prediction(models, features, time_info, names=clusters); predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Save prediction to mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = \"mongodb+srv://luisresende13:Gaia0333@pluvia-cluster.ea8fb4s.mongodb.net/?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=10000)\n",
    "\n",
    "insert_result = client.Waterbag.Prediction.insert_many(predictions)\n",
    "insert_result.inserted_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# API Endpoints - Retrieve predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str_id(obj):\n",
    "    obj['_id'] = str(obj['_id'])\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mongo client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = \"mongodb+srv://luisresende13:Gaia0333@pluvia-cluster.ea8fb4s.mongodb.net/?retryWrites=true&w=majority\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions collection endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endpoint params description:\n",
    "\n",
    "1. Documents will be filtered by the params matching fields in the documents.\n",
    "2. Params can have multiple values divided by comma, i.e '/predictions?cluster_id=0,1,2'\n",
    "3. Optional parameters:\n",
    "    1. sort -> field to sort by. Default: 'timestamp'\n",
    "    2. sort_order -> '1' or '-1'. Default: '-1'\n",
    "    3. limit -> integer greater than 1. Default: None\n",
    "    \n",
    "#### Request url examples:\n",
    "\n",
    "1. /predictions?cluster_id=0,1,2&date=2022-09-27\n",
    "2. /predictions?cluster_id=0&sort=timestamp&sort_order=-1\n",
    "3. /predictions?cluster_id=0&limit=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_param_processing(query):\n",
    "    \n",
    "    if 'limit' not in query.keys():\n",
    "        limit = None            # Default limit\n",
    "    else:\n",
    "        limit = int(query['limit'])\n",
    "        del query['limit']\n",
    "    \n",
    "    if 'sort' not in query.keys():\n",
    "        sort_by = 'timestamp'   # Default sorting\n",
    "        sort_order = -1\n",
    "    else:\n",
    "        sort_by = query['sort']\n",
    "        del query['sort']\n",
    "        if 'sort_order' not in query.keys():\n",
    "            sort_order = -1     # Default sort order\n",
    "        else:\n",
    "            sort_order = int(query['sort_order'])\n",
    "            del query['sort_order']\n",
    "            \n",
    "    query_spread = {key: {'$in': str(value).split(',')} for key, value in query.items()}    \n",
    "    return query_spread, sort_by, sort_order, limit\n",
    "\n",
    "def prediction_records(query):\n",
    "    query_spread, sort_by, sort_order, limit = url_param_processing(query)\n",
    "    print(\n",
    "        'Endpoint Request: /predictions. Query Params:', query_spread,\n",
    "        ' URL Params:', {'sort': sort_by, 'sort_order': sort_order, 'limit': limit}\n",
    "    )\n",
    "    client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=15000)\n",
    "    docs = client.Waterbag.Prediction.find(query_spread).sort([(sort_by, sort_order)])\n",
    "    if limit is not None:\n",
    "        docs = docs.limit(limit)\n",
    "    return list(map(to_str_id, docs)) # prediction object list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example query request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Request: /predictions. Query Params: {'date': {'$in': ['2022-09-27']}}  URL Params: {'sort': 'cluster_id', 'sort_order': -1, 'limit': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'_id': '6333205abf7dfe3425cd5d8c',\n",
       "  'timestamp': datetime.datetime(2022, 9, 27, 16, 10),\n",
       "  'date': '2022-09-27',\n",
       "  'time': '13:10:00',\n",
       "  'cluster_id': '4',\n",
       "  'cluster': 'Avenida Ministro Ivan Lins',\n",
       "  'range': '1h',\n",
       "  'probability': 0.008267,\n",
       "  'confidence': 0.983465,\n",
       "  'label': '0'},\n",
       " {'_id': '63331f2ebf7dfe3425cd5d86',\n",
       "  'timestamp': datetime.datetime(2022, 9, 27, 16, 5, 0, 1000),\n",
       "  'date': '2022-09-27',\n",
       "  'time': '13:05:00',\n",
       "  'cluster_id': '4',\n",
       "  'cluster': 'Avenida Ministro Ivan Lins',\n",
       "  'range': '1h',\n",
       "  'probability': 0.008267,\n",
       "  'confidence': 0.983465,\n",
       "  'label': '0'},\n",
       " {'_id': '63331e02bf7dfe3425cd5d80',\n",
       "  'timestamp': datetime.datetime(2022, 9, 27, 16, 0),\n",
       "  'date': '2022-09-27',\n",
       "  'time': '13:00:00',\n",
       "  'cluster_id': '4',\n",
       "  'cluster': 'Avenida Ministro Ivan Lins',\n",
       "  'range': '1h',\n",
       "  'probability': 0.008267,\n",
       "  'confidence': 0.983465,\n",
       "  'label': '0'}]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = request.args.to_dict() # Flask request url args\n",
    "query = {'date': '2022-09-27', 'sort': 'cluster_id' , 'sort_order': '-1', 'limit': '3'}\n",
    "\n",
    "prediction_records(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last timestamp predictions\n",
    "\n",
    "#### /predict endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cluster_id': 0,\n",
       "  '_id': '633311214d7183838dc5561c',\n",
       "  'timestamp': Timestamp('2022-09-27 15:05:00'),\n",
       "  'date': '2022-09-27',\n",
       "  'time': '12:05:00',\n",
       "  'cluster': 'Avenida Armando Lombardi',\n",
       "  'range': '1h',\n",
       "  'probability': 0.010816,\n",
       "  'confidence': 0.978369,\n",
       "  'label': 0},\n",
       " {'cluster_id': 1,\n",
       "  '_id': '633311214d7183838dc5561d',\n",
       "  'timestamp': Timestamp('2022-09-27 15:05:00'),\n",
       "  'date': '2022-09-27',\n",
       "  'time': '12:05:00',\n",
       "  'cluster': 'Rua do Catete',\n",
       "  'range': '1h',\n",
       "  'probability': 0.003329,\n",
       "  'confidence': 0.993342,\n",
       "  'label': 0},\n",
       " {'cluster_id': 2,\n",
       "  '_id': '633311214d7183838dc5561e',\n",
       "  'timestamp': Timestamp('2022-09-27 15:05:00'),\n",
       "  'date': '2022-09-27',\n",
       "  'time': '12:05:00',\n",
       "  'cluster': 'Rua Tonelero',\n",
       "  'range': '1h',\n",
       "  'probability': 0.004038,\n",
       "  'confidence': 0.991925,\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_prediction_record(limit=500):\n",
    "    \n",
    "    now = datetime.now(tz_br)\n",
    "    today = now.date().isoformat()\n",
    "    time = now.time().isoformat()[:8]\n",
    "    yesterday = (now - pd.offsets.Day()).date().isoformat()\n",
    "    \n",
    "    sort_by = [('timestamp', -1), ('cluster_id', 1)]\n",
    "    last_24h = {\n",
    "        \"$or\": [{\n",
    "            \"date\": today\n",
    "        }, {\n",
    "            '$and': [{'date': yesterday}, {'time': {'$gte': time}}]\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    ### Consult prediction database latest record\n",
    "    client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=15000)\n",
    "    first_docs = client.Waterbag.Prediction.find(last_24h).sort(sort_by).limit(limit)\n",
    "    first_docs = pd.DataFrame(list(map(to_str_id, first_docs))) # prediction object list\n",
    "    docs_clusters = first_docs.groupby('cluster_id', as_index=False).first()\n",
    "    \n",
    "    return list(docs_clusters.T.to_dict().values())\n",
    "\n",
    "last_prediction_record(limit=500)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Extra: Test predict endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_id\":\"632c32223e18981a9a002da8\",\"cluster\":\"Catete\",\"confidence\":0.9841241118565575,\"date\":\"2022-09-22\",\"probability\":0.00793794407172125,\"range\":\"1h\",\"time\":\"07:00:00\",\"timestamp\":\"Thu, 22 Sep 2022 10:00:00 GMT\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "api_url = 'https://bolsoes-api.herokuapp.com'\n",
    "\n",
    "print(requests.get(api_url + '/predict').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Clean database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = \"mongodb+srv://luisresende13:Gaia0333@pluvia-cluster.ea8fb4s.mongodb.net/?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=15000)\n",
    "\n",
    "delete_res = client.Waterbag.Prediction.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 1267,\n",
       " 'electionId': ObjectId('7fffffff000000000000000c'),\n",
       " 'opTime': {'ts': Timestamp(1664233178, 1269), 't': 12},\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1664233178, 1269),\n",
       "  'signature': {'hash': b'\\xd7\\x806c\"x\\xed\\xd9\\x0bm\\x04\\xb6w\\xfa\\xd2\\xddu\\xb6\\xf3\\n',\n",
       "   'keyId': 7088356184993824773}},\n",
       " 'operationTime': Timestamp(1664233178, 1269)}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_res.raw_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
