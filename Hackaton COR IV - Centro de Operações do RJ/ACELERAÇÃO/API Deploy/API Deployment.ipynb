{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waterbag Model API Deployment Test Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Bolsões:\n",
    "\n",
    "    Anos da série histórica: 2015 - 2022\n",
    "    Número de bolsões registrados: 3140\n",
    "    Média de bolsões no verão (2018 - 2022): 285 bolsões\n",
    "    Dia com maior número de bolsões na cidade: 67 bolsões registrados (10/02/2020 - 10 de fevereiro de 2020)\n",
    "\n",
    "Dados do modelo:\n",
    "\n",
    "Frequencia de atualização do modelo: 5 minutos\n",
    "Calcula a probabilidade para a proxima: 1 hora\n",
    "Cálculo da confiança da previsão:\n",
    "    \n",
    "    conf = abs(prob - 0,5) / 0,5  # Diferença percentual da probabilidade com o limite de decisão (0,5)\n",
    "    \n",
    "    onde:\n",
    "        prob -> probabilidade\n",
    "        conf -> confiança\n",
    "    \n",
    "    Ex:\n",
    "        prob = 0.9\n",
    "        conf = abs(prob - 0,5) / 0,5\n",
    "        conf = abs(0,9 - 0,5) / 0,5\n",
    "        conf = 0,4 / 0,5        \n",
    "        conf = 0,8 (80%)\n",
    "\n",
    "Dados de estações:\n",
    "\n",
    "    Estações inmet (4):\n",
    "        'A602', 'A621', 'A636', 'A652'\n",
    "\n",
    "    Dados inmet:\n",
    "        'acumulado_chuva_1_h', 'pressao', 'pressao_maxima', 'pressao_minima',\n",
    "        'radiacao_global', 'rajada_vento_max', 'temperatura',\n",
    "        'temperatura_maxima', 'temperatura_minima', 'temperatura_orvalho',\n",
    "        'temperatura_orvalho_maximo', 'temperatura_orvalho_minimo',\n",
    "        'velocidade_vento'\n",
    "\n",
    "    Estações Alerta-Rio (33):\n",
    "        'Piedade', 'Saúde', 'Jacarepaguá/Cidade de Deus', 'Laranjeiras',\n",
    "        'Vidigal', 'Urca', 'Rocinha', 'Tijuca', 'Santa Teresa', 'Copacabana',\n",
    "        'Grajaú', 'Ilha do Governador', 'Penha', 'Madureira', 'Irajá', 'Bangu',\n",
    "        'Jacarepaguá/Tanque', 'Jardim Botânico', 'Barra/Barrinha',\n",
    "        'Barra/Riocentro', 'Guaratiba', 'Est. Grajaú/Jacarepaguá', 'Santa Cruz',\n",
    "        'Grande Méier', 'Anchieta', 'Grota Funda', 'Campo Grande', 'Sepetiba',\n",
    "        'Alto da Boa Vista', 'Av. Brasil/Mendanha', 'Recreio dos Bandeirantes',\n",
    "        'São Cristóvão', 'Tijuca/Muda'\n",
    "\n",
    "    Dados Alerta-Rio:\n",
    "        'acumulado_chuva_15_min',\n",
    "        'acumulado_chuva_1_h',\n",
    "        'acumulado_chuva_4_h',\n",
    "        'acumulado_chuva_24_h',\n",
    "        'acumulado_chuva_96_h'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-11-09T08:52:16.183299-03:00'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install --upgrade google-cloud-bigquery\n",
    "import os, json, pandas as pd, numpy as np, requests, pickle, pymongo\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.preprocessing import MinMaxScaler as mms\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime\n",
    "import pytz; tz_br = pytz.timezone('Brazil/East')\n",
    "datetime.now(tz_br).isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flat stations' observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_map = lambda row: row[1].add_suffix(' - ' + row[0])\n",
    "\n",
    "def flat_observations(data):\n",
    "    return pd.concat(list(map(row_map, data.iterrows())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibrate predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(prob, threshold=0.5):\n",
    "    if prob < threshold:\n",
    "        return 0.5 * prob / threshold\n",
    "    else:\n",
    "        return 0.5 + 0.5 * (prob - threshold) / (1 - threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current date & time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now_info(tz='Brazil/East'):\n",
    "    if tz is not None:\n",
    "        tz = pytz.timezone(tz)\n",
    "    now = datetime.now(tz)\n",
    "    today = now.date().isoformat()\n",
    "    time = now.time().isoformat()[:8]\n",
    "    return now, today, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model deployment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_path = 'feature_info.csv'\n",
    "deploy_info = pd.read_csv(info_path, index_col=0)\n",
    "\n",
    "from alerta_deploy import alerta_feature_name_map, alerta_station_name_id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Inmet bigquery request - python client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'pluvia-360323'\n",
    "google_credentials = '../../../../Apps/Python/bolsao-api/credentials/pluvia-360323-eae2907a9c98.json'\n",
    "google_credentials = service_account.Credentials.from_service_account_file(google_credentials)\n",
    "\n",
    "query = '''\n",
    "SELECT * FROM `datario.meio_ambiente_clima.meteorologia_inmet`\n",
    "WHERE data_particao >= \"{}\"\n",
    "ORDER BY data_particao DESC, horario DESC\n",
    "'''\n",
    "\n",
    "def inmet_bigquery_request(google_credentials):\n",
    "    yesterday = (datetime.now(tz_br) - pd.offsets.Day()).date().isoformat()\n",
    "    client = bigquery.Client(credentials=google_credentials)\n",
    "    query_job = client.query(query.format(yesterday))\n",
    "    inmet = pd.DataFrame(list(map(dict, query_job.result())))\n",
    "\n",
    "    ### Inmet data preprocessing\n",
    "    key_cols = ['primary_key', 'data_particao', 'horario']\n",
    "    # Last available record per station\n",
    "    last_records = inmet.groupby(['id_estacao']).first().drop(key_cols, axis=1)\n",
    "\n",
    "    # Flat stations' readings\n",
    "    return flat_observations(last_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inmet bigquery request - python client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pressao - A602                       1020.8\n",
       "pressao_minima - A602                1020.7\n",
       "pressao_maxima - A602                1020.9\n",
       "temperatura_orvalho - A602             16.1\n",
       "temperatura_orvalho_minimo - A602      15.6\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inmet_flat = inmet_bigquery_request(google_credentials); inmet_flat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Alerta-Rio API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m05 - 1                        0.0\n",
       "acumulado_chuva_15_min - 1     0.0\n",
       "mes - 1                       26.0\n",
       "acumulado_chuva_96_h - 1      35.8\n",
       "acumulado_chuva_24_h - 1      22.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def alertario_api_request():\n",
    "    AlertaAPI = r'http://websempre.rio.rj.gov.br/json/chuvas'\n",
    "    alerta = pd.DataFrame(requests.get(AlertaAPI).json()['objects'])\n",
    "\n",
    "    # Alerta-Rio data preprocessing\n",
    "    alerta = pd.DataFrame(\n",
    "        alerta['data'].tolist(),\n",
    "        index=alerta['name'].map(alerta_station_name_id_map).astype('str')\n",
    "    ).rename(columns=alerta_feature_name_map)\n",
    "\n",
    "    # Flat stations observations\n",
    "    return flat_observations(alerta)\n",
    "\n",
    "# ---\n",
    "# Alerta-Rio API request\n",
    "alerta_flat = alertario_api_request(); alerta_flat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(keys, path, file_fmt):\n",
    "    models = {}\n",
    "    for model_id in keys:\n",
    "        path_model = path + str(model_id) + '/'\n",
    "        if os.path.exists(path_model):\n",
    "            models[model_id] = pickle.load(open(path_model + file_fmt.format(model_id), 'rb'))\n",
    "    return models\n",
    "\n",
    "def load_encoders(path):\n",
    "    models = {}\n",
    "    for file in os.listdir(path):\n",
    "        model_id, ext = file.split('.')\n",
    "        if ext == 'pickle':\n",
    "            models[model_id] = pickle.load(open(path + file, 'rb'))\n",
    "    return models\n",
    "\n",
    "time_keys = [\n",
    "    'month', 'day', 'hour', 'minute', 'time',\n",
    "    'dayofyear', 'weekofyear', 'weekday', 'quarter'\n",
    "]\n",
    "\n",
    "def load_time_features(now, encoders):\n",
    "    \n",
    "    ts = pd.DatetimeIndex([now]).floor('15Min')\n",
    "    values = [\n",
    "        ts.month, ts.day, ts.hour, ts.minute, ts.time,\n",
    "        ts.dayofyear, ts.weekofyear, ts.weekday, ts.quarter\n",
    "    ]\n",
    "    time_features = pd.DataFrame(np.array(values).T, index=ts, columns=time_keys)\n",
    "\n",
    "    # data type conversion for label encoding\n",
    "    float_cols = [key for key in time_keys if key != 'time']\n",
    "    time_features[float_cols] = time_features[float_cols].astype('float')\n",
    "    time_features['time'] = time_features['time'].astype(str)\n",
    "\n",
    "    # Label encoding\n",
    "    for col in time_features.columns:\n",
    "        time_features[col] = encoders[col].transform(time_features[col])\n",
    "    return time_features.iloc[0]\n",
    "\n",
    "def formatted_features(features, deploy_info, fill='mean', report_ignored=False):\n",
    "\n",
    "    # Handle missing features - fill with the mean\n",
    "    missing_features = list(set(deploy_info.index).difference(features.index))\n",
    "    if len(missing_features):\n",
    "        print(f'Missing features ({len(missing_cols)}):', missing_cols, '\\n')\n",
    "        for name in missing_features:\n",
    "            features[name] = deploy_info.loc[name, fill]\n",
    "\n",
    "    # Handle extra features (ignore)\n",
    "    ignored_cols = list(set(features.index).difference(deploy_info.index))\n",
    "    if len(ignored_cols) and report_ignored:\n",
    "        print(f'Ignored features ({len(ignored_cols)}):', ignored_cols, '\\n')\n",
    "\n",
    "    # Reorder features to match model input format\n",
    "    features = features.loc[deploy_info.index]\n",
    "\n",
    "    # Fill missing values - with the mean\n",
    "    na_msk = features.isna()\n",
    "    if na_msk.sum():\n",
    "        features[na_msk] = deploy_info.loc[na_msk, fill]\n",
    "\n",
    "    # Features shape\n",
    "    print('Features shape:', features.shape)\n",
    "    \n",
    "    # Reshape and return\n",
    "    return features.to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models and encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clusters = '../Dados/Clusters/clusters_micro.csv'\n",
    "path_models = '../../../../Apps/Python/bolsao-api/models/'\n",
    "# path_models = 'Modelos/'\n",
    "\n",
    "### Load models, infos and encoders\n",
    "clusters = pd.read_csv(path_clusters, index_col=0)['main_route']\n",
    "models = load_models(clusters.index,  path_models, file_fmt='{}.pickle')\n",
    "encoders = load_encoders('Encoders/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-389762183528>:27: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  ts.dayofyear, ts.weekofyear, ts.weekday, ts.quarter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "month          10\n",
       "day             1\n",
       "hour           15\n",
       "minute          1\n",
       "time           61\n",
       "dayofyear     305\n",
       "weekofyear     43\n",
       "weekday         2\n",
       "quarter         3\n",
       "Name: 2022-11-02 15:15:00-03:00, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "now, today, time = now_info()\n",
    "\n",
    "time_flat = load_time_features(now, encoders)\n",
    "\n",
    "display(time_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and transform observations from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (213,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>time</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>weekday</th>\n",
       "      <th>quarter</th>\n",
       "      <th>acumulado_chuva_1_h - A602</th>\n",
       "      <th>...</th>\n",
       "      <th>acumulado_chuva_4_h - 32</th>\n",
       "      <th>acumulado_chuva_24_h - 32</th>\n",
       "      <th>acumulado_chuva_15_min - 32</th>\n",
       "      <th>acumulado_chuva_1_h - 32</th>\n",
       "      <th>acumulado_chuva_96_h - 32</th>\n",
       "      <th>acumulado_chuva_4_h - 33</th>\n",
       "      <th>acumulado_chuva_24_h - 33</th>\n",
       "      <th>acumulado_chuva_15_min - 33</th>\n",
       "      <th>acumulado_chuva_1_h - 33</th>\n",
       "      <th>acumulado_chuva_96_h - 33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>42.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>83.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  day  hour  minute  time  dayofyear  weekofyear  weekday  quarter  \\\n",
       "0   10.0  1.0  15.0     1.0  61.0      305.0        43.0      2.0      3.0   \n",
       "\n",
       "   acumulado_chuva_1_h - A602  ...  acumulado_chuva_4_h - 32  \\\n",
       "0                         1.2  ...                      13.0   \n",
       "\n",
       "   acumulado_chuva_24_h - 32  acumulado_chuva_15_min - 32  \\\n",
       "0                       23.2                          1.0   \n",
       "\n",
       "   acumulado_chuva_1_h - 32  acumulado_chuva_96_h - 32  \\\n",
       "0                      11.2                       42.6   \n",
       "\n",
       "   acumulado_chuva_4_h - 33  acumulado_chuva_24_h - 33  \\\n",
       "0                      23.4                       83.2   \n",
       "\n",
       "   acumulado_chuva_15_min - 33  acumulado_chuva_1_h - 33  \\\n",
       "0                          0.4                      11.0   \n",
       "\n",
       "   acumulado_chuva_96_h - 33  \n",
       "0                      110.0  \n",
       "\n",
       "[1 rows x 213 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concat requested features\n",
    "features = pd.concat([time_flat, inmet_flat, alerta_flat])\n",
    "features = formatted_features(features, deploy_info, fill='mean', report_ignored=False)\n",
    "\n",
    "display(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Multiple model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_model_prediction(models, features, time_info, names):\n",
    "    \n",
    "    predictions = []\n",
    "    for model_id, model in models.items():\n",
    "        yprob = model.predict_proba(features)[0][1]\n",
    "#         yprob_cal = calibrate(yprob, model['metadata']['threshold'])\n",
    "        yconf = abs(0.5 - yprob) / 0.5\n",
    "        label = int(yprob >= 0.5)\n",
    "        ### Prediction record\n",
    "        predictions.append({\n",
    "            'timestamp': time_info['now'],\n",
    "            'date': time_info['today'],\n",
    "            'time': time_info['time'],\n",
    "            'cluster_id': model_id,\n",
    "            'cluster': names[model_id],\n",
    "            'range': '1h',\n",
    "            'probability': round(yprob, 6),\n",
    "            'confidence': round(yconf, 6),\n",
    "            'label': label,\n",
    "        })\n",
    "    return predictions        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': datetime.datetime(2022, 10, 19, 12, 18, 29, 397751, tzinfo=<DstTzInfo 'Brazil/East' -03-1 day, 21:00:00 STD>),\n",
       "  'date': '2022-10-19',\n",
       "  'time': '12:18:29',\n",
       "  'cluster_id': 0,\n",
       "  'cluster': 'Avenida Armando Lombardi',\n",
       "  'range': '1h',\n",
       "  'probability': 0.003169,\n",
       "  'confidence': 0.993663,\n",
       "  'label': 0},\n",
       " {'timestamp': datetime.datetime(2022, 10, 19, 12, 18, 29, 397751, tzinfo=<DstTzInfo 'Brazil/East' -03-1 day, 21:00:00 STD>),\n",
       "  'date': '2022-10-19',\n",
       "  'time': '12:18:29',\n",
       "  'cluster_id': 1,\n",
       "  'cluster': 'Rua do Catete',\n",
       "  'range': '1h',\n",
       "  'probability': 8.8e-05,\n",
       "  'confidence': 0.999824,\n",
       "  'label': 0},\n",
       " {'timestamp': datetime.datetime(2022, 10, 19, 12, 18, 29, 397751, tzinfo=<DstTzInfo 'Brazil/East' -03-1 day, 21:00:00 STD>),\n",
       "  'date': '2022-10-19',\n",
       "  'time': '12:18:29',\n",
       "  'cluster_id': 2,\n",
       "  'cluster': 'Rua Tonelero',\n",
       "  'range': '1h',\n",
       "  'probability': 0.000258,\n",
       "  'confidence': 0.999485,\n",
       "  'label': 0},\n",
       " {'timestamp': datetime.datetime(2022, 10, 19, 12, 18, 29, 397751, tzinfo=<DstTzInfo 'Brazil/East' -03-1 day, 21:00:00 STD>),\n",
       "  'date': '2022-10-19',\n",
       "  'time': '12:18:29',\n",
       "  'cluster_id': 3,\n",
       "  'cluster': 'Avenida Epitácio Pessoa',\n",
       "  'range': '1h',\n",
       "  'probability': 0.000278,\n",
       "  'confidence': 0.999443,\n",
       "  'label': 0},\n",
       " {'timestamp': datetime.datetime(2022, 10, 19, 12, 18, 29, 397751, tzinfo=<DstTzInfo 'Brazil/East' -03-1 day, 21:00:00 STD>),\n",
       "  'date': '2022-10-19',\n",
       "  'time': '12:18:29',\n",
       "  'cluster_id': 4,\n",
       "  'cluster': 'Avenida Ministro Ivan Lins',\n",
       "  'range': '1h',\n",
       "  'probability': 0.014422,\n",
       "  'confidence': 0.971156,\n",
       "  'label': 0}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "now, today, time = now_info()\n",
    "time_info = {'now': now, 'today': today, 'time': time}\n",
    "\n",
    "predictions = multi_model_prediction(models, features, time_info, names=clusters)\n",
    "\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Save prediction to mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prediction(predictions, conn_str, timeout=15):\n",
    "    client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=int(timeout*1e3))\n",
    "    insert_result = client.Waterbag.Prediction.insert_many(predictions)\n",
    "    if len(insert_result.inserted_ids) == 0:\n",
    "        raise(Exception('Insert prediction to database failed! No prediction inserted.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = \"mongodb+srv://luisresende13:Gaia0333@pluvia-cluster.ea8fb4s.mongodb.net/?retryWrites=true&w=majority\"\n",
    "post_prediction(predictions, conn_str, timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Full prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_task(\n",
    "    models, encoders, names, deploy_info,\n",
    "    google_credentials, conn_str, fill='mean',\n",
    "    timeout=15, report_ignored_features=False\n",
    "):\n",
    "    \n",
    "    # ---\n",
    "    # Report task start\n",
    "\n",
    "    now, today, time = now_info()\n",
    "    print(f'Scheduled prediction starting. Date: {today}, Time: {time}.')\n",
    "\n",
    "    # ---\n",
    "    # Inmet bigquery request - python client library\n",
    "\n",
    "    inmet_flat = inmet_bigquery_request(google_credentials)\n",
    "\n",
    "    # ---\n",
    "    # Alerta-Rio API request\n",
    "\n",
    "    alerta_flat = alertario_api_request()\n",
    "\n",
    "    # ---\n",
    "    # Time features\n",
    "\n",
    "    time_flat = load_time_features(now, encoders)\n",
    "\n",
    "    # ---\n",
    "    # Feature transformation\n",
    "\n",
    "    # Combine requested features\n",
    "    features = pd.concat([time_flat, inmet_flat, alerta_flat])\n",
    "\n",
    "    # Format features\n",
    "    features = formatted_features(features, deploy_info, fill=fill, report_ignored=report_ignored_features)\n",
    "\n",
    "    # ---\n",
    "    # Make Predictions\n",
    "\n",
    "    time_info = {'now': now, 'today': today, 'time': time}\n",
    "    predictions = multi_model_prediction(models, features, time_info, names)\n",
    "\n",
    "    # ---\n",
    "    # Post to mongoDB prediction database\n",
    "\n",
    "    post_prediction(predictions, conn_str, timeout)\n",
    "\n",
    "    # ---\n",
    "    # Report task success\n",
    "\n",
    "    now, today, time = now_info()\n",
    "    print(f'Scheduled prediction: Success. Date: {today}, Time: {time}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make and post predictions: Predict task    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled prediction starting. Date: 2022-10-19, Time: 11:45:52.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-389762183528>:27: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series. To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  ts.dayofyear, ts.weekofyear, ts.weekday, ts.quarter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (213,)\n",
      "Scheduled prediction: Success. Date: 2022-10-19, Time: 11:45:56.\n"
     ]
    }
   ],
   "source": [
    "predict_task(\n",
    "    models, encoders, clusters, deploy_info,\n",
    "    google_credentials, conn_str, fill='mean',\n",
    "    timeout=5, report_ignored_features=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# API Endpoints - Retrieve predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str_id(obj):\n",
    "    obj['_id'] = str(obj['_id'])\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mongo client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = \"mongodb+srv://luisresende13:Gaia0333@pluvia-cluster.ea8fb4s.mongodb.net/?retryWrites=true&w=majority\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions collection endpoint docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endpoints\n",
    "\n",
    "Objeto(Prediction):\n",
    "    _id: string\n",
    "    timestamp: datetime\n",
    "    date: string\n",
    "    time: string\n",
    "    cluster_id: integer\n",
    "    cluster: string\n",
    "    range: string\n",
    "    probability: float\n",
    "    confidence: float\n",
    "    label: integer\n",
    "\n",
    "Descrição parâmetros\n",
    "\n",
    "    _id: Identidade da previsão\n",
    "    date: Data em que a previsão foi gerada\n",
    "    time: Horário em que a previsão foi gerada\n",
    "    cluster_id: Identidade da região associada à previsão (inteiro)\n",
    "    cluster: Nome da região associada á previsão\n",
    "    range: Alcançe da previsão (eríodo após o horário da previsão associado à probabilidade gerada). (Ex: 1h, 2h...)\n",
    "    probability: Probabilidade prevista de formação de bolsão na região com id 'cluster_id' e nome 'cluster'\n",
    "    confidence: Confiança da probabilidade prevista.\n",
    "    label: Previsão binária de fomração de bolsão na região com id 'cluster_id' e nome 'cluster' ('0' se a probabilidade for menor que 0.5, se não \n",
    "\n",
    "Endpoints:\n",
    "\n",
    "    1. predict/\n",
    "\n",
    "        Resposta: Objeto(Prediction)\n",
    "\n",
    "    2. predictions/\n",
    "\n",
    "        Resposta: Lista de Objeto(Prediction)\n",
    "\n",
    "        Parametros:\n",
    "        \n",
    "            Parâmetros de filtro:\n",
    "                _id: Identidade da previsão\n",
    "                date: Data em que a previsão foi gerada\n",
    "                time: Horário em que a previsão foi gerada\n",
    "                cluster_id: Identidade da região associada à previsão (inteiro)\n",
    "                cluster: Nome da região associada á previsão\n",
    "                range: Alcançe da previsão (eríodo após o horário da previsão associado à probabilidade gerada). (Ex: 1h, 2h...)\n",
    "                label: Previsão binária de fomração de bolsão na região com id 'cluster_id' e nome 'cluster' ('0' se a probabilidade for menor que 0.5, se não '1')\n",
    "\n",
    "            Parâmetros de controle de resposta:\n",
    "                \n",
    "                sort: Campo do Objeto(Prediciton) usado para ordenar objetos retornados.\n",
    "                sort_order: Estratégia de ordenação dos objetos. 1 para ascendente, 0 para descendente - (Inteiro)\n",
    "                limit: Limite de objetos retornados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endpoint params description:\n",
    "\n",
    "1. Documents will be filtered by the params matching fields in the documents.\n",
    "2. Params can have multiple values divided by comma, i.e '/predictions?cluster_id=0,1,2'\n",
    "3. Optional parameters:\n",
    "    1. sort -> field to sort by. Default: 'timestamp'\n",
    "    2. sort_order -> '1' or '-1'. Default: '-1'\n",
    "    3. limit -> integer greater than 1. Default: None\n",
    "    \n",
    "#### Request url examples:\n",
    "\n",
    "1. /predictions?cluster_id=0,1,2&date=2022-09-27\n",
    "2. /predictions?cluster_id=0&sort=timestamp&sort_order=-1\n",
    "3. /predictions?cluster_id=0&limit=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_param_processing(query):\n",
    "    \n",
    "    if 'limit' not in query.keys():\n",
    "        limit = None            # Default limit\n",
    "    else:\n",
    "        limit = int(query['limit'])\n",
    "        del query['limit']\n",
    "    \n",
    "    if 'sort' not in query.keys():\n",
    "        sort_by = 'timestamp'   # Default sorting\n",
    "        sort_order = -1\n",
    "    else:\n",
    "        sort_by = query['sort']\n",
    "        del query['sort']\n",
    "        if 'sort_order' not in query.keys():\n",
    "            sort_order = -1     # Default sort order\n",
    "        else:\n",
    "            sort_order = int(query['sort_order'])\n",
    "            del query['sort_order']\n",
    "            \n",
    "    query_spread = {key: {'$in': str(value).split(',')} for key, value in query.items()}    \n",
    "    return query_spread, sort_by, sort_order, limit\n",
    "\n",
    "def prediction_records(query):\n",
    "    query_spread, sort_by, sort_order, limit = url_param_processing(query)\n",
    "    print(\n",
    "        'Endpoint Request: /predictions. Query Params:', query_spread,\n",
    "        ' URL Params:', {'sort': sort_by, 'sort_order': sort_order, 'limit': limit}\n",
    "    )\n",
    "    client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=15000)\n",
    "    docs = client.Waterbag.Prediction.find(query_spread).sort([(sort_by, sort_order)])\n",
    "    if limit is not None:\n",
    "        docs = docs.limit(limit)\n",
    "    return list(map(to_str_id, docs)) # prediction object list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example query request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Request: /predictions. Query Params: {'date': {'$in': ['2022-10-17']}}  URL Params: {'sort': 'cluster_id', 'sort_order': -1, 'limit': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'_id': '634d977e35152c75c3d2ac8d',\n",
       "  'timestamp': datetime.datetime(2022, 10, 17, 14, 56, 56, 563000),\n",
       "  'date': '2022-10-17',\n",
       "  'time': '14:56:56',\n",
       "  'cluster_id': 4,\n",
       "  'cluster': 'Avenida Ministro Ivan Lins',\n",
       "  'range': '1h',\n",
       "  'probability': 0.003713,\n",
       "  'confidence': 0.992574,\n",
       "  'label': 0},\n",
       " {'_id': '634d63a283a39eafc6713b29',\n",
       "  'timestamp': datetime.datetime(2022, 10, 17, 14, 16, 0, 5000),\n",
       "  'date': '2022-10-17',\n",
       "  'time': '11:16:00',\n",
       "  'cluster_id': 4,\n",
       "  'cluster': 'Avenida Ministro Ivan Lins',\n",
       "  'range': '1h',\n",
       "  'probability': 0.001821,\n",
       "  'confidence': 0.996358,\n",
       "  'label': 0},\n",
       " {'_id': '634d636683a39eafc6713b23',\n",
       "  'timestamp': datetime.datetime(2022, 10, 17, 14, 15, 0, 4000),\n",
       "  'date': '2022-10-17',\n",
       "  'time': '11:15:00',\n",
       "  'cluster_id': 4,\n",
       "  'cluster': 'Avenida Ministro Ivan Lins',\n",
       "  'range': '1h',\n",
       "  'probability': 0.001821,\n",
       "  'confidence': 0.996358,\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = request.args.to_dict() # Flask request url args\n",
    "query = {'date': '2022-10-17', 'sort': 'cluster_id' , 'sort_order': '-1', 'limit': '3'}\n",
    "\n",
    "prediction_records(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last timestamp predictions\n",
    "\n",
    "#### /predict endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cluster_id': 0,\n",
       "  '_id': '634d96f6df93fd4898334a06',\n",
       "  'timestamp': Timestamp('2022-10-17 17:55:00.001000'),\n",
       "  'date': '2022-10-17',\n",
       "  'time': '14:55:00',\n",
       "  'cluster': 'Avenida Armando Lombardi',\n",
       "  'range': '1h',\n",
       "  'probability': 0.001538,\n",
       "  'confidence': 0.996924,\n",
       "  'label': 0},\n",
       " {'cluster_id': 1,\n",
       "  '_id': '634d96f6df93fd4898334a07',\n",
       "  'timestamp': Timestamp('2022-10-17 17:55:00.001000'),\n",
       "  'date': '2022-10-17',\n",
       "  'time': '14:55:00',\n",
       "  'cluster': 'Rua do Catete',\n",
       "  'range': '1h',\n",
       "  'probability': 0.002576,\n",
       "  'confidence': 0.994848,\n",
       "  'label': 0},\n",
       " {'cluster_id': 2,\n",
       "  '_id': '634d96f6df93fd4898334a08',\n",
       "  'timestamp': Timestamp('2022-10-17 17:55:00.001000'),\n",
       "  'date': '2022-10-17',\n",
       "  'time': '14:55:00',\n",
       "  'cluster': 'Rua Tonelero',\n",
       "  'range': '1h',\n",
       "  'probability': 0.001867,\n",
       "  'confidence': 0.996266,\n",
       "  'label': 0},\n",
       " {'cluster_id': 3,\n",
       "  '_id': '634d96f6df93fd4898334a09',\n",
       "  'timestamp': Timestamp('2022-10-17 17:55:00.001000'),\n",
       "  'date': '2022-10-17',\n",
       "  'time': '14:55:00',\n",
       "  'cluster': 'Avenida Epitácio Pessoa',\n",
       "  'range': '1h',\n",
       "  'probability': 0.008189,\n",
       "  'confidence': 0.983623,\n",
       "  'label': 0},\n",
       " {'cluster_id': 4,\n",
       "  '_id': '634d977e35152c75c3d2ac8d',\n",
       "  'timestamp': Timestamp('2022-10-17 14:56:56.563000'),\n",
       "  'date': '2022-10-17',\n",
       "  'time': '14:56:56',\n",
       "  'cluster': 'Avenida Ministro Ivan Lins',\n",
       "  'range': '1h',\n",
       "  'probability': 0.003713,\n",
       "  'confidence': 0.992574,\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_prediction_record(limit=500):\n",
    "    \n",
    "    now = datetime.now(tz_br)\n",
    "    today = now.date().isoformat()\n",
    "    time = now.time().isoformat()[:8]\n",
    "    yesterday = (now - pd.offsets.Day()).date().isoformat()\n",
    "    \n",
    "    sort_by = [('timestamp', -1), ('cluster_id', 1)]\n",
    "    last_24h = {\n",
    "        \"$or\": [{\n",
    "            \"date\": today\n",
    "        }, {\n",
    "            '$and': [{'date': yesterday}, {'time': {'$gte': time}}]\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    ### Consult prediction database latest record\n",
    "    client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=15000)\n",
    "    first_docs = client.Waterbag.Prediction.find(last_24h).sort(sort_by).limit(limit)\n",
    "    first_docs = pd.DataFrame(list(map(to_str_id, first_docs))) # prediction object list\n",
    "    docs_clusters = first_docs.groupby('cluster_id', as_index=False).first()\n",
    "    \n",
    "    return list(docs_clusters.T.to_dict().values())\n",
    "\n",
    "last_prediction_record(limit=500)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Extra: Test predict endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_id\":\"632c32223e18981a9a002da8\",\"cluster\":\"Catete\",\"confidence\":0.9841241118565575,\"date\":\"2022-09-22\",\"probability\":0.00793794407172125,\"range\":\"1h\",\"time\":\"07:00:00\",\"timestamp\":\"Thu, 22 Sep 2022 10:00:00 GMT\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "api_url = 'https://bolsoes-api.herokuapp.com'\n",
    "\n",
    "print(requests.get(api_url + '/predict').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Post database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_table(docs, db='Waterbag', coll='Prediction', conn_str=None, timeout=15):\n",
    "    client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=int(timeout*1e3))\n",
    "    insert_result = client[db][coll].insert_many(docs)\n",
    "    if len(insert_result.inserted_ids) == 0:\n",
    "        raise(Exception('Insert to database failed! Nothing inserted.'))\n",
    "    else: print('Insert to database success! Inserted:', len(insert_result.inserted_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert to database success! Inserted: 80\n"
     ]
    }
   ],
   "source": [
    "# load cluster polygon dataset\n",
    "path_clusters = '../Dados/Clusters/clusters_micro.csv'\n",
    "clusters_docs = pd.read_csv(path_clusters).to_dict(orient='records')\n",
    "\n",
    "conn_str = \"mongodb+srv://luisresende13:Gaia0333@pluvia-cluster.ea8fb4s.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# post docs to database collection\n",
    "post_table(\n",
    "    clusters_docs,\n",
    "    db='Waterbag',\n",
    "    coll='ClustersMicro',\n",
    "    conn_str=conn_str, timeout=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Clean database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 24011,\n",
       " 'electionId': ObjectId('7fffffff000000000000000f'),\n",
       " 'opTime': {'ts': Timestamp(1666210990, 11019), 't': 15},\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1666210991, 1),\n",
       "  'signature': {'hash': b\",a\\xce\\x05_\\x1d\\x1b\\xf9\\xfc\\xb6#\\xb7D'\\xf4\\xa2\\xf5\\xed\\x17d\",\n",
       "   'keyId': 7123989338215415813}},\n",
       " 'operationTime': Timestamp(1666210990, 11019)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_str = \"mongodb+srv://luisresende13:Gaia0333@pluvia-cluster.ea8fb4s.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "client = pymongo.MongoClient(conn_str, serverSelectionTimeoutMS=15000)\n",
    "\n",
    "delete_res = client.Waterbag.Prediction.delete_many({})\n",
    "\n",
    "delete_res.raw_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
