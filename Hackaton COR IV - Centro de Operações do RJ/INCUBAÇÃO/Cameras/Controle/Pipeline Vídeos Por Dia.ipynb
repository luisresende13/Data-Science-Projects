{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video processing pipeline to concat and accelerate flood videos from Google Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose base directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\Desktop\\Repositories\\Data Science Projects\\Hackaton COR IV - Centro de Operações do RJ\\INCUBAÇÃO\\Cameras\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# Simples class to report execution time\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.start = time()\n",
    "    def end(self, decimals=4):\n",
    "        end = time() - self.start\n",
    "        print('\\n* TIME TO EXECUTE:', round(end, decimals), 's')\n",
    "        \n",
    "# Get blob count, bytes and names from Google Cloud Storage bucket\n",
    "\n",
    "def gcs_folder_info(folder, ext, bucket_name, print_each=1000):\n",
    "    prefix = folder\n",
    "    delimiter = None\n",
    "    names = []\n",
    "    timer = Timer()\n",
    "    blobs = gcs.list_blobs(prefix, delimiter, bucket_name)\n",
    "    for i, blob in enumerate(blobs):\n",
    "        if blob.name.endswith(ext):\n",
    "            names.append([blob.name, blob.size])\n",
    "        if (i + 1) % print_each == 0: print(f'\\n- Blobs Searched: {i + 1}'); co(True)\n",
    "    names = pd.DataFrame(names, columns=['blob_name', 'bytes']) # build blobs dataframe\n",
    "    print(f'\\n- Blobs Searched: {i + 1}')\n",
    "    print(f'\\n  · Blobs (Matched): {len(names)}')\n",
    "    print(f'\\n  · Giga Bytes (Matched): {round(names[\"bytes\"].sum() / 1e9, 3)} GB')\n",
    "    timer.end() # prints time to execute\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline methods set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Google Cloud Storage wrapper module and set storage instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.googlecloudstorage import GCS\n",
    "\n",
    "sa_json = '../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'\n",
    "user_project = None\n",
    "default_bucket_name = 'flood-video-collection'\n",
    "\n",
    "gcs = GCS(sa_json, user_project, default_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video writer class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisr\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from modules.video import VideoWriter\n",
    "\n",
    "writer = VideoWriter(fps=3, shape=(854, 480), codec='mp4v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accelerated video writer class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.video import VideoWriter\n",
    "\n",
    "writer_speed = VideoWriter(fps=24, shape=(854, 480), codec='mp4v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video writer class funcitonality\n",
    "1. Add running clock to video files\n",
    "2. Concatenate video files from nested folders\n",
    "3. Accelerate video files from nested folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Count blobs with .mp4 extension and total file bytes of download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output as co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pipeline Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 · Pipeline parameters set up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download from Google Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note: Forward trailing slashses, i.e. `/`, at the end of `prefix` limits\n",
    "results to folders matching exactly to `prefix`. Otherwise, matches any folder or blob\n",
    "that contains `prefix`.\n",
    "'''\n",
    "bucket_name = 'flood-video-collection'\n",
    "prefix = 'polygons/flood/'\n",
    "delimiter = None\n",
    "folder = 'Dados/flood-video-collection' # bucket collection destination folder\n",
    "report_freq = 5\n",
    "overwrite_download = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotate videos timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Dados/flood-video-collection'  # local collection source folder\n",
    "to_folder = 'Dados/flood-video-collection-stamped' # `time-stamped` local collection source folder\n",
    "ext = '.mp4' # video file format to search for in nested folders\n",
    "overwrite_annot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate and accelerate videos from folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = 'Dados/flood-video-collection-stamped' # `time-stamped` local collection source folder\n",
    "to_base_folder = 'Dados/flood-video-collection-date' # concatenated local collection destination folder\n",
    "overwrite_concat = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General purposes parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0.1 · List and count blobs and download bytes · ***Preparation Step***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Blobs Searched: 1181\n",
      "\n",
      "  · Blobs (Matched): 1181\n",
      "\n",
      "  · Giga Bytes (Matched): 0.783 GB\n",
      "\n",
      "* TIME TO EXECUTE: 1.0821 s\n"
     ]
    }
   ],
   "source": [
    "folder_info = gcs_folder_info(prefix, ext, bucket_name, print_each=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 · Download  blobs in Cloud Storage bucket to folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1 · Download blobs in `bucket_name` matching `prefix` to local `folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREFIX: polygons/flood/ · RUNNING: 13.5 min · RATE: 0.6854 s / file · FINISH-ESTIMATE: 0.0 min · PROGRESS: 1180/1181 · DOWNLOADS: 995/1181\n",
      "\n",
      "* TIME TO EXECUTE: 810.7053 s\n"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "\n",
    "gcs.download_to_folder(folder, prefix, delimiter, bucket_name, report_freq, overwrite_download)\n",
    "\n",
    "timer.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 · Annotate videos with dinamic timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add clock timestamp to nested video files in `folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIDEO TIMESTAMP ANNOTATION · DONE: 996/996 · SUCCESS: 996/996\n",
      "\n",
      "* TIME TO EXECUTE: 264.6119 s\n"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "\n",
    "writer.annot_folder_nested(folder, to_folder, ext, overwrite_annot)\n",
    "\n",
    "timer.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 · Concatenate and accelerate videos from folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate videos by date from nested folders in `base_folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CONCAT VIDEOS FROM FOLDER BY DATE · DONE: 57/57 · FOLDER: polygons/flood/8/267\n",
      "\n",
      "* TIME TO EXECUTE: 220.7912 s\n"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "\n",
    "writer_speed.concatenate_videos_from_nested_folders_by_date(\n",
    "    base_folder, to_base_folder, ext, overwrite_concat\n",
    ")\n",
    "\n",
    "timer.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
