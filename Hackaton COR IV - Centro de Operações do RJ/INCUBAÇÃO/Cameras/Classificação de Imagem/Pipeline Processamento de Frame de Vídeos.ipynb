{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to  Process Frames from Multiple Video Files  · Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\Desktop\\Repositories\\Data Science Projects\\Hackaton COR IV - Centro de Operações do RJ\\INCUBAÇÃO\\Cameras\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to display train and test classes counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisr\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_class_count(y_train, y_test):\n",
    "    display(pd.concat([\n",
    "        pd.Series(y_train).value_counts().to_frame('Train set'),\n",
    "        pd.Series(y_test).value_counts().to_frame('Test set')\n",
    "    ], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class to load frames from labeled videos as labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, numpy as np, pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "def timestamp_parser(path):\n",
    "    file_name = path.split('/')[-1]\n",
    "    stamp = ' '.join(file_name.split(' ')[1:])\n",
    "    return dt.strptime(stamp, '%Y-%m-%d %H-%M-%S.mp4')\n",
    "\n",
    "class VideoImageProcessing:\n",
    "        \n",
    "    def __init__(self, dim=1, process=None, fps=3, timestamp_parser=timestamp_parser):\n",
    "        \"\"\"  \"\"\"\n",
    "        self.dim = dim\n",
    "        self.process = process\n",
    "        self.fps = fps\n",
    "        self.timestamp_parser = timestamp_parser\n",
    "        \n",
    "    def apply_to_frames_from_labeled_videos(self, videos, path_key, print_each=None):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "            videos - pandas dataframe containing a column with name `path_key`, with paths to a set of videos.\n",
    "            path_key - name of column containing path to videos in local file system\n",
    "        \"\"\"\n",
    "        i, n  = 0, len(videos)\n",
    "        results = []\n",
    "        for idx, video_object in videos.iterrows():\n",
    "            frames_results = self.apply_to_frames(video_object, path_key)\n",
    "            results += frames_results\n",
    "            i += 1\n",
    "            if print_each is not None and i % print_each == 0:\n",
    "                co(True); print(f'LABELED VIDEOS PROCESSING · PROGRESS: {i}/{n}')\n",
    "        return results\n",
    "\n",
    "    def apply_to_frames(self, video_object, path_key):\n",
    "        path = video_object[path_key]\n",
    "        timestamp = None\n",
    "        if self.timestamp_parser is not None:\n",
    "            timestamp = self.timestamp_parser(path)\n",
    "            offset = pd.offsets.Second() / self.fps\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"CANNOT OPEN VIDEO CAPTURE · PATH: {path}\")\n",
    "            return []\n",
    "        frames_results = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break # stream finished\n",
    "            if self.dim == 1: # 1D flat frame\n",
    "                frame = np.reshape(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), -1)\n",
    "            if self.dim == 2: # 2D gray scale frame\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            if self.timestamp_parser is not None:\n",
    "                timestamp += offset # frame time stamp update\n",
    "            result = self.process(frame, metadata=video_object.to_dict(), timestamp=timestamp)\n",
    "            frames_results.append(result)\n",
    "        cap.release(); cv2.destroyAllWindows()\n",
    "        return frames_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class to write videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "\n",
    "class Video:\n",
    "\n",
    "    def __init__(self, codec:str='mp4v', fps:int=3, shape:tuple=(854, 480), overwrite=False):\n",
    "        self.codec = codec; self.fps = fps; self.shape = shape\n",
    "        self.overwrite = overwrite\n",
    "\n",
    "    def writer(self, path):\n",
    "        if not self.overwrite and os.path.exists(path):\n",
    "            print(f'ANNOTATE VIDEO TIMESTAMP FAILED. FILE ALREADY EXISTS · FILE-PATH: {path}')\n",
    "            return False\n",
    "        return cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*self.codec), self.fps, self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List nested sub-directories from given folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "def inner_subdirs(folder, ext='.mp4'):\n",
    "    if folder.endswith('/'): folder = folder[:-1]\n",
    "    folder_depth = len(folder.split('/'))\n",
    "    in_subdirs = []\n",
    "    for path, subdirs, files in os.walk(folder):\n",
    "        if os.path.isdir(path) and any([file.endswith(ext) for file in files]):\n",
    "            subpath = '/'.join(path.split('\\\\')[1:])\n",
    "            in_subdirs.append(subpath)\n",
    "    return in_subdirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reload labeled flood videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blob_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:25:00</th>\n",
       "      <td>polygons/flood-unlabeled/1/1475/CODE1475 2023-...</td>\n",
       "      <td>alagamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:30:00</th>\n",
       "      <td>polygons/flood-unlabeled/1/1475/CODE1475 2023-...</td>\n",
       "      <td>alagamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:35:00</th>\n",
       "      <td>polygons/flood-unlabeled/1/1475/CODE1475 2023-...</td>\n",
       "      <td>alagamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:40:00</th>\n",
       "      <td>polygons/flood-unlabeled/1/1475/CODE1475 2023-...</td>\n",
       "      <td>alagamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:50:00</th>\n",
       "      <td>polygons/flood-unlabeled/1/1475/CODE1475 2023-...</td>\n",
       "      <td>alagamento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             blob_name   \n",
       "timestamp                                                                \n",
       "2023-02-07 19:25:00  polygons/flood-unlabeled/1/1475/CODE1475 2023-...  \\\n",
       "2023-02-07 19:30:00  polygons/flood-unlabeled/1/1475/CODE1475 2023-...   \n",
       "2023-02-07 19:35:00  polygons/flood-unlabeled/1/1475/CODE1475 2023-...   \n",
       "2023-02-07 19:40:00  polygons/flood-unlabeled/1/1475/CODE1475 2023-...   \n",
       "2023-02-07 19:50:00  polygons/flood-unlabeled/1/1475/CODE1475 2023-...   \n",
       "\n",
       "                            tag  \n",
       "timestamp                        \n",
       "2023-02-07 19:25:00  alagamento  \n",
       "2023-02-07 19:30:00  alagamento  \n",
       "2023-02-07 19:35:00  alagamento  \n",
       "2023-02-07 19:40:00  alagamento  \n",
       "2023-02-07 19:50:00  alagamento  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (165, 8)\n",
      "\n",
      " - Shape after processing: (163, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "videos = pd.read_csv('Dados/Rotulos/1475_2023-02-07.csv')\n",
    "\n",
    "# preprocessing - blob/file name fix · replace `:` for `-`\n",
    "videos['blob_name'] = [blob_name.replace(':', '-') for blob_name in videos['blob_name']]\n",
    "\n",
    "# preprocessing - datetime conversion\n",
    "videos['timestamp'] = pd.to_datetime(videos['timestamp'])\n",
    "videos = videos.set_index('timestamp', drop=True).sort_index()\n",
    "\n",
    "# preprocessing - drop videos larger than `video_max_bytes`\n",
    "video_max_bytes = 5e6 # 5 Mb\n",
    "original_shape = videos.shape\n",
    "videos = videos[videos['blob_size'] < video_max_bytes]\n",
    "\n",
    "display(videos[['blob_name', 'tag']].head())\n",
    "print(f'Shape: {original_shape}')\n",
    "print(f'\\n - Shape after processing: {videos.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Video Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarize target variable categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Samples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normalidade</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acúmulo</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Video Samples\n",
       "label                     \n",
       "normalidade            128\n",
       "acúmulo                 35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "replace_tags = {\n",
    "    'acúmulo': ['lâmina', 'bolsão', 'alagamento'],\n",
    "    'normalidade': ['poça', 'normalidade'],\n",
    "}\n",
    "\n",
    "y_true = []\n",
    "for tag in videos['tag']:\n",
    "    for key, values in replace_tags.items():\n",
    "        if tag in values: y_true.append(key)\n",
    "\n",
    "y_true = pd.Series(y_true, index=videos.index)\n",
    "\n",
    "videos['label'] = y_true\n",
    "\n",
    "display(videos['label'].value_counts().to_frame('Video Samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Video Data Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional · Train and test split of video samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train set</th>\n",
       "      <th>Test set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normalidade</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acúmulo</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Train set  Test set\n",
       "label                           \n",
       "normalidade          5         5\n",
       "acúmulo              1         2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complete sample set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normalidade</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acúmulo</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Complete sample set\n",
       "label                           \n",
       "normalidade                   10\n",
       "acúmulo                        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "t_size = 0.04\n",
    "e_size = 0.04\n",
    "\n",
    "# X, Y = x_res, y_res  # pre-sampled\n",
    "X, Y = videos, videos['label']  # complete set of videos\n",
    "\n",
    "xt, xe, yt, ye = train_test_split(\n",
    "    X, Y, test_size=e_size, train_size=t_size,\n",
    "    random_state=random_state, shuffle=True, stratify=Y\n",
    ")\n",
    "\n",
    "# complete x and y sequences\n",
    "yy = pd.concat([yt, ye], axis=0)\n",
    "xx = pd.concat([xt, xe], axis=0)\n",
    "\n",
    "split_class_count(yt, ye)\n",
    "display(yy.value_counts().to_frame('Complete sample set'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Flood Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load flood image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, pandas as pd\n",
    "\n",
    "filename = 'code1475.sav'\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image classification prediction and metadata\n",
    "\n",
    "def classify_image(frame, metadata, timestamp=None):\n",
    "    prediction = model.predict([frame])[0]\n",
    "    return pd.Series({\n",
    "        'prediction': prediction,\n",
    "        'timestamp': timestamp,\n",
    "        **metadata\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Classifiy images from selected labeled videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Videos frames pipeline · Frame image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELED VIDEOS PROCESSING · PROGRESS: 163/163\n",
      "\n",
      "Videos Selected: 163\n",
      "Frames Loaded: 5419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder = 'Dados/flood-video-collection-stamped'\n",
    "process = classify_image\n",
    "\n",
    "# XX, YY = xx.copy(), yy.copy()  # pre-sampled from loaded videos dataset\n",
    "XX, YY = videos.copy(), videos['label'].copy()  # complete loaded videos dataset\n",
    "\n",
    "XX['path'] = [f'{folder}/{blob_name}' for blob_name in XX['blob_name']]\n",
    "\n",
    "pipeline = VideoImageProcessing(dim=1, process=process)\n",
    "results= pipeline.apply_to_frames_from_labeled_videos(videos=XX.reset_index(), path_key='path', print_each=1)\n",
    "\n",
    "print(f'\\nVideos Selected: {len(XX)}')\n",
    "print(f'Frames Loaded: {len(results)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     acúmulo       0.00      0.00      0.00       105\n",
      " normalidade       0.77      1.00      0.87       347\n",
      "\n",
      "    accuracy                           0.77       452\n",
      "   macro avg       0.38      0.50      0.43       452\n",
      "weighted avg       0.59      0.77      0.67       452\n",
      "\n",
      "\n",
      " * Accuracy: 0.77\n",
      "\n",
      " * Mislabeled data points: 105 / 452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luisr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\luisr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "frames = pd.DataFrame(results)\n",
    "\n",
    "#### Classification Simulation Report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get frames labels and predictions\n",
    "y_true = frames['label']\n",
    "y_pred = frames['prediction']\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(f'\\n * Accuracy: {round((y_true == y_pred).mean(), 2)}')\n",
    "print(f'\\n * Mislabeled data points: {(y_true != y_pred).sum()} / {len(y_true)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Concatenate labeled videos from single camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom functions to process videos' frames individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_to_video(frame, text):\n",
    "    cv2.putText(frame, text, org=(542, 27), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "    fontScale=0.67, color=(0, 0, 0), thickness=2, lineType=cv2.LINE_8)\n",
    "    cv2.putText(frame, text, org=(540, 25), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "    fontScale=0.67, color=(40, 230, 230), thickness=2, lineType=cv2.LINE_8)\n",
    "    return frame\n",
    "\n",
    "def history_write(frame, metadata, timestamp):\n",
    "    frame_1d = np.reshape(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), -1) # 1D from gray 2D image (reduces columns 3 times)\n",
    "    timestamp_str =  timestamp.strftime('OCTA %d/%m/%Y %H:%M:%S')\n",
    "    label = metadata['label']\n",
    "    prediction = model.predict([frame_1d])[0]\n",
    "    frame = add_text_to_video(frame, timestamp_str)  # put timestamp text\n",
    "    text_label = f'Rotulo: {label.upper().replace(\"Ú\", \"U\")}'\n",
    "    text_prediction = f'Previsao (IA): {prediction.upper().replace(\"Ú\", \"U\")}'\n",
    "    cv2.putText(\n",
    "        frame, text_label, org=(20, 425), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.67, color=(40, 230, 230), thickness=2\n",
    "    )\n",
    "    cv2.putText(\n",
    "        frame, text_prediction, org=(20, 460), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.67, color=(40, 230, 230), thickness=2\n",
    "    )\n",
    "    history_writer.write(frame)\n",
    "    return {\n",
    "#         'frame': frame,\n",
    "        'write': 'success',\n",
    "        'prediction': prediction,\n",
    "        'timestamp': timestamp,\n",
    "        **metadata,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Videos frames pipeline · Concatenate multiple videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELED VIDEOS PROCESSING · PROGRESS: 163/163\n",
      "\n",
      "Videos Selected: 163\n",
      "Frames Loaded: 5419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder = 'Dados/flood-video-collection'\n",
    "full_history_video_path = 'Dados/Simulação/history-labeled-code1475.mp4'\n",
    "process = history_write\n",
    "\n",
    "# XX, YY = xx.copy(), yy.copy()  # pre-sampled from loaded videos dataset\n",
    "XX, YY = videos.copy(), videos['label'].copy()  # complete loaded videos dataset\n",
    "\n",
    "XX['path'] = [f'{folder}/{blob_name}' for blob_name in XX['blob_name']]\n",
    "\n",
    "# OPEN VIDEO FILE WRITER\n",
    "video = Video(overwrite=True, fps=15)\n",
    "history_writer = video.writer(path=full_history_video_path)\n",
    "\n",
    "# RUN FRAME PIPELINE\n",
    "pipeline = VideoImageProcessing(dim=3, process=process)\n",
    "results = pipeline.apply_to_frames_from_labeled_videos(videos=XX.sort_index().reset_index(), path_key='path', print_each=1)\n",
    "\n",
    "# CLOSE/RELEASE VIDEO FILE WRITER\n",
    "history_writer.release(); cv2.destroyAllWindows()\n",
    "\n",
    "print(f'\\nVideos Selected: {len(XX)}')\n",
    "print(f'Frames Loaded: {len(results)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operation Success</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>success</th>\n",
       "      <td>5419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Operation Success\n",
       "write                     \n",
       "success               5419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     acúmulo       0.94      0.94      0.94       978\n",
      " normalidade       0.99      0.99      0.99      4441\n",
      "\n",
      "    accuracy                           0.98      5419\n",
      "   macro avg       0.96      0.97      0.96      5419\n",
      "weighted avg       0.98      0.98      0.98      5419\n",
      "\n",
      "\n",
      " * Accuracy: 0.98\n",
      "\n",
      " * Mislabeled data points: 115 / 5419\n"
     ]
    }
   ],
   "source": [
    "frames_concat = pd.DataFrame(results)\n",
    "\n",
    "#### Classification Simulation Report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get frames labels and predictions\n",
    "y_true = frames_concat['label']\n",
    "y_pred = frames_concat['prediction']\n",
    "\n",
    "display(frames_concat['write'].value_counts().to_frame('Operation Success'))\n",
    "print()\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(f'\\n * Accuracy: {round((y_true == y_pred).mean(), 2)}')\n",
    "print(f'\\n * Mislabeled data points: {(y_true != y_pred).sum()} / {len(y_true)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
