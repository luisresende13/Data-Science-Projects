{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate Camera History with Flood Classification Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\Desktop\\Repositories\\Data Science Projects\\Hackaton COR IV - Centro de Operações do RJ\\INCUBAÇÃO\\Cameras\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class to load frames from labeled videos as labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.video_frame_processing import VideoProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to binarize target variable class labels * CHANGE FUNCTION NAME TO `replace_tags(y, tags)` or something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def relabel(Y: pd.Series, labels: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Relabels the given Pandas series with the corresponding label from the given dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    Y (pd.Series): Pandas series to relabel\n",
    "    labels (dict): Dictionary containing the corresponding labels for each tag\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: Relabeled Pandas series\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    for tag in Y:\n",
    "        for key, values in labels.items():\n",
    "            if tag in values:\n",
    "                y_true.append(key)\n",
    "                break\n",
    "    return pd.Series(y_true, index=Y.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to display target variable class count of train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_class_count(y_train, y_test):\n",
    "    display(pd.concat([\n",
    "        pd.Series(y_train).value_counts().to_frame('Train set'),\n",
    "        pd.Series(y_test).value_counts().to_frame('Test set')\n",
    "    ], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class to write videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "\n",
    "class Video:\n",
    "\n",
    "    def __init__(self, codec:str='mp4v', fps:int=3, shape:tuple=(854, 480), overwrite=False):\n",
    "        self.codec = codec; self.fps = fps; self.shape = shape\n",
    "        self.overwrite = overwrite\n",
    "\n",
    "    def writer(self, path):\n",
    "        if not self.overwrite and os.path.exists(path):\n",
    "            print(f'ANNOTATE VIDEO TIMESTAMP FAILED. FILE ALREADY EXISTS · FILE-PATH: {path}')\n",
    "            return False\n",
    "        return cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*self.codec), self.fps, self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the camera code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 1487 # 1475 # 1649 # 1648 # 1487\n",
    "\n",
    "dataset_date = '2023-04-29'\n",
    "model_date = '2023-05-06'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Reload labeled flood videos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blob_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:25:00</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:30:00</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:35:00</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:50:00</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 19:54:00</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             blob_name  tag\n",
       "timestamp                                                                  \n",
       "2023-02-07 19:25:00  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  0.2\n",
       "2023-02-07 19:30:00  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  0.2\n",
       "2023-02-07 19:35:00  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  0.2\n",
       "2023-02-07 19:50:00  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  1.0\n",
       "2023-02-07 19:54:00  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (360, 8)\n",
      "\n",
      " - Shape after processing: (360, 8)\n",
      "\n",
      "Total video bytes: 338.954 Mb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "videos = pd.read_csv(f'Dados/Rotulados/videos_labeled_CODE{code}_{dataset_date}.csv')\n",
    "\n",
    "# preprocessing - blob/file name fix · replace `:` for `-`\n",
    "videos['blob_name'] = [blob_name.replace(':', '-') for blob_name in videos['blob_name']]\n",
    "\n",
    "# preprocessing - datetime conversion\n",
    "videos['timestamp'] = pd.to_datetime(videos['timestamp'])\n",
    "videos = videos.set_index('timestamp', drop=True).sort_index()\n",
    "\n",
    "# preprocessing - drop videos larger than `video_max_bytes`\n",
    "video_max_bytes = 5e6 # 5 Mb\n",
    "original_shape = videos.shape\n",
    "# videos = videos[videos['blob_size'] < video_max_bytes]\n",
    "\n",
    "display(videos[['blob_name', 'tag']].head())\n",
    "print(f'Shape: {original_shape}')\n",
    "print(f'\\n - Shape after processing: {videos.shape}')\n",
    "\n",
    "mega_bytes = round(videos[\"blob_size\"].sum() / 1e6, 3)\n",
    "print(f'\\nTotal video bytes: {mega_bytes} Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Reload labeled flood images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blob_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>polygons/flood-unlabeled/-1/1487/CODE1487 2023...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           blob_name  tag\n",
       "0  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  0.2\n",
       "1  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  0.2\n",
       "2  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  0.2\n",
       "3  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  0.2\n",
       "4  polygons/flood-unlabeled/-1/1487/CODE1487 2023...  0.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (11354, 10)\n",
      "\n",
      " - Shape after processing: (11354, 10)\n",
      "\n",
      "Total video bytes: 265.168 Mb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# code = 1648 # 1487\n",
    "\n",
    "images = pd.read_csv(f'Dados/Rotulados/images_labeled_CODE{code}_{dataset_date}.csv')\n",
    "\n",
    "# preprocessing\n",
    "images.sort_values('image_timestamp', inplace=True)\n",
    "# images['image_timestamp'] = pd.to_datetime(images['image_timestamp'])\n",
    "# images = images.set_index('image_timestamp', drop=True).sort_index()\n",
    "\n",
    "# drop images larger than `video_max_bytes`\n",
    "image_max_bytes = 5e6 # 5 Mb\n",
    "original_shape = images.shape\n",
    "# images = images[images['blob_size'] < image_max_bytes]\n",
    "\n",
    "display(images[['blob_name', 'tag']].head())\n",
    "print(f'Shape: {original_shape}')\n",
    "print(f'\\n - Shape after processing: {images.shape}')\n",
    "\n",
    "mega_bytes = round(images.drop_duplicates('blob_name')[\"blob_size\"].sum() / 1e6, 3)\n",
    "print(f'\\nTotal video bytes: {mega_bytes} Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set image reference dataset · IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_tags = {\n",
    "#     'acúmulo': ['lâmina', 'bolsão', 'alagamento'],\n",
    "#     'normalidade': ['poça', 'normalidade'],\n",
    "# }\n",
    "\n",
    "replace_tags = {\n",
    "    0: [0.0],\n",
    "    1: [0.2],\n",
    "    2: [0.4],\n",
    "    3: [0.6],\n",
    "    4: [0.8],\n",
    "    5: [1.0],\n",
    "}\n",
    "\n",
    "image_reference = images.set_index(['blob_name', 'image_timestamp'])\n",
    "image_reference['label'] = relabel(images['tag'], replace_tags).values # overrides `label` field from videos dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Video Metadata Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarize target variable categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video Samples\n",
       "0            276\n",
       "1             70\n",
       "3              6\n",
       "5              5\n",
       "2              3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace_tags = {\n",
    "#     'acúmulo': ['lâmina', 'bolsão', 'alagamento'],\n",
    "#     'normalidade': ['poça', 'normalidade'],\n",
    "# }\n",
    "\n",
    "replace_tags = {\n",
    "    0: [0.0],\n",
    "    1: [0.2],\n",
    "    2: [0.4],\n",
    "    3: [0.6],\n",
    "    4: [0.8],\n",
    "    5: [1.0],\n",
    "}\n",
    "\n",
    "videos['label'] = relabel(videos['tag'], replace_tags)  # update videos dataset\n",
    "\n",
    "display(videos['label'].value_counts().to_frame('Video Samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Flood Image Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class to wrap regression models with rounded prediction functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RounderRegressor:\n",
    "    \n",
    "    bins_default = np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "    def __init__(self, model=None, fitted_model=None, bins=bins_default):\n",
    "        self.model = model\n",
    "        self.fitted_model = fitted_model\n",
    "        self.bins = bins\n",
    "        \n",
    "    def round_close(self, Y, bins=bins_default):\n",
    "        Y_round = []\n",
    "        for value in Y:\n",
    "            diffs = np.abs(bins - value)\n",
    "            rounded_value = bins[diffs==diffs.min()][0]\n",
    "            Y_round.append(rounded_value)\n",
    "        return np.array(Y_round)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.fitted_model = self.model.fit(x, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_pred = self.fitted_model.predict(x)\n",
    "        y_pred_round = self.round_close(y_pred, self.bins)\n",
    "        return y_pred_round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load flood image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, pandas as pd\n",
    "\n",
    "# code = 1648\n",
    "\n",
    "file_name = f'models/water-level/code{code}_{model_date}.sav'\n",
    "model = pickle.load(open(file_name, 'rb'))\n",
    "\n",
    "# Image processing function\n",
    "\n",
    "# Get image classification model prediction and metadata\n",
    "\n",
    "def classify_image(frame, metadata, timestamp=None):\n",
    "    prediction = model.predict([frame])[0]\n",
    "    return pd.Series({\n",
    "        'prediction': prediction,\n",
    "        'timestamp': timestamp,\n",
    "        **metadata\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Histogram Dissimilarity Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import modules\n",
    "\n",
    "import cv2\n",
    "from modules.histcomparison import HistogramDissimilarityAnalysis\n",
    "\n",
    "# Function to load HDA model\n",
    "\n",
    "def get_hda(code, folder):\n",
    "    code_ref = f'{folder}/{code}/reference'\n",
    "    base_str = f'CODE{code}'\n",
    "    base_filepath = f'{code_ref}/{base_str}_'\n",
    "    code_back = cv2.imread(f\"{base_filepath}MEAN.jpg\")\n",
    "    code_mask = cv2.imread(f\"{base_filepath}MASK.jpg\")\n",
    "    code_day = cv2.imread(f\"{base_filepath}day.jpg\")\n",
    "    code_night = cv2.imread(f\"{base_filepath}night.jpg\")\n",
    "    code_puddle = cv2.imread(f\"{base_filepath}puddle.jpg\")\n",
    "    code_flood = cv2.imread(f\"{base_filepath}flood.jpg\")\n",
    "    return HistogramDissimilarityAnalysis(code, code_back, code_mask, code_day, code_night, code_puddle, code_flood)\n",
    "\n",
    "\n",
    "# Load model instance\n",
    "\n",
    "# code = 1648\n",
    "model = get_hda(code, folder='Dados/images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Process labeled videos from single camera\n",
    "\n",
    "#### Processing pipeline:\n",
    "1. Classify frame\n",
    "1. Annotate frame with timestamp, label and prediction\n",
    "1. Write frame to video file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom functions to process videos' frames individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def blob_name_path_fix(blob_name):\n",
    "    blob_info = blob_name.split('/')\n",
    "    file_info = blob_info[-1].split(' ')\n",
    "    file_time_fix = file_info[-1].replace('-', ':')\n",
    "    blob_name_fix = '/'.join(blob_info[:-1] + [' '.join(file_info[:-1] + [file_time_fix])])\n",
    "    return blob_name_fix\n",
    "\n",
    "def round_ms(stamp):\n",
    "    n_digits = len(stamp)\n",
    "    if n_digits > 23:\n",
    "        digits_out = - (n_digits - 23)\n",
    "        stamp = stamp[:digits_out]\n",
    "    elif n_digits < 23 and n_digits > 19:\n",
    "        digits_in = 23 - n_digits\n",
    "        stamp = stamp + '0' * digits_in\n",
    "    elif n_digits <= 19:\n",
    "        digits_in = 19 - n_digits\n",
    "        stamp = stamp + '0' * digits_in + '.' + '000'\n",
    "    return stamp\n",
    "\n",
    "def add_timestamp_to_frame(frame, text):\n",
    "    cv2.putText(frame, text, org=(542, 27), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "    fontScale=0.67, color=(0, 0, 0), thickness=2, lineType=cv2.LINE_8)\n",
    "    cv2.putText(frame, text, org=(540, 25), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "    fontScale=0.67, color=(40, 230, 230), thickness=2, lineType=cv2.LINE_8)\n",
    "    return frame\n",
    "\n",
    "def history_write(frame, timestamp, metadata):\n",
    "    \n",
    "    \"\"\"\n",
    "    expects to be deefined outside of function:\n",
    "        model - model with predict method\n",
    "        history_writer\n",
    "        image_reference\n",
    "        LABEL_TYPE\n",
    "        MODEL_TYPE\n",
    "    \"\"\"\n",
    "        \n",
    "    # get image`blob_name` and `image_timstamp` references\n",
    "    blob_name = metadata['blob_name']\n",
    "    \n",
    "    # fix `blob_name` file name format\n",
    "    blob_name_fix = blob_name_path_fix(blob_name)\n",
    "    \n",
    "    # format image timestamp to match the image dataset's format\n",
    "    image_timestamp = timestamp.round('ms')  # round timestamp to miliseconds\n",
    "    image_timestamp_str = round_ms(str(image_timestamp))  # round seconds of timestamp string to 3 decimal places\n",
    "    \n",
    "    # get image metadata\n",
    "    image_metadata = {'label': ''}\n",
    "    for name in (blob_name, blob_name_fix): \n",
    "        idx = (name, image_timestamp_str)\n",
    "        try:\n",
    "            image_metadata = image_reference.loc[idx]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # format image timestamp string\n",
    "    timestamp_str =  timestamp.strftime('OCTA %d/%m/%Y %H:%M:%S')\n",
    "    frame = add_timestamp_to_frame(frame, timestamp_str)  # put timestamp text\n",
    "\n",
    "    # get image label\n",
    "    # label = metadata['label']  # video label\n",
    "    label = image_metadata['label']  # image label\n",
    "    \n",
    "    # convert image dimension to 1D\n",
    "    frame_1d = np.reshape(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), -1) # 1D from gray 2D image (reduces columns 3 times)\n",
    "\n",
    "    # get prediction from 1D image\n",
    "    if MODEL_TYPE in ['HDA']:\n",
    "        prediction = model.predict(frame)        \n",
    "    else:\n",
    "        prediction = model.predict([frame_1d])[0]\n",
    "\n",
    "    # format video text annotations\n",
    "    label_text = label\n",
    "    prediction_text = prediction\n",
    "    if MODEL_TYPE in ['HDA', 'GNB']:\n",
    "        label_text = label_text.upper().replace(\"Ú\", \"U\")\n",
    "        prediction_text = prediction_text.upper().replace(\"Ú\", \"U\")\n",
    "        label_text = f'Rotulo: {label_text}'\n",
    "        prediction_text = f'Previsao (IA): {prediction_text}'\n",
    "    elif MODEL_TYPE in ['LR']:\n",
    "        label_text = str(round(label_text * 1/5 * 100, 1)) + ' %' if label_text != '' else 'NAO-ROTULADO'\n",
    "        prediction_text = str(round(prediction_text * 100, 1)) + ' %'\n",
    "        label_text = f'Nivel real: {label_text}'\n",
    "        prediction_text = f'Nivel detectado (IA): {prediction_text}'\n",
    "    \n",
    "    \n",
    "    # put text annotation on video\n",
    "    cv2.putText(\n",
    "        frame, label_text, org=(20, 425), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "        fontScale=0.67, color=(40, 230, 230), thickness=2\n",
    "    )\n",
    "    cv2.putText(\n",
    "        frame, prediction_text, org=(20, 460), fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "        fontScale=0.67, color=(40, 230, 230), thickness=2\n",
    "    )\n",
    "    \n",
    "    # write edited image to video\n",
    "    history_writer.write(frame)\n",
    "    \n",
    "    # return operation record\n",
    "    return {\n",
    "        'write': 'success',\n",
    "        'prediction': prediction,\n",
    "        'timestamp': timestamp,\n",
    "        **metadata,\n",
    "        **image_metadata,\n",
    "        'label': label,\n",
    "        'image_timestamp': image_timestamp_str,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Videos frames pipeline · Concatenate multiple videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '2023-02-14 11:45:00.333' in image_reference.index.to_frame()['image_timestamp'] # Error for code 1648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABELED VIDEOS PROCESSING · PROGRESS: 360/360\n",
      "\n",
      "Videos Selected: 360\n",
      "Frames Loaded: 11354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "# Pipeline parameters\n",
    "\n",
    "pre_sampled = False\n",
    "\n",
    "process = history_write\n",
    "folder = 'Dados/flood-video-collection'\n",
    "\n",
    "LABEL_TYPE = 'IMAGE_LABEL'\n",
    "MODEL_TYPE = 'LR' # HDA, GNB, LR\n",
    "\n",
    "# Video parameters\n",
    "\n",
    "fps = 15\n",
    "overwrite = True\n",
    "\n",
    "# Get current date as string\n",
    "date = dt.now().date().isoformat()\n",
    "\n",
    "# path to save labeled camera video history\n",
    "full_history_video_path = f'Dados/Simulação/history-labeled-code{code}_{MODEL_TYPE}_{date}.mp4'\n",
    "\n",
    "if pre_sampled:\n",
    "    X = xx.copy()  # pre-sampled from loaded videos dataset\n",
    "else:\n",
    "    X = videos.copy()  # complete loaded videos dataset\n",
    "\n",
    "X['path'] = f'{folder}/' + X['blob_name']\n",
    "X = X.sort_index().reset_index() # IMPORTANT TO KEEP VIDEOS TIMESTAMP ORDER CORRECT · CHECK IF INDEX IS DATETIME INDEX\n",
    "\n",
    "# OPEN VIDEO FILE WRITER\n",
    "video = Video(fps=fps, overwrite=overwrite)\n",
    "history_writer = video.writer(path=full_history_video_path)\n",
    "\n",
    "# RUN FRAME PIPELINE\n",
    "pipeline = VideoProcessor(frame_dimension=3, frame_processing_function=process)\n",
    "results = pipeline.process_labeled_videos(videos_dataframe=X, path_key='path', print_each=1)\n",
    "\n",
    "# CLOSE/RELEASE VIDEO FILE WRITER\n",
    "history_writer.release(); cv2.destroyAllWindows()\n",
    "\n",
    "print(f'\\nVideos Selected: {len(X)}')\n",
    "print(f'Frames Loaded: {len(results)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Frame Write Operation Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>success</th>\n",
       "      <td>11354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Video Frame Write Operation Success\n",
       "success                                11354"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m display(frames_concat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_frame(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo Frame Write Operation Success\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# print(f'\\n * average absolute difference: {round(np.abs(y_true - y_pred).mean(), 2)}')\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m * Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m((y_true \u001b[38;5;241m==\u001b[39m y_pred)\u001b[38;5;241m.\u001b[39mmean(), \u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2310\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   2196\u001b[0m     y_true,\n\u001b[0;32m   2197\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2205\u001b[0m ):\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m \n\u001b[0;32m   2208\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2310\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2313\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "frames_concat = pd.DataFrame(results)\n",
    "\n",
    "#### Classification Model Real Conditions Simulation Report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get frames labels and predictions\n",
    "y_true = frames_concat['label']\n",
    "y_pred = frames_concat['prediction']\n",
    "\n",
    "display(frames_concat['write'].value_counts().to_frame('Video Frame Write Operation Success'))\n",
    "print()\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "# print(f'\\n * average absolute difference: {round(np.abs(y_true - y_pred).mean(), 2)}')\n",
    "print(f'\\n * Accuracy: {round((y_true == y_pred).mean(), 2)}')\n",
    "print(f'\\n * Mislabeled data points: {(y_true != y_pred).sum()} / {len(y_true)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_concat = pd.DataFrame(results)\n",
    "\n",
    "frames_concat[frames_concat['label']=='']#[['blob_name', 'image_timestamp']].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
