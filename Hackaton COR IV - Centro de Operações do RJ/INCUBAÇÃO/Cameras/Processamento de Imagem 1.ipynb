{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Storage buckets image and video processing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output as co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Cloud Storage wrapper module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.googlecloudstorage import GCS\n",
    "\n",
    "sa_json = '../../../../Apps/Python/cams-rio/auth/octacity-iduff.json' # 'auth/pluvia-sa.json'\n",
    "user_project = 'octacity'\n",
    "default_bucket_name = 'city-camera-images'\n",
    "\n",
    "gcs = GCS(sa_json, user_project, default_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image classification settings - Histogram max. percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.histogram import HistogramClassifier\n",
    "\n",
    "threshold=0.6\n",
    "clf_hist = HistogramClassifier(threshold)\n",
    "skipper = clf_hist.is_histogram_clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python module: Controlled pipeline execution (pandas dataframe based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.controlled_pipeline import ControlledPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Clean up storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete blobs that match provided extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 18/18 · Deleted: 0/0\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'flood-video-collection'\n",
    "prefix = 'rain/'\n",
    "delimiter = None\n",
    "\n",
    "ext = '.mp4.mp4'\n",
    "\n",
    "blobs = gcs.list_blobs(bucket_name, prefix, delimiter)\n",
    "\n",
    "blobs_ext = []\n",
    "for blob_name in blobs:\n",
    "    \n",
    "    if blob_name.endswith(ext):\n",
    "        blobs_ext.append(blob_name)\n",
    "\n",
    "print('Blobs:', len(blobs), '· Query:', len(blobs_ext))\n",
    "\n",
    "bucket = gcs.get_bucket(bucket_name)\n",
    "\n",
    "deleted = 0\n",
    "for i, blob in enumerate(bucket.list_blobs(prefix=prefix, delimiter=delimiter)):\n",
    "\n",
    "    if blob.name.endswith(ext):\n",
    "        blob.delete(); deleted += 1\n",
    "\n",
    "    co(True); print(f'Iteration: {i+1}/{len(blobs)} · Deleted: {deleted}/{len(blobs_ext)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blobs: 577 · Query: 0\n"
     ]
    }
   ],
   "source": [
    "blobs = gcs.list_blobs(bucket_name, prefix, delimiter)\n",
    "\n",
    "blobs_ext = []\n",
    "for blob_name in blobs:\n",
    "    if blob_name.endswith(ext): blobs_ext.append(blob_name)\n",
    "#     if len(blob_name.split(pattern)) - 1 == 2: blobs_ext.append(blob_name)\n",
    "\n",
    "print(f'Blobs: {len(blobs)} · Query: {len(blobs_ext)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Delete images in cloud storage bucket based on image classification result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List blobs in blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'city-camera-images'\n",
    "prefix = ''\n",
    "delimiter = None\n",
    "ext = '.jpg'\n",
    "\n",
    "drop_first = False\n",
    "print_each = 1000\n",
    "\n",
    "blobs = gcs.list_blobs(bucket_name, prefix, delimiter)\n",
    "\n",
    "names = []\n",
    "for i, blob in enumerate(blobs):\n",
    "    if blob.name.endswith(ext): names.append(blob.name)\n",
    "    if (i + 1) % print_each == 0: print(f'\\n- Blobs Searched: {i + 1}'); co(True)\n",
    "\n",
    "print(f'\\n- Blobs Searched: {i + 1}')\n",
    "if drop_first: print(f'\\n · First item excluded: {names[0]}'); del names[0]\n",
    "print(f'\\n · Results: {len(names)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and save blobs control dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pd.DataFrame(names, columns=['blob_name'])\n",
    "\n",
    "control['bucket_name'] = 'city-camera-images'\n",
    "control['status'] = 'UNKNOWN' # special control field\n",
    "\n",
    "data_path = '../../../Data Science Projects/Hackaton COR IV - Centro de Operações do RJ/INCUBAÇÃO/Cameras/Dados'\n",
    "control_path = f'{data_path}/blobs/images_control.csv'\n",
    "\n",
    "control.to_csv(control_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: Delete dark images · status control managed locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "def load_image_from_bytes(bytes_string):\n",
    "    return cv2.imdecode(np.frombuffer(bytes_string, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "def delete_blob_if_invalid(blob_name, bucket_name):\n",
    "    blob = gcs.get_blob(blob_name, bucket_name) # get blob\n",
    "    image_bytes = blob.download_as_string()\n",
    "    status = image_bytes == b'' or clf_hist.is_histogram_clustered(load_image_from_bytes(image_bytes))\n",
    "    if status: blob.delete()\n",
    "    return status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test control function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'city-camera-images'\n",
    "blob_name = 'rain/1020/2023-02-10 17:55:01/CODE1020_2023-02-10 18:04:59.jpg'\n",
    "\n",
    "delete_blob_if_invalid(blob_name, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline: Delete invalid blobs using control dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- PROGRESS: 0 / 1 ops · PROGRESS-PRCT: 0.0 %\n",
      "\n",
      "- TOTAL: 626601 / 626602 ops · TOTAL-PRCT: 100.0 %\n",
      "\n",
      "* EXCEPTION: 404 GET https://storage.googleapis.com/download/storage/v1/b/city-camera-images/o/rain%2F1020%2F2023-02-10%2017%3A55%3A01%2FCODE1020_2023-02-10%2018%3A04%3A59.jpg?alt=media&userProject=octacity: No such object: city-camera-images/rain/1020/2023-02-10 17:55:01/CODE1020_2023-02-10 18:04:59.jpg: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>) · UPDATE-STATUS: ERROR\n",
      "\n",
      "- PROGRESS: 0 / 1 ops · PROGRESS-PRCT: 0.0 %\n",
      "\n",
      "- TOTAL: 626601 / 626602 ops · TOTAL-PRCT: 100.0 %\n",
      "\n",
      "* BLOBS CONTROL UPDATE SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "save_each = 1000\n",
    "report_each = 100\n",
    "\n",
    "control_path = f'Dados/blobs/images_control.csv'\n",
    "\n",
    "control_func = delete_blob_if_invalid\n",
    "params_fields = ['blob_name', 'bucket_name']\n",
    "status_field = 'status'\n",
    "query = {'status': ['ERROR']} #, 'UPLOAD_FAILED']}\n",
    "status_options = ['VALID', 'DELETED']\n",
    "error_flag = 'ERROR'\n",
    "\n",
    "pipe = ControlledPipeline(\n",
    "    control_path, control_func, params_fields,\n",
    "    query, status_field, status_options, error_flag,\n",
    ")\n",
    "\n",
    "pipe.run(report_each, save_each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload blobs control · Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VALID      491834\n",
       "DELETED    134767\n",
       "ERROR           1\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "control_path = f'Dados/blobs/images_control.csv'\n",
    "\n",
    "folders = pd.read_csv(control_path)\n",
    "\n",
    "folders['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Delete empty folders in bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List blobs in blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Blobs Searched: 514863\n",
      "\n",
      " · Results: 15324\n",
      "BLOB pics/ excluded.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'city-camera-images'\n",
    "prefix = '' # search all blobs\n",
    "delimiter = None\n",
    "ext = '/'\n",
    "\n",
    "drop_first = False\n",
    "print_each = 1000\n",
    "\n",
    "blobs = gcs.list_blobs(prefix, delimiter, bucket_name)\n",
    "\n",
    "names = []\n",
    "for i, blob in enumerate(blobs):\n",
    "    if blob.name.endswith(ext): names.append(blob.name)\n",
    "    if (i + 1) % print_each == 0: print(f'\\n- Blobs Searched: {i + 1}'); co(True)\n",
    "\n",
    "print(f'\\n- Blobs Searched: {i + 1}')\n",
    "if drop_first: print(f'\\n · First item excluded: {names[0]}'); del names[0]\n",
    "print(f'\\n · Results: {len(names)}')\n",
    "\n",
    "drop_if_exists = ['pics/', 'flood/', 'rain/', 'comando/', 'waze/']\n",
    "\n",
    "if len(drop_if_exists):\n",
    "    for name in drop_if_exists:\n",
    "        if name in names:\n",
    "            print(f'\\n- BLOB: {name} (excluded)')\n",
    "            del names[names.index(name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and save blobs control dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pd.DataFrame(names, columns=['folder'])\n",
    "\n",
    "control['bucket_name'] = None # bucket_name\n",
    "control['status'] = 'UNKNOWN' # special control field\n",
    "\n",
    "control_path = f'Dados/blobs/empty_folder_control_2.csv'\n",
    "\n",
    "# control.to_csv(control_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python function: Delete folder if empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_folder_if_empty(folder, bucket_name): # ignores non-existing folders\n",
    "    i = None\n",
    "    for i, blob in enumerate(gcs.list_blobs(prefix=folder, bucket_name=bucket_name)):\n",
    "        if i == 1: return False\n",
    "    if i is None:\n",
    "        print(f'FOLDER NOT FOUND · FOLDER: {folder} · BUCKET: {bucket_name}');\n",
    "        return False\n",
    "    blob.delete()\n",
    "    print(f'\\n* FOLDER EMPTY: DELETED · FOLDER: {folder} · BUCKET: {bucket_name}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test control function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDER NOT FOUND · FOLDER: test/pics/1020/2023-02-08 09:55:00/ · BUCKET: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = float('nan') # 'city-camera-images'\n",
    "folder = 'test/pics/1020/2023-02-08 09:55:00/'\n",
    "\n",
    "delete_folder_if_empty(folder, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pipeline: delete empty folders using control dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- PROGRESS: 6800 / 6890 ops · PROGRESS-PRCT: 98.7 %\n",
      "\n",
      "- TOTAL: 15233 / 15323 ops · TOTAL-PRCT: 99.4 %\n",
      "\n",
      "- RUNNING: 7.4 min · EXPECT-FINISH: 0.1 min · RATE: 15.3635 ops / s\n",
      "\n",
      "- PROGRESS: 6889 / 6890 ops · PROGRESS-PRCT: 100.0 %\n",
      "\n",
      "- TOTAL: 15322 / 15323 ops · TOTAL-PRCT: 100.0 %\n",
      "\n",
      "- RUNNING: 7.5 min · EXPECT-FINISH: 0.0 min · RATE: 15.3691 ops / s\n",
      "\n",
      "* BLOBS CONTROL UPDATE SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "save_each = 1000\n",
    "report_each = 100\n",
    "\n",
    "control_path = f'Dados/blobs/empty_folder_control_2.csv'\n",
    "\n",
    "control_func = delete_folder_if_empty\n",
    "params_fields = ['folder', 'bucket_name']\n",
    "query = {'status': ['UNKNOWN']} #, 'UPLOAD_FAILED']}\n",
    "status_field = 'status'\n",
    "status_options = ['VALID', 'DELETED']\n",
    "error_flag = 'ERROR'\n",
    "\n",
    "pipe = ControlledPipeline(\n",
    "    control_path, control_func, params_fields,\n",
    "    query, status_field, status_options, error_flag,\n",
    ")\n",
    "\n",
    "pipe.run(report_each, save_each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload control dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VALID      15322\n",
       "DELETED        1\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_path = f'Dados/blobs/empty_folder_control_2.csv'\n",
    "control = pd.read_csv(control_path)\n",
    "\n",
    "control['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>bucket_name</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flood/1083/2023-02-10 18:10:00/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DELETED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            folder  bucket_name   status\n",
       "0  flood/1083/2023-02-10 18:10:00/          NaN  DELETED"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control[control['status']=='DELETED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "query = {\n",
    "    'folder': 'manual/2023-08-02/1119/2023-02-08 15:55:00/',\n",
    "    'to_blob_name': 'test/TEST.mp4',\n",
    "    'from_bucket_name': 'city-camera-images',\n",
    "    'to_bucket_name': 'city-camera-images', # 'flood-video-collection'\n",
    "    'ext': '.jpg',\n",
    "    'content_type': 'video/mp4',\n",
    "    'overwrite': True,\n",
    "    'report': False,\n",
    "}\n",
    "\n",
    "baseurl = 'http://127.0.0.1:5001'\n",
    "\n",
    "url = f'{baseurl}/write-video?{urlencode(query)}'\n",
    "\n",
    "res = requests.get(url, params=query)\n",
    "\n",
    "print(res.status_code, res.reason, res.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
