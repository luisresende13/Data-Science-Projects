{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd9cc6ba-a38e-44d1-b35e-eea4dae47e0c",
   "metadata": {},
   "source": [
    "# Multiple object tracking and re-identification with DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abab14fc-506c-473d-bb9b-dcc53a385d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics\n",
    "# !pip install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf8823-8d83-4806-bdcf-2d99237441ea",
   "metadata": {},
   "source": [
    "#### Class to write videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81842f27-df48-45ae-a8eb-f8ed42ea9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "\n",
    "class Video:\n",
    "\n",
    "    def __init__(self, codec:str='mp4v', fps:int=3, shape:tuple=(854, 480), overwrite=False):\n",
    "        self.codec = codec; self.fps = fps; self.shape = shape\n",
    "        self.overwrite = overwrite\n",
    "\n",
    "    def writer(self, path):\n",
    "        if not self.overwrite and os.path.exists(path):\n",
    "            print(f'ANNOTATE VIDEO TIMESTAMP FAILED. FILE ALREADY EXISTS · FILE-PATH: {path}')\n",
    "            return False\n",
    "        return cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*self.codec), self.fps, self.shape)\n",
    "\n",
    "    \n",
    "#### OPEN VIDEO FILE WRITER · Method #1\n",
    "# video_path = \"output.mp4\"\n",
    "# fps, shape = get_video_metadata(video_path, transform=None)\n",
    "# shape = (shape[1], shape[0]) # witdth, height\n",
    "# overwrite = True\n",
    "# video = Video(fps=fps, shape=shape, overwrite=overwrite)\n",
    "# writer = video.writer(path=video_path)\n",
    "\n",
    "# writer.release(); cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe991893-2ce4-4d3f-973d-57185fe3fa2c",
   "metadata": {},
   "source": [
    "#### Function to get basic metadata from video file:\n",
    "    fps: frames per second (FPS) of video file\n",
    "    shape: shape of first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44907586-cc56-414e-8f16-67ca9bbc700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_metadata(video_path, transform=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) # get the fps\n",
    "    _, frame = cap.read() # read the first frame\n",
    "    if transform is not None: # custom transformation\n",
    "        frame = transform(frame)\n",
    "    shape = frame.shape; # get the shape\n",
    "    cap.release(); cv2.destroyAllWindows()\n",
    "    return fps, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93041cc3-9fc6-44cc-9f3f-808e172d55a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Function to open video file writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e7f5dfb-63c0-4f32-b664-8c0143b2caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def create_video_writer(video_cap, output_filename):\n",
    "\n",
    "    # grab the width, height, and fps of the frames in the video stream.\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # initialize the FourCC and a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n",
    "                             (frame_width, frame_height))\n",
    "\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3c8fd-19a2-47ba-a916-7aa48de3e64b",
   "metadata": {},
   "source": [
    "#### Function to write demo video of multiple object tracking and re-identification with DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f9cef3-4394-491a-b377-6def17328250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: https://www.thepythoncode.com/article/real-time-object-tracking-with-yolov8-opencv\n",
    "\n",
    "import datetime\n",
    "from IPython.display import clear_output as co\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "def tracking_reid_demo(\n",
    "    video_path, to_video_path, CONFIDENCE_THRESHOLD=0.3,\n",
    "    model=YOLO(\"yolov8n.pt\"), tracker=DeepSort(max_age=50), show=False\n",
    "):\n",
    "\n",
    "    GREEN = (0, 255, 0)\n",
    "    WHITE = (255, 255, 255)\n",
    "\n",
    "    # Initialize BigQuery client\n",
    "    # client = bigquery.Client.from_service_account_json(credentials_path)\n",
    "    \n",
    "    # initialize the video capture object\n",
    "    video_cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # initialize the video writer object\n",
    "    writer = create_video_writer(video_cap, to_video_path) # None\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        start = datetime.datetime.now()\n",
    "\n",
    "        ret, frame = video_cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # run the YOLO model on the frame\n",
    "        detections = model(frame)[0]\n",
    "\n",
    "        # initialize the list of bounding boxes and confidences\n",
    "        results = []\n",
    "\n",
    "        ######################################\n",
    "        # DETECTION\n",
    "        ######################################\n",
    "\n",
    "        # loop over the detections\n",
    "        for data in detections.boxes.data.tolist():\n",
    "            # extract the confidence (i.e., probability) associated with the prediction\n",
    "            confidence = data[4]\n",
    "\n",
    "            # filter out weak detections by ensuring the \n",
    "            # confidence is greater than the minimum confidence\n",
    "            if float(confidence) < CONFIDENCE_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            # if the confidence is greater than the minimum confidence,\n",
    "            # get the bounding box and the class id\n",
    "            xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "            class_id = int(data[5])\n",
    "            # add the bounding box (x, y, w, h), confidence and class id to the results list\n",
    "            results.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "\n",
    "        ######################################\n",
    "        # TRACKING\n",
    "        ######################################\n",
    "\n",
    "        # update the tracker with the new detections\n",
    "        tracks = tracker.update_tracks(results, frame=frame)\n",
    "        # loop over the tracks\n",
    "        for track in tracks:\n",
    "            # if the track is not confirmed, ignore it\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "\n",
    "            # get the track id and the bounding box\n",
    "            track_id = track.track_id\n",
    "            ltrb = track.to_ltrb()\n",
    "\n",
    "            xmin, ymin, xmax, ymax = int(ltrb[0]), int(\n",
    "                ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "            # draw the bounding box and the track id\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "            cv2.rectangle(frame, (xmin, ymin - 40), (xmin + 40, ymin), GREEN, -1)\n",
    "            cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, WHITE, 2)\n",
    "\n",
    "        # end time to compute the fps\n",
    "        end = datetime.datetime.now()\n",
    "        # show the time it took to process 1 frame\n",
    "        co(True); print(f\"Time to process frame {i}/{total_frames}: {(end - start).total_seconds() * 1000:.0f} milliseconds\")\n",
    "        # calculate the frame per second and draw it on the frame\n",
    "        fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "        cv2.putText(frame, fps, (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "\n",
    "        # show the frame to our screen\n",
    "        if show:\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    video_cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b7508-bf48-45df-9cdd-9ac785728719",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multiple object tracking and re-identification with DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a932c5-07e7-4270-8dec-032f9bdad65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system paths\n",
    "folder = '../Dados/Demos/smartphone-video-samples/'\n",
    "to_folder = '../Dados/Demos/tracking-id/'\n",
    "file_name = 'VID_20230515_125317.mp4'\n",
    "\n",
    "video_path = folder + file_name\n",
    "to_video_path = to_folder + file_name\n",
    "\n",
    "# load the pre-trained YOLOv8n model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "tracker = DeepSort(max_age=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f27b3e-68d7-4c59-a561-b39b8152cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_reid_demo(\n",
    "    video_path, to_video_path,\n",
    "    CONFIDENCE_THRESHOLD=0.3,\n",
    "    model=YOLO(\"yolov8n.pt\"),\n",
    "    tracker=DeepSort(max_age=50),\n",
    "    show=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01aa9f3-a21e-4df7-b029-26129a4f6170",
   "metadata": {},
   "source": [
    "#### Write demo for multiple videos from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1be4197-d05c-4a24-a898-46c718a85de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to process frame 293/293: 766 milliseconds\n"
     ]
    }
   ],
   "source": [
    "folder = '../Dados/Demos/smartphone-video-samples/'\n",
    "to_folder = '../Dados/Demos/tracking-id/'\n",
    "\n",
    "for file_name in os.listdir(data_path):\n",
    "    \n",
    "    video_path = data_path + file_name\n",
    "    to_video_path = to_data_path + file_name\n",
    "    \n",
    "    tracking_reid_demo(\n",
    "        video_path, to_video_path,\n",
    "        CONFIDENCE_THRESHOLD=0.6,\n",
    "        model=YOLO(\"yolov8n.pt\"),\n",
    "        tracker=DeepSort(max_age=50),\n",
    "        show=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
