{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3e35af-635c-41f2-b1b1-4b21d17b9613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "online\n"
     ]
    }
   ],
   "source": [
    "print('online')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e5da8-3a8a-46ad-af36-af0e3b8f5071",
   "metadata": {},
   "source": [
    "#### AWS ec2 instance deploy from github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be843d-db3f-44b0-a2cd-3c99e2894d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/ubuntu/CameraVision\n",
    "git pull origin my-branch\n",
    "chown -R ubuntu:ubuntu /home/ubuntu/CameraVision\n",
    "ls -l\n",
    "\n",
    "(Reboot instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd389ca-8e63-45fe-8598-a80a2f5bfcc2",
   "metadata": {},
   "source": [
    "## Boto3 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c0992-9a0a-4aea-a21b-07252fa64722",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2e602-5b25-478a-83ed-ce6c47fad1f7",
   "metadata": {},
   "source": [
    "### Set credentials environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7edf8299-1ac7-4307-91a5-af82a862236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS\n",
    "    # - Access Key ID: AKIAQDINISPVPDSG6KER\n",
    "    # - Access Key: QFn9dulaP6p1+FwZQdw6b5q4gj5inVjuJQnZ9jvw\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'AKIAQDINISPVPDSG6KER'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = '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'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'sa-east-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab35629-641d-42ea-b8dd-8817e189c050",
   "metadata": {},
   "source": [
    "### Get aws ec2 instance IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "70fdee50-ef4e-4d98-89be-58e0a163a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public IPv4: 54.94.50.150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'AKIAQDINISPVG5SQOWXG'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = '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'\n",
    "\n",
    "def get_public_ipv4(instance_id):\n",
    "    ec2_client = boto3.client('ec2', region_name='sa-east-1')  # Replace 'us-west-1' with your desired region\n",
    "    response = ec2_client.describe_instances(InstanceIds=[instance_id])\n",
    "    try:\n",
    "        reservations = response['Reservations']\n",
    "        if reservations:\n",
    "            instances = reservations[0]['Instances']\n",
    "            if instances:\n",
    "                instance = instances[0]\n",
    "                public_ip = instance.get('PublicIpAddress')\n",
    "                return public_ip\n",
    "    except Exception as e:\n",
    "        print(f'Request failed. Error: {str(e)}')\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "instance_id = 'i-01796a60ab18b8bd5'\n",
    "public_ipv4 = get_public_ipv4(instance_id)\n",
    "if public_ipv4:\n",
    "    print(\"Public IPv4:\", public_ipv4)\n",
    "else:\n",
    "    print(\"Failed to retrieve the public IPv4 address.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5cbfe-2c94-4880-ab0e-1f9c6ea95975",
   "metadata": {},
   "source": [
    "### Get aws ec2 instance IP address using HTTP API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0093f30-eb07-4f1c-95df-6815e124ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.94.51.82\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "cloudRunServerURL = 'https://octa-vision-oayt5ztuxq-ue.a.run.app'\n",
    "try:\n",
    "    awsIP = requests.get(f\"{cloudRunServerURL}/ip\").text\n",
    "except:\n",
    "    awsIP = ''\n",
    "print(awsIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04e235-fa18-4a15-8f46-1c59f38d0374",
   "metadata": {},
   "source": [
    "### Reboot aws ec2 instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b4a21fe-d9f8-45e9-80de-92f07d1fcd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebooting EC2 instance: i-01796a60ab18b8bd5\n",
      "Reboot is in progress.\n",
      "Reboot was successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# Set environment variables with your AWS credentials and region\n",
    "# os.environ['AWS_ACCESS_KEY_ID'] = 'YOUR_ACCESS_KEY_ID'\n",
    "# os.environ['AWS_SECRET_ACCESS_KEY'] = 'YOUR_SECRET_ACCESS_KEY'\n",
    "# os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'  # Change to your desired AWS region\n",
    "\n",
    "def reboot_ec2_instance(instance_id):\n",
    "    try:\n",
    "        # Create a Boto3 EC2 client\n",
    "        ec2_client = boto3.client('ec2')\n",
    "\n",
    "        # Reboot the EC2 instance\n",
    "        response = ec2_client.reboot_instances(InstanceIds=[instance_id])\n",
    "\n",
    "        # The response doesn't contain detailed information about the instance state after reboot\n",
    "        print(\"Rebooting EC2 instance:\", instance_id)\n",
    "        print(\"Reboot is in progress.\")\n",
    "\n",
    "        # Wait for the instance state to change to running after the reboot\n",
    "        waiter = ec2_client.get_waiter('instance_running')\n",
    "        waiter.wait(InstanceIds=[instance_id])\n",
    "\n",
    "        # Get the instance state after the reboot\n",
    "        instance = ec2_client.describe_instances(InstanceIds=[instance_id])\n",
    "        instance_state = instance['Reservations'][0]['Instances'][0]['State']['Name']\n",
    "\n",
    "        if instance_state == 'running':\n",
    "            print(\"Reboot was successful.\")\n",
    "        else:\n",
    "            print(\"Reboot failed. Current instance state:\", instance_state)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "# Replace this with the ID of the EC2 instance you want to reboot\n",
    "instance_id = 'i-01796a60ab18b8bd5'\n",
    "\n",
    "# Call the reboot_ec2_instance function with the instance_id\n",
    "reboot_ec2_instance(instance_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486d989-fcde-49cf-85a4-f54fab23d3a4",
   "metadata": {},
   "source": [
    "### Reboot aws ec2 instance using HTTP API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca671bcc-0fba-4a93-a7fc-535568a5d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reboot EC2 instance success\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "cloudRunServerURL = 'https://octa-vision-oayt5ztuxq-ue.a.run.app'\n",
    "\n",
    "server_url = cloudRunServerURL\n",
    "success = requests.get(f\"{server_url}/reboot\").text\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff105a5e-86d9-4ccd-a1c5-c36302fa675d",
   "metadata": {},
   "source": [
    "## Multiple object tracking and re-identification with DeepSORT Â· Object database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2ebb7-6e15-43f2-9d31-87bf50f6d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def processing():\n",
    "    print(f'processing async')\n",
    "    await asyncio.sleep(3) # doing some processing\n",
    "    print(f'finished processing async')\n",
    "    return 1\n",
    "\n",
    "async def foo():\n",
    "    for i in range(5):\n",
    "        print(f'i = {i}')\n",
    "\n",
    "def sync_func(value):\n",
    "    for j in range(value):\n",
    "        print(f'j = {j}')\n",
    "\n",
    "task = asyncio.create_task(processing()) # task that might take too long\n",
    "task2 = asyncio.create_task(foo()) # task that doesn need to wait task1 to finish\n",
    "val = await task\n",
    "await task2\n",
    "sync_func(val)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44dbff2e-ca8d-4435-a0f3-3f6acf2aa8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def my_func():\n",
    "    print('func start')\n",
    "    await task\n",
    "    print('func end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb67959-63f0-49e3-86da-710c787676bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.run(my_func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e43effc-2d68-4cb7-a230-b2e50a82109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics\n",
    "# !pip install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a74f4b-0f55-4e5a-9590-4e75f15a28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone --branch master https://github.com/luisresende13/CameraVision\n",
    "python -m venv .camera-vision-venv\n",
    ".camera-vision-venv\\Scripts\\activate\n",
    "cd CameraVision\n",
    "pip install -r requirements.txt\n",
    "pip install lap\n",
    "flask run --reload --debugger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df3061-5236-4cb8-8280-0352d4ba1ec0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Class to write videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c03e8436-062f-4a2d-aeda-e1189f3bbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "\n",
    "class Video:\n",
    "\n",
    "    def __init__(self, codec:str='MP4V', fps:int=3, shape:tuple=(854, 480), overwrite=False):\n",
    "        self.codec = codec; self.fps = fps; self.shape = shape\n",
    "        self.overwrite = overwrite\n",
    "\n",
    "    def writer(self, path):\n",
    "        if not self.overwrite and os.path.exists(path):\n",
    "            print(f'ANNOTATE VIDEO TIMESTAMP FAILED. FILE ALREADY EXISTS Â· FILE-PATH: {path}')\n",
    "            return False\n",
    "        fourcc = cv2.VideoWriter_fourcc(*self.codec)\n",
    "        return cv2.VideoWriter(path, fourcc, self.fps, self.shape)\n",
    "\n",
    "    \n",
    "#### OPEN VIDEO FILE WRITER Â· Method #1\n",
    "# video_path = \"output.mp4\"\n",
    "# fps, shape = get_video_metadata(video_path, transform=None)\n",
    "# shape = (shape[1], shape[0]) # witdth, height\n",
    "# overwrite = True\n",
    "# video = Video(fps=fps, shape=shape, overwrite=overwrite)\n",
    "# writer = video.writer(path=video_path)\n",
    "\n",
    "# writer.release(); cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296e36d-afe9-49ed-b263-395e5c3455c8",
   "metadata": {},
   "source": [
    "#### Function to get basic metadata from video file:\n",
    "    fps: frames per second (FPS) of video file\n",
    "    shape: shape of first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "92a5e667-baf7-49da-9f22-c0705eb9aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_metadata(video_path, transform=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) # get the fps\n",
    "    _, frame = cap.read() # read the first frame\n",
    "    if transform is not None: # custom transformation\n",
    "        frame = transform(frame)\n",
    "    shape = frame.shape; # get the shape\n",
    "    cap.release(); cv2.destroyAllWindows()\n",
    "    return fps, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "69fa0a91-1353-47ce-a7c7-e90a0140ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'b', '0': '1'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"0\": \"1\"}\n",
    "{\"a\": \"b\", **a}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8ef1afe7-e1b8-42d3-ba03-f30b21b0fe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ba0a2-9d63-4dcd-8772-3a9aa8f26d12",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Function to open video file writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a90942d0-53d3-4e88-8043-d1990fbc7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def create_video_writer(video_cap, output_filename):\n",
    "\n",
    "    # grab the width, height, and fps of the frames in the video stream.\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # initialize the FourCC and a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n",
    "                             (frame_width, frame_height))\n",
    "\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505dc10a-5549-4153-bb5e-6e68b66b7514",
   "metadata": {},
   "source": [
    "#### Format output of YOLO object detection model from python's `ultralitycs` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4908eb3f-67de-4966-8d62-782d7b49a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_yolo_detection(detection, class_names=None):\n",
    "    \"\"\"\n",
    "    Formats the YOLO detection results.\n",
    "\n",
    "    Args:\n",
    "        detection (object): The detection object.\n",
    "        class_names (dict): Dict of class names by class id.\n",
    "\n",
    "    Returns:\n",
    "        list: Formatted detection results.\n",
    "    \"\"\"\n",
    "    formatted_detection = []\n",
    "\n",
    "    for data in detection.boxes.data.tolist():\n",
    "        # Get the bounding box and the class id\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "\n",
    "        # Extract the confidence (i.e., probability) associated with the prediction\n",
    "        confidence = data[4]\n",
    "\n",
    "        # Get class id and name\n",
    "        class_id = int(data[5])\n",
    "        class_name = class_names[class_id] if class_names is not None else None\n",
    "\n",
    "        # Add standard format detections\n",
    "        formatted_detection.append([class_id, class_name, confidence, [xmin, ymin, xmax, ymax]])\n",
    "\n",
    "    return formatted_detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21930a-742c-4e16-b6c2-4a084c1ee797",
   "metadata": {},
   "source": [
    "### Function to process object identification output (post processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8fd7ed75-03eb-4c5c-86c1-f115956b4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tracking and detection from: https://www.thepythoncode.com/article/real-time-object-tracking-with-yolov8-opencv\n",
    "\n",
    "import datetime, pandas as pd\n",
    "from IPython.display import clear_output as co\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import asyncio\n",
    "\n",
    "def tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.3,\n",
    "    objects_allowed=None,\n",
    "    max_frames=10,\n",
    "    post_processing_function=None,\n",
    "    post_processing_args={},\n",
    "    proccess_each=None,\n",
    "    frame_annotator=None,\n",
    "    to_video_path=None,\n",
    "    generator=False\n",
    "):\n",
    "    \n",
    "    # initialize YOLO object detection model\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    # Get class names from model\n",
    "    class_names = model.names\n",
    "\n",
    "    # initialize DeepSORT real-time tracker\n",
    "    deepsort = DeepSort(max_age=50)\n",
    "        \n",
    "    # initialize the video capture object\n",
    "    video_cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # check if video capture is a live http image stream\n",
    "    is_video_stream = video_path.startswith('http')\n",
    "\n",
    "    # total frames of video file\n",
    "    total_frames = None if is_video_stream else int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT)) # if capture is from video file\n",
    "\n",
    "    if to_video_path is not None:\n",
    "        # Get the frames per second (fps)\n",
    "        fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        # Get the frame dimensions (shape)\n",
    "        w = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        h = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Video writer instance\n",
    "        video = Video(codec='MP4V', fps=fps, shape=(w, h), overwrite=True)\n",
    "        WRITER = video.writer(to_video_path)\n",
    "\n",
    "    # initialize set for track ids \n",
    "    unique_track_ids = set()\n",
    "\n",
    "    # initialize post processing output list\n",
    "    post_processing_output = []\n",
    "    \n",
    "    i = -1\n",
    "    while True:\n",
    "\n",
    "        # update number of frames processed or skipped\n",
    "        i += 1\n",
    "        \n",
    "        # break loop if `max_frames` are processed\n",
    "        if max_frames is not None and max_frames == i:\n",
    "            break\n",
    "\n",
    "        # current date and time\n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        # datetime as string rounded to seconds\n",
    "        timestamp = str(start)[:19]\n",
    "        \n",
    "        # read video frame\n",
    "        ret, frame = video_cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # continue if frame index `i` is not a multiple of `process_each`. never continues for first frame\n",
    "        if proccess_each is not None and i % proccess_each != 0:\n",
    "            continue\n",
    "\n",
    "        ######################################\n",
    "        # RUN DETECTION Â· Obs. Choose standard model method for prediction and wrap models that use other methods before passing then to the function.\n",
    "\n",
    "        # run the YOLO model on the frame\n",
    "        yolo_detection = model(frame)[0]\n",
    "        \n",
    "        # formatted yolo detections\n",
    "        detections = formatted_yolo_detection(yolo_detection, class_names=class_names)\n",
    "\n",
    "        # initialize list for tracker input\n",
    "        tracker_input = []\n",
    "        \n",
    "        # set up input for tracker from detections\n",
    "        for det in detections:\n",
    "            \n",
    "            # get detected object attributes\n",
    "            class_id, class_name, confidence, bbox = det\n",
    "            \n",
    "            # filter out weak detections by ensuring the \n",
    "            # confidence is greater than the minimum confidence\n",
    "            if float(confidence) < confidence_threshold:\n",
    "                continue\n",
    "                \n",
    "            # filter out unwanted objects  \n",
    "            if objects_allowed is not None and class_name not in objects_allowed:\n",
    "                continue\n",
    "\n",
    "            # if the confidence is greater than the minimum confidence,\n",
    "            # get the bounding box and the class id\n",
    "            xmin, ymin, xmax, ymax = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "            \n",
    "            # add the bounding box (x, y, w, h), confidence and class id to the results list\n",
    "            tracker_input.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "\n",
    "        ######################################\n",
    "        # RUN TRACKING\n",
    "\n",
    "        # update the tracker with the new detections\n",
    "        tracks = deepsort.update_tracks(tracker_input, frame=frame)\n",
    "        \n",
    "        # initialize list for formatted tracker output\n",
    "        tracking = []\n",
    "\n",
    "        # list tracking result\n",
    "        for track in tracks:\n",
    "        \n",
    "            # if the track is not confirmed, ignore it\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            # get attributes of tracked object\n",
    "            track_id = track.track_id\n",
    "            class_label = track.det_class\n",
    "            class_name = class_names[class_label]\n",
    "            confidence = track.det_conf\n",
    "            bbox = track.to_ltrb()\n",
    "\n",
    "            # append attributes of tracked objects\n",
    "            tracking.append([track_id, class_label, class_name, confidence, bbox, start])\n",
    "        \n",
    "        ######################################\n",
    "        # GET NEWLY IDENTIFIED OBJECTS\n",
    "        \n",
    "        # initialize list for newly detected objects\n",
    "        new_objects = []\n",
    "\n",
    "        # loop over the formatted tracks and get newly identified objects\n",
    "        for track in tracking:\n",
    "\n",
    "            # get track attributes\n",
    "            track_id, class_label, class_name, confidence, bbox, timestamp = track\n",
    "\n",
    "            # check if track ID is unique\n",
    "            if track_id not in unique_track_ids:\n",
    "\n",
    "                # prepare record of newly identified object\n",
    "                record = {\n",
    "                    'class_label': class_label,\n",
    "                    'class_name': class_name,\n",
    "                    'confidence': confidence,\n",
    "                    'timestamp': timestamp,\n",
    "                    'track_id': track_id,\n",
    "                    'bbox': list(bbox),\n",
    "                }\n",
    "\n",
    "                # append record to list of new objects\n",
    "                new_objects.append(record)\n",
    "\n",
    "                # add the tracked object ID to the set of unique track IDs\n",
    "                unique_track_ids.add(track_id)\n",
    "\n",
    "        ######################################\n",
    "        # PROCESS RESULT\n",
    "        \n",
    "        # end time to compute the fps\n",
    "        end = datetime.datetime.now()\n",
    "        \n",
    "        if frame_annotator is not None:\n",
    "            annotated_frame = frame_annotator(frame, detections, tracking, new_objects, start, end)\n",
    "            \n",
    "        if to_video_path is not None:\n",
    "            selected_frame = frame if frame_annotator is None else annotated_frame\n",
    "            WRITER.write(selected_frame)\n",
    "                \n",
    "        # call arbitrary post processing function on frame and detection & tracking outputs\n",
    "        if post_processing_function is not None:\n",
    "            post_processing_output.append(post_processing_function(frame, detections, tracking, new_objects, start, end, **post_processing_args))\n",
    "\n",
    "        # report progress and time to process the current frame\n",
    "        # if total_frames is not None:\n",
    "            # co(True); print(f\"Time to process frame {i}/{total_frames}: {(end - start).total_seconds() * 1000:.0f} milliseconds\")\n",
    "\n",
    "        if generator:\n",
    "            selected_frame = frame if frame_annotator is None else annotated_frame\n",
    "            ret, buffer = cv2.imencode('.jpg', selected_frame)\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + buffer.tobytes() + b'\\r\\n')\n",
    "        \n",
    "    if to_video_path is not None:\n",
    "        # Optional Â· release video writer\n",
    "        WRITER.release() # run after writing is finished\n",
    "\n",
    "    # release video capture\n",
    "    video_cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # return post processing results\n",
    "    return post_processing_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9b879-a2b0-4bc3-815c-5e22b3ca029f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiple object tracking and re-identification with DeepSORT\n",
    "\n",
    "### Process detection and re-identification results Â· Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3c571-e7b2-4ae5-9bf2-e3595982ebb0",
   "metadata": {},
   "source": [
    "Define system paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5f33b4f3-35dd-4a2e-9dc6-8aacd23518c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system paths\n",
    "folder = '../Dados/Demos/smartphone-video-samples/'\n",
    "to_folder = '../Dados/Demos/tracking-id-db/'\n",
    "file_name = 'VID_20230515_125317.mp4'\n",
    "\n",
    "video_path = folder + file_name\n",
    "to_video_path = to_folder + file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19f37c-00b1-4294-a159-1d78d453b360",
   "metadata": {},
   "source": [
    "#### Function to write frame and results to video file Â· Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e3e8e94a-c5c3-47f7-a297-88c69683f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up color scheme\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "def write_demo(frame, detections, tracking, new_objects, process_start, process_end):\n",
    "\n",
    "    # loop over the formatted tracks and get newly identified objects\n",
    "    for track in tracking:\n",
    "\n",
    "        # get track attributes\n",
    "        track_id, class_label, class_name, confidence, bbox, timestamp = track\n",
    "\n",
    "        # get pixel values from track bounding box\n",
    "        xmin, ymin, xmax, ymax = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "        \n",
    "        # draw the bounding box and the track id\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.rectangle(frame, (xmin, ymin - 40), (xmin + 40, ymin), GREEN, -1)\n",
    "        cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8), cv2.FONT_HERSHEY_SIMPLEX, 1, WHITE, 2)\n",
    "        \n",
    "    # calculate the frame per second and draw it on the frame\n",
    "    fps = f\"FPS: {1 / (process_end - process_start).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, BLUE, 8)\n",
    "    \n",
    "    return frame\n",
    "    # write annotated frame to video file\n",
    "    # WRITER.write(frame)\n",
    "\n",
    "    \n",
    "#### Run pipeline Â· Example usage\n",
    "\n",
    "post_processing_output = tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.5,\n",
    "    max_frames=20,\n",
    "    post_processing_function=None,\n",
    "    proccess_each=None,\n",
    "    frame_annotator=write_demo,\n",
    "    to_video_path=to_video_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e823ea-19d7-4f87-b14a-bc26fafb806d",
   "metadata": {},
   "source": [
    "#### Show post processing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9fad014-aa83-4c8e-b570-b57be0f03903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_processing_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642dd7d-21e5-4246-b715-9fe980090b9f",
   "metadata": {},
   "source": [
    "---\n",
    "## Example usage with other sample functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65b3c7-0c6a-4277-a41c-0ff690aae830",
   "metadata": {},
   "source": [
    "#### Function to display frame of video demonstration of detection and tracking with re-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "185fe656-58ba-46d4-a480-db36248d41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "# set up color scheme\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "def show_demo(frame, detections, tracking, new_objects, process_start, process_end):\n",
    "\n",
    "    # Convert BGR image to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # loop over the formatted tracks and get newly identified objects\n",
    "    for track in tracking:\n",
    "\n",
    "        # get track attributes\n",
    "        track_id, class_label, class_name, confidence, bbox, timestamp = track\n",
    "\n",
    "        # get pixel values from track bounding box\n",
    "        xmin, ymin, xmax, ymax = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "\n",
    "        # draw the bounding box and the track id\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.rectangle(frame, (xmin, ymin - 40), (xmin + 40, ymin), GREEN, -1)\n",
    "        cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8), cv2.FONT_HERSHEY_SIMPLEX, 1, WHITE, 2)\n",
    "\n",
    "    # calculate the frame per second and draw it on the frame\n",
    "    fps = f\"Processing FPS: {1 / (process_end - process_start).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, BLUE, 8)\n",
    "    \n",
    "    # clear last frame screen output\n",
    "    co(True)\n",
    "    \n",
    "    # show the frame to our screen\n",
    "    plt.imshow(frame);\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    # cv2.imshow(\"Frame\", frame)\n",
    "    # cv2.waitKey(1) == ord(\"q\")\n",
    "    # plt.show()\n",
    "\n",
    "    \n",
    "#### Run pipeline Â· Example usage\n",
    "\n",
    "post_processing_output = tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.5,\n",
    "    max_frames=200,\n",
    "    post_processing_function=show_demo,\n",
    "    proccess_each=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff1ba73-8179-4ee0-8ad0-2220bdcd11fd",
   "metadata": {},
   "source": [
    "#### Function to gather id and info of newly identified objects from frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bc369-9dca-4b79-97a9-e771fa58429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "def gather_unique_objects(frame, detections, tracking, new_objects, process_start, process_end):\n",
    "\n",
    "    # extend list of unique objects with new objects\n",
    "    return new_objects\n",
    "    \n",
    "    \n",
    "#### Run pipeline Â· Example usage\n",
    "\n",
    "# initialize set for track ids \n",
    "unique_track_ids = set()\n",
    "\n",
    "post_processing_output = tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.5,\n",
    "    max_frames=20,\n",
    "    post_processing_function=gather_unique_objects,\n",
    "    proccess_each=None,\n",
    ")\n",
    "\n",
    "# Display result: Identified objects\n",
    "\n",
    "co(True); display(pd.DataFrame(np.sum(post_processing_output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b88bb-631f-45f7-8ae5-95808d4b0d1b",
   "metadata": {},
   "source": [
    "#### Function to post records of newly identified objects from frame into a BigQuery database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7e686ccc-d302-44b2-8d19-2cfac5e281cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_new_objects</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_errors</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errors</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
       "n_new_objects   0   0   5   0   1   0   0   0   0   0   0   0   0   0   0   1   \n",
       "n_errors        0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "errors         []  []  []  []  []  []  []  []  []  []  []  []  []  []  []  []   \n",
       "\n",
       "               16  17  18  19  \n",
       "n_new_objects   0   0   0   0  \n",
       "n_errors        0   0   0   0  \n",
       "errors         []  []  []  []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################\n",
    "# INSERT RECORDS OF NEW OBJECTS INTO BIGQUERY DATABASE\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import numpy as np, pandas as pd\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "# set up the BigQuery client using the service account key file\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "# set up the dataset and table ids\n",
    "dataset_id = 'video_analytics'  # Replace with your dataset ID\n",
    "table_id = 'objetos_identificados'      # Replace with your table ID\n",
    "\n",
    "# get the BigQuery client and table instances\n",
    "client = bigquery.Client.from_service_account_json(key_path)\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "def bigquery_post_new_objects(frame, detections, tracking, new_objects, process_start, process_end):\n",
    "    \n",
    "    # initialize list for errors\n",
    "    errors = []\n",
    "    \n",
    "    # if there's any nwe object\n",
    "    if len(new_objects):\n",
    "        \n",
    "        # drop unwanted fields\n",
    "        for obj in new_objects:\n",
    "            del obj['track_id']\n",
    "            del obj['bbox']\n",
    "        \n",
    "        # insert records of new objects into BigQuery table\n",
    "        errors = client.insert_rows(table, new_objects)\n",
    "\n",
    "        # log errors if any\n",
    "        if errors:\n",
    "            print('Error inserting record into BigQuery:', errors)\n",
    "\n",
    "    # return list with errors\n",
    "    return {'n_new_objects': len(new_objects), 'n_errors': len(errors), 'errors': errors}\n",
    "    \n",
    "    \n",
    "#### Run pipeline Â· Example usage\n",
    "\n",
    "post_processing_output = tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.5,\n",
    "    max_frames=60,\n",
    "    post_processing_function=bigquery_post_new_objects,\n",
    "    proccess_each=3,\n",
    ")\n",
    "\n",
    "# Display result: Errors if any\n",
    "\n",
    "co(True); display(pd.DataFrame(post_processing_output).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea875fff-729c-42db-99fa-7c78857a76f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Extra: Google BigQuery table Â· Set up and usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dde760-4e0a-4f5f-90c1-3f97744372e7",
   "metadata": {},
   "source": [
    "#### Create objects table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c910157b-6219-460f-95a3-d288ea6798df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-bigquery\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up the BigQuery client using the service account key file\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "# Set up the dataset and table information\n",
    "dataset_id = 'video_analytics'  # Replace with your dataset ID\n",
    "table_id = 'objetos_identificados'      # Replace with your table ID\n",
    "\n",
    "# Set BigQuery configuration object\n",
    "bq_config = {\n",
    "    'key_path': key_path,\n",
    "    'dataset_id': dataset_id,\n",
    "    'table_id': table_id\n",
    "}\n",
    "\n",
    "# CREATE TABLE IF IT DOESN'T EXIST\n",
    "\n",
    "# Define the schema of the table\n",
    "schema = [\n",
    "    # bigquery.SchemaField('class_label', 'STRING'),\n",
    "    bigquery.SchemaField('class_name', 'STRING'),\n",
    "    bigquery.SchemaField('confidence', 'FLOAT'),\n",
    "    bigquery.SchemaField('timestamp', 'TIMESTAMP'),\n",
    "    bigquery.SchemaField('camera_id', 'STRING'),\n",
    "    bigquery.SchemaField('camera_name', 'STRING'),\n",
    "    bigquery.SchemaField('url', 'STRING'),\n",
    "]\n",
    "\n",
    "# Create the table if it doesn't exist\n",
    "client = bigquery.Client.from_service_account_json(key_path)\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "table = client.create_table(table)\n",
    "\n",
    "# INSERT ROWS INTO TABLE\n",
    "\n",
    "# # Insert the rows into the table\n",
    "# errors = client.insert_rows_json(table, [{}, {}, ...])\n",
    "\n",
    "# if errors == []:\n",
    "#     print('Records inserted successfully.')\n",
    "# else:\n",
    "#     print(f'Errors occurred during insertion: {errors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4511738-92ae-40ed-9775-0a3d6c316af5",
   "metadata": {},
   "source": [
    "#### Create `users` database in bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4a14d4-199d-433b-8dda-735598462685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table octacity.video_analytics.users created successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up the BigQuery client using the service account key file\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client.from_service_account_json(key_path)\n",
    "\n",
    "# Define the schema for the users table\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"email\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"password\", \"STRING\", mode=\"REQUIRED\")\n",
    "]\n",
    "\n",
    "# Create the users table in BigQuery\n",
    "table_id = \"octacity.video_analytics.users\"  # Replace with your project ID and dataset ID\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)\n",
    "\n",
    "print(f\"Table {table_id} created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba406e3-4276-423a-8cae-66b0cdbad789",
   "metadata": {},
   "source": [
    "#### Create `cameras` database in bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c982c924-4b48-43a5-a9ef-990679eea0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table octacity.video_analytics.cameras created successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up the BigQuery client using the service account key file\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client.from_service_account_json(key_path)\n",
    "\n",
    "# Define the schema for the cameras table\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"url\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"objects\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"post_url\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"post_scheme\", \"STRING\"),\n",
    "    bigquery.SchemaField('timestamp', 'TIMESTAMP'),\n",
    "]\n",
    "\n",
    "# Create the cameras table in BigQuery\n",
    "table_id = \"octacity.video_analytics.cameras\"  # Replace with your project ID and dataset ID\n",
    "\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)\n",
    "print(f\"Table {table_id} created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41af086-1eb4-47a5-9f33-7a93a0b3e973",
   "metadata": {},
   "source": [
    "#### Delete any bigquery table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4037c6bc-d5f2-4f86-9927-ba7df479e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table octacity.video_analytics.objetos_identificados deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up the BigQuery client using the service account key file\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "# Define the ID of the table you want to delete\n",
    "table_id = \"octacity.video_analytics.cameras\"  # Replace with your project ID and table ID\n",
    "# table_id = \"octacity.video_analytics.objetos_identificados\"  # Replace with your project ID and table ID\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client.from_service_account_json(key_path)\n",
    "\n",
    "# Delete the table\n",
    "client.delete_table(table_id, not_found_ok=True)  # Set not_found_ok to True to ignore if the table doesn't exist\n",
    "\n",
    "print(f\"Table {table_id} deleted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb013de-6873-4378-9401-7b62aab367a2",
   "metadata": {},
   "source": [
    "#### Delete all rows from bigquery table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11f66c-50a8-42c8-8c59-b83d6f136c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "def delete_all_rows(dataset_id, table_id, key_path):\n",
    "    # Instantiate the BigQuery client\n",
    "    client = bigquery.Client.from_service_account_json(key_path)\n",
    "\n",
    "    # Get the table reference\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Get the table object\n",
    "    table = client.get_table(table_ref)\n",
    "\n",
    "    # Create a delete query to remove all rows\n",
    "    delete_query = f\"DELETE FROM `{table.project}.{table.dataset_id}.{table.table_id}` WHERE TRUE\"\n",
    "    # Create the job config\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "\n",
    "    # Start the query job\n",
    "    query_job = client.query(delete_query, job_config=job_config)\n",
    "\n",
    "    # Wait for the query job to complete\n",
    "    query_job.result()\n",
    "\n",
    "    print(f\"All rows deleted from {table.project}.{table.dataset_id}.{table.table_id}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_id = 'video_analytics'  # Your dataset ID\n",
    "# table_id = 'cameras'      # Your table ID\n",
    "table_id = 'objetos_identificados'      # Your table ID\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "delete_all_rows(dataset_id, table_id, key_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d39eb1-2ebd-476d-93bb-faf73d308a5e",
   "metadata": {},
   "source": [
    "---\n",
    "### Extra: Test camera endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d55af-0d69-4b43-b786-f373c7572f5c",
   "metadata": {},
   "source": [
    "#### Put camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "492634db-439d-4805-83ce-3e2b044aea27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Camera record updated successfully',\n",
       " 'record': {'objects': 'person,  car,  bus',\n",
       "  'post_scheme': '{\"Nome\": \"objeto\", \"Confianca\": \"confianca\", \"Hora\": \"hora\", \"Teste1\": \"Exemplo1\"}',\n",
       "  'post_url': 'http://127.0.0.1:5000/track/trigger/test',\n",
       "  'timestamp': 'Wed, 05 Jul 2023 22:10:53 GMT',\n",
       "  'url': 'http://187.111.99.18:9004/?CODE=1646'}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "body = {\n",
    "    'url': 'http://187.111.99.18:9004/?CODE=1646',\n",
    "    'objects': 'person, car, bus',\n",
    "    'post_url': 'http://127.0.0.1:5000/track/trigger/test',\n",
    "    'post_scheme': json.dumps({\n",
    "        'Nome': 'objeto',\n",
    "        'Confianca': 'confianca',\n",
    "        'Hora': 'hora',\n",
    "        'Teste1': \"Exemplo1\"\n",
    "        # 'id': 'id_rastreio',\n",
    "        # 'Caixa': 'caixa',\n",
    "    })\n",
    "}\n",
    "\n",
    "res = requests.put(url='http://127.0.0.1:5000/camera', json=body)\n",
    "\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b80d98-bc9f-4d50-80de-4d227c3e678e",
   "metadata": {},
   "source": [
    "#### Track trigger endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5d64be42-0d0b-4f5e-88af-59e247ab07f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Response [200]>,\n",
       " {'MESSAGE': 'Track post/trigger successfull', 'RESULTS': []})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'http://127.0.0.1:5000'\n",
    "\n",
    "res = requests.post(f'{base_url}/track/trigger', json={**body, 'detector': 'yolo', 'seconds': 3, 'objects': 'person, car, bus'})\n",
    "\n",
    "res, res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29923430-d2b2-47d1-9697-06343b66ae19",
   "metadata": {},
   "source": [
    "#### Delete camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47b0c0ab-1b59-4d03-90b2-8e857ac0371f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Record deleted successfully.'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.delete(\n",
    "    url='http://127.0.0.1:5000/camera',\n",
    "    json={'url': 'http://187.111.99.18:9004/?CODE=1646'}\n",
    ")\n",
    "\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65c3c1-e56d-4746-9671-556e7847af9c",
   "metadata": {},
   "source": [
    "#### Get cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33645fca-5245-40fd-84e5-9c76ad8b2aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 4,\n",
       "  'objects': 'person,  car,  pose-hands-up',\n",
       "  'post_scheme': '{\"objeto\": \"class_name\", \"confianca\": \"confidence\", \"hora\": \"timestamp\"}',\n",
       "  'post_url': 'http://127.0.0.1:5000/track/trigger/test',\n",
       "  'timestamp': 'Thu, 06 Jul 2023 03:37:48 GMT',\n",
       "  'url': 'http://187.111.99.18:9004/?CODE=1643'},\n",
       " {'id': 3,\n",
       "  'objects': '',\n",
       "  'post_scheme': '',\n",
       "  'post_url': '',\n",
       "  'timestamp': 'Wed, 05 Jul 2023 22:12:32 GMT',\n",
       "  'url': 'http://187.111.99.18:9004/?CODE=1648'},\n",
       " {'id': 2,\n",
       "  'objects': '',\n",
       "  'post_scheme': '',\n",
       "  'post_url': '',\n",
       "  'timestamp': 'Wed, 05 Jul 2023 22:11:31 GMT',\n",
       "  'url': 'http://187.111.99.18:9004/?CODE=1647'},\n",
       " {'id': 1,\n",
       "  'objects': 'person,  car,  bus',\n",
       "  'post_scheme': '{\"objeto\": \"class_name\", \"confianca\": \"confidence\", \"hora\": \"timestamp\"}',\n",
       "  'post_url': 'http://127.0.0.1:5000/track/trigger/test',\n",
       "  'timestamp': 'Wed, 05 Jul 2023 22:10:53 GMT',\n",
       "  'url': 'http://187.111.99.18:9004/?CODE=1646'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "requests.get('http://127.0.0.1:5000/cameras').json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfc641-0d86-4907-aad4-4c24775fd26f",
   "metadata": {},
   "source": [
    "---\n",
    "### Extra: Local SQL database file Â· Set up and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce627626-2d96-45ee-8494-3e713636a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database or create a new one if it doesn't exist\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table to store records\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS records (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        track_id INTEGER,\n",
    "        class_label INTEGER,\n",
    "        class_name TEXT,\n",
    "        confidence REAL,\n",
    "        frame_number INTEGER\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Example record data\n",
    "record_data = {\n",
    "    'track_id': 1,\n",
    "    'class_label': 0,\n",
    "    'class_name': 'Person',\n",
    "    'confidence': 0.95,\n",
    "    'frame_number': 10\n",
    "}\n",
    "\n",
    "# Insert a record into the table\n",
    "cursor.execute('''\n",
    "    INSERT INTO records (track_id, class_label, class_name, confidence, frame_number)\n",
    "    VALUES (:track_id, :class_label, :class_name, :confidence, :frame_number)\n",
    "''', record_data)\n",
    "\n",
    "# Save the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Query the records from the table\n",
    "cursor.execute('SELECT * FROM records')\n",
    "records = cursor.fetchall()\n",
    "\n",
    "# Print the records\n",
    "for record in records:\n",
    "    print(record)\n",
    "\n",
    "# Close the cursor and the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
