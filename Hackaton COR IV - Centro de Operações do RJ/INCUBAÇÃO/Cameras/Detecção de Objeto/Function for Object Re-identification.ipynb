{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff105a5e-86d9-4ccd-a1c5-c36302fa675d",
   "metadata": {},
   "source": [
    "## Multiple object tracking and re-identification with DeepSORT · Object database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e43effc-2d68-4cb7-a230-b2e50a82109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics\n",
    "# !pip install deep-sort-realtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df3061-5236-4cb8-8280-0352d4ba1ec0",
   "metadata": {},
   "source": [
    "#### Class to write videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c03e8436-062f-4a2d-aeda-e1189f3bbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "\n",
    "class Video:\n",
    "\n",
    "    def __init__(self, codec:str='MP4V', fps:int=3, shape:tuple=(854, 480), overwrite=False):\n",
    "        self.codec = codec; self.fps = fps; self.shape = shape\n",
    "        self.overwrite = overwrite\n",
    "\n",
    "    def writer(self, path):\n",
    "        if not self.overwrite and os.path.exists(path):\n",
    "            print(f'ANNOTATE VIDEO TIMESTAMP FAILED. FILE ALREADY EXISTS · FILE-PATH: {path}')\n",
    "            return False\n",
    "        fourcc = cv2.VideoWriter_fourcc(*self.codec)\n",
    "        return cv2.VideoWriter(path, fourcc, self.fps, self.shape)\n",
    "\n",
    "    \n",
    "#### OPEN VIDEO FILE WRITER · Method #1\n",
    "# video_path = \"output.mp4\"\n",
    "# fps, shape = get_video_metadata(video_path, transform=None)\n",
    "# shape = (shape[1], shape[0]) # witdth, height\n",
    "# overwrite = True\n",
    "# video = Video(fps=fps, shape=shape, overwrite=overwrite)\n",
    "# writer = video.writer(path=video_path)\n",
    "\n",
    "# writer.release(); cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296e36d-afe9-49ed-b263-395e5c3455c8",
   "metadata": {},
   "source": [
    "#### Function to get basic metadata from video file:\n",
    "    fps: frames per second (FPS) of video file\n",
    "    shape: shape of first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "92a5e667-baf7-49da-9f22-c0705eb9aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_metadata(video_path, transform=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) # get the fps\n",
    "    _, frame = cap.read() # read the first frame\n",
    "    if transform is not None: # custom transformation\n",
    "        frame = transform(frame)\n",
    "    shape = frame.shape; # get the shape\n",
    "    cap.release(); cv2.destroyAllWindows()\n",
    "    return fps, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ba0a2-9d63-4dcd-8772-3a9aa8f26d12",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Function to open video file writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a90942d0-53d3-4e88-8043-d1990fbc7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def create_video_writer(video_cap, output_filename):\n",
    "\n",
    "    # grab the width, height, and fps of the frames in the video stream.\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # initialize the FourCC and a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n",
    "                             (frame_width, frame_height))\n",
    "\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505dc10a-5549-4153-bb5e-6e68b66b7514",
   "metadata": {},
   "source": [
    "#### Format output of YOLO object detection model from python's `ultralitycs` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4908eb3f-67de-4966-8d62-782d7b49a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_yolo_detection(detection, class_names=None):\n",
    "    \"\"\"\n",
    "    Formats the YOLO detection results.\n",
    "\n",
    "    Args:\n",
    "        detection (object): The detection object.\n",
    "        class_names (dict): Dict of class names by class id.\n",
    "\n",
    "    Returns:\n",
    "        list: Formatted detection results.\n",
    "    \"\"\"\n",
    "    formatted_detection = []\n",
    "\n",
    "    for data in detection.boxes.data.tolist():\n",
    "        # Get the bounding box and the class id\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "\n",
    "        # Extract the confidence (i.e., probability) associated with the prediction\n",
    "        confidence = data[4]\n",
    "\n",
    "        # Get class id and name\n",
    "        class_id = int(data[5])\n",
    "        class_name = class_names[class_id] if class_names is not None else None\n",
    "\n",
    "        # Add standard format detections\n",
    "        formatted_detection.append([class_id, class_name, confidence, [xmin, ymin, xmax, ymax]])\n",
    "\n",
    "    return formatted_detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21930a-742c-4e16-b6c2-4a084c1ee797",
   "metadata": {},
   "source": [
    "### Function to process object identification output (post processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8fd7ed75-03eb-4c5c-86c1-f115956b4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tracking and detection from: https://www.thepythoncode.com/article/real-time-object-tracking-with-yolov8-opencv\n",
    "\n",
    "import datetime, pandas as pd\n",
    "from IPython.display import clear_output as co\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import asyncio\n",
    "\n",
    "def tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.3,\n",
    "    objects_allowed=None,\n",
    "    max_frames=10,\n",
    "    post_processing_function=None,\n",
    "    post_processing_args={},\n",
    "    proccess_each=None,\n",
    "    frame_annotator=None,\n",
    "    to_video_path=None,\n",
    "    generator=False\n",
    "):\n",
    "    \n",
    "    # initialize YOLO object detection model\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    # Get class names from model\n",
    "    class_names = model.names\n",
    "\n",
    "    # initialize DeepSORT real-time tracker\n",
    "    deepsort = DeepSort(max_age=50)\n",
    "        \n",
    "    # initialize the video capture object\n",
    "    video_cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # check if video capture is a live http image stream\n",
    "    is_video_stream = video_path.startswith('http')\n",
    "\n",
    "    # total frames of video file\n",
    "    total_frames = None if is_video_stream else int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT)) # if capture is from video file\n",
    "\n",
    "    if to_video_path is not None:\n",
    "        # Get the frames per second (fps)\n",
    "        fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        # Get the frame dimensions (shape)\n",
    "        w = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        h = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Video writer instance\n",
    "        video = Video(codec='MP4V', fps=fps, shape=(w, h), overwrite=True)\n",
    "        WRITER = video.writer(to_video_path)\n",
    "\n",
    "    # initialize set for track ids \n",
    "    unique_track_ids = set()\n",
    "\n",
    "    # initialize post processing output list\n",
    "    post_processing_output = []\n",
    "    \n",
    "    i = -1\n",
    "    while True:\n",
    "\n",
    "        # update number of frames processed or skipped\n",
    "        i += 1\n",
    "        \n",
    "        # break loop if `max_frames` are processed\n",
    "        if max_frames is not None and max_frames == i:\n",
    "            break\n",
    "\n",
    "        # current date and time\n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        # datetime as string rounded to seconds\n",
    "        timestamp = str(start)[:19]\n",
    "        \n",
    "        # read video frame\n",
    "        ret, frame = video_cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # continue if frame index `i` is not a multiple of `process_each`. never continues for first frame\n",
    "        if proccess_each is not None and i % proccess_each != 0:\n",
    "            continue\n",
    "\n",
    "        ######################################\n",
    "        # RUN DETECTION · Obs. Choose standard model method for prediction and wrap models that use other methods before passing then to the function.\n",
    "\n",
    "        # run the YOLO model on the frame\n",
    "        yolo_detection = model(frame)[0]\n",
    "        \n",
    "        # formatted yolo detections\n",
    "        detections = formatted_yolo_detection(yolo_detection, class_names=class_names)\n",
    "\n",
    "        # initialize list for tracker input\n",
    "        tracker_input = []\n",
    "        \n",
    "        # set up input for tracker from detections\n",
    "        for det in detections:\n",
    "            \n",
    "            # get detected object attributes\n",
    "            class_id, class_name, confidence, bbox = det\n",
    "            \n",
    "            # filter out weak detections by ensuring the \n",
    "            # confidence is greater than the minimum confidence\n",
    "            if float(confidence) < confidence_threshold:\n",
    "                continue\n",
    "                \n",
    "            # filter out unwanted objects  \n",
    "            if objects_allowed is not None and class_name not in objects_allowed:\n",
    "                continue\n",
    "\n",
    "            # if the confidence is greater than the minimum confidence,\n",
    "            # get the bounding box and the class id\n",
    "            xmin, ymin, xmax, ymax = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "            \n",
    "            # add the bounding box (x, y, w, h), confidence and class id to the results list\n",
    "            tracker_input.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "\n",
    "        ######################################\n",
    "        # RUN TRACKING\n",
    "\n",
    "        # update the tracker with the new detections\n",
    "        tracks = deepsort.update_tracks(tracker_input, frame=frame)\n",
    "        \n",
    "        # initialize list for formatted tracker output\n",
    "        tracking = []\n",
    "\n",
    "        # list tracking result\n",
    "        for track in tracks:\n",
    "        \n",
    "            # if the track is not confirmed, ignore it\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            # get attributes of tracked object\n",
    "            track_id = track.track_id\n",
    "            class_label = track.det_class\n",
    "            class_name = class_names[class_label]\n",
    "            confidence = track.det_conf\n",
    "            bbox = track.to_ltrb()\n",
    "\n",
    "            # append attributes of tracked objects\n",
    "            tracking.append([track_id, class_label, class_name, confidence, bbox, start])\n",
    "        \n",
    "        ######################################\n",
    "        # GET NEWLY IDENTIFIED OBJECTS\n",
    "        \n",
    "        # initialize list for newly detected objects\n",
    "        new_objects = []\n",
    "\n",
    "        # loop over the formatted tracks and get newly identified objects\n",
    "        for track in tracking:\n",
    "\n",
    "            # get track attributes\n",
    "            track_id, class_label, class_name, confidence, bbox, timestamp = track\n",
    "\n",
    "            # check if track ID is unique\n",
    "            if track_id not in unique_track_ids:\n",
    "\n",
    "                # prepare record of newly identified object\n",
    "                record = {\n",
    "                    'class_label': class_label,\n",
    "                    'class_name': class_name,\n",
    "                    'confidence': confidence,\n",
    "                    'timestamp': timestamp,\n",
    "                    'track_id': track_id,\n",
    "                    'bbox': list(bbox),\n",
    "                }\n",
    "\n",
    "                # append record to list of new objects\n",
    "                new_objects.append(record)\n",
    "\n",
    "                # add the tracked object ID to the set of unique track IDs\n",
    "                unique_track_ids.add(track_id)\n",
    "\n",
    "        ######################################\n",
    "        # PROCESS RESULT\n",
    "        \n",
    "        # end time to compute the fps\n",
    "        end = datetime.datetime.now()\n",
    "        \n",
    "        if frame_annotator is not None:\n",
    "            annotated_frame = frame_annotator(frame, detections, tracking, new_objects, start, end)\n",
    "            \n",
    "        if to_video_path is not None:\n",
    "            selected_frame = frame if frame_annotator is None else annotated_frame\n",
    "            WRITER.write(selected_frame)\n",
    "                \n",
    "        # call arbitrary post processing function on frame and detection & tracking outputs\n",
    "        if post_processing_function is not None:\n",
    "            post_processing_output.append(post_processing_function(frame, detections, tracking, new_objects, start, end, **post_processing_args))\n",
    "\n",
    "        # report progress and time to process the current frame\n",
    "        # if total_frames is not None:\n",
    "            # co(True); print(f\"Time to process frame {i}/{total_frames}: {(end - start).total_seconds() * 1000:.0f} milliseconds\")\n",
    "\n",
    "        if generator:\n",
    "            selected_frame = frame if frame_annotator is None else annotated_frame\n",
    "            ret, buffer = cv2.imencode('.jpg', selected_frame)\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + buffer.tobytes() + b'\\r\\n')\n",
    "        \n",
    "    if to_video_path is not None:\n",
    "        # Optional · release video writer\n",
    "        WRITER.release() # run after writing is finished\n",
    "\n",
    "    # release video capture\n",
    "    video_cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # return post processing results\n",
    "    return post_processing_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9b879-a2b0-4bc3-815c-5e22b3ca029f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiple object tracking and re-identification with DeepSORT\n",
    "\n",
    "### Process detection and re-identification results · Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3c571-e7b2-4ae5-9bf2-e3595982ebb0",
   "metadata": {},
   "source": [
    "Define system paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5f33b4f3-35dd-4a2e-9dc6-8aacd23518c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system paths\n",
    "folder = '../Dados/Demos/smartphone-video-samples/'\n",
    "to_folder = '../Dados/Demos/tracking-id-db/'\n",
    "file_name = 'VID_20230515_125317.mp4'\n",
    "\n",
    "video_path = folder + file_name\n",
    "to_video_path = to_folder + file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19f37c-00b1-4294-a159-1d78d453b360",
   "metadata": {},
   "source": [
    "#### Function to write frame and results to video file · Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e3e8e94a-c5c3-47f7-a297-88c69683f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up color scheme\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "def write_demo(frame, detections, tracking, new_objects, process_start, process_end):\n",
    "\n",
    "    # loop over the formatted tracks and get newly identified objects\n",
    "    for track in tracking:\n",
    "\n",
    "        # get track attributes\n",
    "        track_id, class_label, class_name, confidence, bbox, timestamp = track\n",
    "\n",
    "        # get pixel values from track bounding box\n",
    "        xmin, ymin, xmax, ymax = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "        \n",
    "        # draw the bounding box and the track id\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.rectangle(frame, (xmin, ymin - 40), (xmin + 40, ymin), GREEN, -1)\n",
    "        cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8), cv2.FONT_HERSHEY_SIMPLEX, 1, WHITE, 2)\n",
    "        \n",
    "    # calculate the frame per second and draw it on the frame\n",
    "    fps = f\"FPS: {1 / (process_end - process_start).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, BLUE, 8)\n",
    "    \n",
    "    return frame\n",
    "    # write annotated frame to video file\n",
    "    # WRITER.write(frame)\n",
    "\n",
    "    \n",
    "#### Run pipeline · Example usage\n",
    "\n",
    "post_processing_output = tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.5,\n",
    "    max_frames=20,\n",
    "    post_processing_function=None,\n",
    "    proccess_each=None,\n",
    "    frame_annotator=write_demo,\n",
    "    to_video_path=to_video_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e823ea-19d7-4f87-b14a-bc26fafb806d",
   "metadata": {},
   "source": [
    "#### Show post processing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9fad014-aa83-4c8e-b570-b57be0f03903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_processing_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642dd7d-21e5-4246-b715-9fe980090b9f",
   "metadata": {},
   "source": [
    "---\n",
    "## Example usage with other sample functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65b3c7-0c6a-4277-a41c-0ff690aae830",
   "metadata": {},
   "source": [
    "#### Function to display frame of video demonstration of detection and tracking with re-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "185fe656-58ba-46d4-a480-db36248d41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "# set up color scheme\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "def show_demo(frame, detections, tracking, new_objects, process_start, process_end):\n",
    "\n",
    "    # Convert BGR image to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # loop over the formatted tracks and get newly identified objects\n",
    "    for track in tracking:\n",
    "\n",
    "        # get track attributes\n",
    "        track_id, class_label, class_name, confidence, bbox, timestamp = track\n",
    "\n",
    "        # get pixel values from track bounding box\n",
    "        xmin, ymin, xmax, ymax = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "\n",
    "        # draw the bounding box and the track id\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.rectangle(frame, (xmin, ymin - 40), (xmin + 40, ymin), GREEN, -1)\n",
    "        cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8), cv2.FONT_HERSHEY_SIMPLEX, 1, WHITE, 2)\n",
    "\n",
    "    # calculate the frame per second and draw it on the frame\n",
    "    fps = f\"Processing FPS: {1 / (process_end - process_start).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, BLUE, 8)\n",
    "    \n",
    "    # clear last frame screen output\n",
    "    co(True)\n",
    "    \n",
    "    # show the frame to our screen\n",
    "    plt.imshow(frame);\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    # cv2.imshow(\"Frame\", frame)\n",
    "    # cv2.waitKey(1) == ord(\"q\")\n",
    "    # plt.show()\n",
    "\n",
    "    \n",
    "#### Run pipeline · Example usage\n",
    "\n",
    "post_processing_output = tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.5,\n",
    "    max_frames=200,\n",
    "    post_processing_function=show_demo,\n",
    "    proccess_each=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff1ba73-8179-4ee0-8ad0-2220bdcd11fd",
   "metadata": {},
   "source": [
    "#### Function to gather id and info of newly identified objects from frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bc369-9dca-4b79-97a9-e771fa58429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "def gather_unique_objects(frame, detections, tracking, new_objects, process_start, process_end):\n",
    "\n",
    "    # extend list of unique objects with new objects\n",
    "    return new_objects\n",
    "    \n",
    "    \n",
    "#### Run pipeline · Example usage\n",
    "\n",
    "# initialize set for track ids \n",
    "unique_track_ids = set()\n",
    "\n",
    "post_processing_output = tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.5,\n",
    "    max_frames=20,\n",
    "    post_processing_function=gather_unique_objects,\n",
    "    proccess_each=None,\n",
    ")\n",
    "\n",
    "# Display result: Identified objects\n",
    "\n",
    "co(True); display(pd.DataFrame(np.sum(post_processing_output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b88bb-631f-45f7-8ae5-95808d4b0d1b",
   "metadata": {},
   "source": [
    "#### Function to post records of newly identified objects from frame into a BigQuery database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7e686ccc-d302-44b2-8d19-2cfac5e281cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_new_objects</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_errors</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errors</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  \\\n",
       "n_new_objects   0   0   5   0   1   0   0   0   0   0   0   0   0   0   0   1   \n",
       "n_errors        0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "errors         []  []  []  []  []  []  []  []  []  []  []  []  []  []  []  []   \n",
       "\n",
       "               16  17  18  19  \n",
       "n_new_objects   0   0   0   0  \n",
       "n_errors        0   0   0   0  \n",
       "errors         []  []  []  []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################\n",
    "# INSERT RECORDS OF NEW OBJECTS INTO BIGQUERY DATABASE\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import numpy as np, pandas as pd\n",
    "from IPython.display import clear_output as co\n",
    "\n",
    "# set up the BigQuery client using the service account key file\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "# set up the dataset and table ids\n",
    "dataset_id = 'video_analytics'  # Replace with your dataset ID\n",
    "table_id = 'objetos_identificados'      # Replace with your table ID\n",
    "\n",
    "# get the BigQuery client and table instances\n",
    "client = bigquery.Client.from_service_account_json(key_path)\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "def bigquery_post_new_objects(frame, detections, tracking, new_objects, process_start, process_end):\n",
    "    \n",
    "    # initialize list for errors\n",
    "    errors = []\n",
    "    \n",
    "    # if there's any nwe object\n",
    "    if len(new_objects):\n",
    "        \n",
    "        # drop unwanted fields\n",
    "        for obj in new_objects:\n",
    "            del obj['track_id']\n",
    "            del obj['bbox']\n",
    "        \n",
    "        # insert records of new objects into BigQuery table\n",
    "        errors = client.insert_rows(table, new_objects)\n",
    "\n",
    "        # log errors if any\n",
    "        if errors:\n",
    "            print('Error inserting record into BigQuery:', errors)\n",
    "\n",
    "    # return list with errors\n",
    "    return {'n_new_objects': len(new_objects), 'n_errors': len(errors), 'errors': errors}\n",
    "    \n",
    "    \n",
    "#### Run pipeline · Example usage\n",
    "\n",
    "post_processing_output = tracking_reid(\n",
    "    video_path,\n",
    "    confidence_threshold=0.5,\n",
    "    max_frames=60,\n",
    "    post_processing_function=bigquery_post_new_objects,\n",
    "    proccess_each=3,\n",
    ")\n",
    "\n",
    "# Display result: Errors if any\n",
    "\n",
    "co(True); display(pd.DataFrame(post_processing_output).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea875fff-729c-42db-99fa-7c78857a76f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Extra: Google BigQuery table · Set up and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c910157b-6219-460f-95a3-d288ea6798df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-bigquery\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up the BigQuery client using the service account key file\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "# Set up the dataset and table information\n",
    "dataset_id = 'video_analytics'  # Replace with your dataset ID\n",
    "table_id = 'objetos_identificados'      # Replace with your table ID\n",
    "\n",
    "# Set BigQuery configuration object\n",
    "bq_config = {\n",
    "    'key_path': key_path,\n",
    "    'dataset_id': dataset_id,\n",
    "    'table_id': table_id\n",
    "}\n",
    "\n",
    "# CREATE TABLE IF IT DOESN'T EXIST\n",
    "\n",
    "# Define the schema of the table\n",
    "schema = [\n",
    "    bigquery.SchemaField('class_label', 'STRING'),\n",
    "    bigquery.SchemaField('class_name', 'STRING'),\n",
    "    bigquery.SchemaField('confidence', 'FLOAT'),\n",
    "    bigquery.SchemaField('timestamp', 'TIMESTAMP'),\n",
    "    bigquery.SchemaField('url', 'STRING'),\n",
    "]\n",
    "\n",
    "# Create the table if it doesn't exist\n",
    "client = bigquery.Client.from_service_account_json(key_path)\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "table = client.create_table(table)\n",
    "\n",
    "# INSERT ROWS INTO TABLE\n",
    "\n",
    "# # Insert the rows into the table\n",
    "# errors = client.insert_rows_json(table, [{}, {}, ...])\n",
    "\n",
    "# if errors == []:\n",
    "#     print('Records inserted successfully.')\n",
    "# else:\n",
    "#     print(f'Errors occurred during insertion: {errors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4511738-92ae-40ed-9775-0a3d6c316af5",
   "metadata": {},
   "source": [
    "#### Create `users` database in bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4a14d4-199d-433b-8dda-735598462685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table octacity.video_analytics.users created successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Set up the BigQuery client using the service account key file\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client.from_service_account_json(key_path)\n",
    "\n",
    "# Define the schema for the users table\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"email\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"password\", \"STRING\", mode=\"REQUIRED\")\n",
    "]\n",
    "\n",
    "# Create the users table in BigQuery\n",
    "table_id = \"octacity.video_analytics.users\"  # Replace with your project ID and dataset ID\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)\n",
    "\n",
    "print(f\"Table {table_id} created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb013de-6873-4378-9401-7b62aab367a2",
   "metadata": {},
   "source": [
    "#### Delete all rows from bigquery table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef4f7c-a1ee-4671-ac02-524612f28fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "def delete_all_rows(dataset_id, table_id, key_path):\n",
    "    # Instantiate the BigQuery client\n",
    "    client = bigquery.Client.from_service_account_json(key_path)\n",
    "\n",
    "    # Get the table reference\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Get the table object\n",
    "    table = client.get_table(table_ref)\n",
    "\n",
    "    # Create a delete query to remove all rows\n",
    "    delete_query = f\"DELETE FROM `{table.project}.{table.dataset_id}.{table.table_id}` WHERE TRUE\"\n",
    "    # Create the job config\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "\n",
    "    # Start the query job\n",
    "    query_job = client.query(delete_query, job_config=job_config)\n",
    "\n",
    "    # Wait for the query job to complete\n",
    "    query_job.result()\n",
    "\n",
    "    print(f\"All rows deleted from {table.project}.{table.dataset_id}.{table.table_id}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_id = 'video_analytics'  # Your dataset ID\n",
    "table_id = 'objetos_identificados'      # Your table ID\n",
    "key_path = '../../../../../Apps/APIs/octa-api/credentials/octacity-iduff.json'  # Replace with the path to your service account key file\n",
    "\n",
    "delete_all_rows(dataset_id, table_id, key_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfc641-0d86-4907-aad4-4c24775fd26f",
   "metadata": {},
   "source": [
    "---\n",
    "### Extra: Local SQL database file · Set up and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce627626-2d96-45ee-8494-3e713636a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database or create a new one if it doesn't exist\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table to store records\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS records (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        track_id INTEGER,\n",
    "        class_label INTEGER,\n",
    "        class_name TEXT,\n",
    "        confidence REAL,\n",
    "        frame_number INTEGER\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Example record data\n",
    "record_data = {\n",
    "    'track_id': 1,\n",
    "    'class_label': 0,\n",
    "    'class_name': 'Person',\n",
    "    'confidence': 0.95,\n",
    "    'frame_number': 10\n",
    "}\n",
    "\n",
    "# Insert a record into the table\n",
    "cursor.execute('''\n",
    "    INSERT INTO records (track_id, class_label, class_name, confidence, frame_number)\n",
    "    VALUES (:track_id, :class_label, :class_name, :confidence, :frame_number)\n",
    "''', record_data)\n",
    "\n",
    "# Save the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Query the records from the table\n",
    "cursor.execute('SELECT * FROM records')\n",
    "records = cursor.fetchall()\n",
    "\n",
    "# Print the records\n",
    "for record in records:\n",
    "    print(record)\n",
    "\n",
    "# Close the cursor and the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
